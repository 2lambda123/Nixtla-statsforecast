{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d337835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a288321",
   "metadata": {},
   "source": [
    "# Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5479dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import inspect\n",
    "import logging\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(name)s %(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq\n",
    "\n",
    "from statsforecast.models import (\n",
    "    adida,\n",
    "    croston_classic,\n",
    "    historic_average,\n",
    "    naive,\n",
    "    seasonal_naive,\n",
    "    seasonal_window_average,\n",
    "    ses,\n",
    ")\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdf74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_series(10_000, equal_ends=False)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77692f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class GroupedArray:\n",
    "    \n",
    "    def __init__(self, data, indptr):\n",
    "        self.data = data\n",
    "        self.indptr = indptr\n",
    "        self.n_groups = self.indptr.size - 1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.data[self.indptr[idx] : self.indptr[idx + 1]]\n",
    "        elif isinstance(idx, slice):\n",
    "            idx = slice(idx.start, idx.stop + 1, idx.step)\n",
    "            new_indptr = self.indptr[idx].copy()\n",
    "            new_data = self.data[new_indptr[0] : new_indptr[-1]].copy()            \n",
    "            new_indptr -= new_indptr[0]\n",
    "            return GroupedArray(new_data, new_indptr)\n",
    "        raise ValueError(f'idx must be either int or slice, got {type(idx)}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_groups\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'GroupedArray(n_data={self.data.size:,}, n_groups={self.n_groups:,})'\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not hasattr(other, 'data') or not hasattr(other, 'indptr'):\n",
    "            return False\n",
    "        return np.allclose(self.data, other.data) and np.array_equal(self.indptr, other.indptr)\n",
    "    \n",
    "    def compute_forecasts(self, h, func, *args):\n",
    "        out = np.full(h * self.n_groups, np.nan, dtype=np.float32)\n",
    "        for i, grp in enumerate(self):\n",
    "            out[h * i : h * (i + 1)] = func(grp, h, *args)\n",
    "        return out\n",
    "    \n",
    "    def split(self, n_chunks):\n",
    "        return [self[x[0] : x[-1] + 1] for x in np.array_split(range(self.n_groups), n_chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "data = np.arange(12)\n",
    "indptr = np.array([0, 4, 8, 12])\n",
    "ga = GroupedArray(data, indptr)\n",
    "\n",
    "test_eq(len(ga), 3)\n",
    "np.testing.assert_equal(\n",
    "    ga.compute_forecasts(2, naive),\n",
    "    np.hstack([2 * [data[i]] for i in indptr[1:] - 1]),\n",
    ")\n",
    "splits = ga.split(2)\n",
    "test_eq(splits[0], GroupedArray(data[:8], indptr[:3]))\n",
    "test_eq(splits[1], GroupedArray(data[8:], np.array([0, 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _grouped_array_from_df(df):\n",
    "    df = df.set_index('ds', append=True)\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df = df.sort_index()\n",
    "    data = df['y'].values.astype(np.float32)\n",
    "    indices_sizes = df.index.get_level_values('unique_id').value_counts(sort=False)\n",
    "    indices = indices_sizes.index\n",
    "    sizes = indices_sizes.values\n",
    "    cum_sizes = sizes.cumsum()\n",
    "    dates = df.index.get_level_values('ds')[cum_sizes - 1]\n",
    "    indptr = np.append(0, cum_sizes).astype(np.int32)\n",
    "    return GroupedArray(data, indptr), indices, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ae534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "sorted_series = series.sort_values(['unique_id', 'ds'])\n",
    "unsorted_series = sorted_series.sample(frac=1.0)\n",
    "ga, indices, dates = _grouped_array_from_df(unsorted_series)\n",
    "\n",
    "np.testing.assert_allclose(ga.data, sorted_series['y'].values)\n",
    "test_eq(indices, sorted_series.index.unique(level='unique_id'))\n",
    "test_eq(dates, series.groupby('unique_id')['ds'].max().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37729326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _build_forecast_name(model, *args) -> str:\n",
    "    model_name = f'{model.__name__}'\n",
    "    func_params = inspect.signature(model).parameters\n",
    "    func_args = list(func_params.items())[2:]  # remove input array and horizon\n",
    "    changed_params = [\n",
    "        f'{name}-{value}'\n",
    "        for value, (name, arg) in zip(args, func_args)\n",
    "        if arg.default != value\n",
    "    ]\n",
    "    if changed_params:\n",
    "        model_name += '_' + '_'.join(changed_params)\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88faa296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(_build_forecast_name(ses, 0.1), 'ses_alpha-0.1')\n",
    "test_eq(_build_forecast_name(seasonal_window_average, 7, 4), 'seasonal_window_average_season_length-7_window_size-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8addd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _as_tuple(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x\n",
    "    return (x,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(_as_tuple((1,)), (1,))\n",
    "test_eq(_as_tuple(1), (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d06d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StatsForecast:\n",
    "    \n",
    "    def __init__(self, df, models, freq, n_jobs=1):\n",
    "        self.ga, self.uids, self.last_dates = _grouped_array_from_df(df)\n",
    "        self.models = models\n",
    "        self.freq = pd.tseries.frequencies.to_offset(freq)\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "    def forecast(self, h):\n",
    "        if self.n_jobs == 1:\n",
    "            fcsts = self._sequential_forecast(h)\n",
    "        else:\n",
    "            fcsts = self._data_parallel_forecast(h)\n",
    "        dates = np.hstack([\n",
    "            pd.date_range(last_date + self.freq, periods=h, freq=self.freq)\n",
    "            for last_date in self.last_dates            \n",
    "        ])\n",
    "        idx = pd.Index(np.repeat(self.uids, h), name='unique_id')\n",
    "        return pd.DataFrame({'ds': dates, **fcsts}, index=idx)\n",
    "        \n",
    "    def _sequential_forecast(self, h):\n",
    "        fcsts = {}\n",
    "        logger.info('Computing forecasts')\n",
    "        for model_args in self.models:\n",
    "            model, *args = _as_tuple(model_args)\n",
    "            model_name = _build_forecast_name(model, *args)\n",
    "            fcsts[model_name] = self.ga.compute_forecasts(h, model, *args)\n",
    "            logger.info(f'Computed forecasts for {model_name}.')\n",
    "        return fcsts\n",
    "    \n",
    "    def _data_parallel_forecast(self, h):\n",
    "        fcsts = {}\n",
    "        logger.info('Computing forecasts')\n",
    "        gas = self.ga.split(self.n_jobs)\n",
    "        with ProcessPoolExecutor(self.n_jobs) as executor:\n",
    "            for model_args in self.models:\n",
    "                model, *args = _as_tuple(model_args)\n",
    "                model_name = _build_forecast_name(model, *args)\n",
    "                futures = []\n",
    "                for ga in gas:\n",
    "                    future = executor.submit(ga.compute_forecasts, h, model, *args)\n",
    "                    futures.append(future)\n",
    "                fcsts[model_name] = np.hstack([f.result() for f in futures])\n",
    "                logger.info(f'Computed forecasts for {model_name}.')\n",
    "        return fcsts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f493ff0",
   "metadata": {},
   "source": [
    "## Daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    series,\n",
    "    [adida, (ses, 0.1), historic_average, croston_classic],\n",
    "    freq='D',\n",
    ")\n",
    "%time res1 = fcst.forecast(14)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93072780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(res1.index.unique(), fcst.uids)\n",
    "test_eq(res1.groupby('unique_id')['ds'].min().values, fcst.last_dates + fcst.freq)\n",
    "test_eq(res1.groupby('unique_id')['ds'].max().values, fcst.last_dates + 14 * fcst.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e50132",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    series,\n",
    "    [adida, (ses, 0.1), historic_average, croston_classic],\n",
    "    freq='D',\n",
    "    n_jobs=2,\n",
    ")\n",
    "%time res2 = fcst.forecast(14)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(res1, res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fdbc35",
   "metadata": {},
   "source": [
    "## Monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e27890",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_series = generate_series(10_000, freq='M', min_length=10, max_length=20, equal_ends=True)\n",
    "monthly_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    monthly_series,\n",
    "    [adida, (ses, 0.1), historic_average, croston_classic],\n",
    "    freq='M',\n",
    ")\n",
    "%time monthly_res = fcst.forecast(4)\n",
    "monthly_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
