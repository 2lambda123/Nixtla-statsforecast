{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad180b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c1362",
   "metadata": {},
   "source": [
    "# Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab95a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import inspect\n",
    "import logging\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4831fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(name)s %(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5743d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import adida, ses, historic_average, croston_classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99700b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_series(10_000, equal_ends=True)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5286f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class GroupedArray:\n",
    "    \n",
    "    def __init__(self, data, indptr):\n",
    "        self.data = data\n",
    "        self.indptr = indptr\n",
    "        self.n_groups = self.indptr.size - 1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.data[self.indptr[idx] : self.indptr[idx + 1]]\n",
    "        elif isinstance(idx, slice):\n",
    "            idx = slice(idx.start, idx.stop + 1, idx.step)\n",
    "            new_indptr = self.indptr[idx].copy()\n",
    "            new_data = self.data[new_indptr[0] : new_indptr[-1]].copy()            \n",
    "            new_indptr -= new_indptr[0]\n",
    "            return GroupedArray(new_data, new_indptr)\n",
    "        raise ValueError(f'idx must be either int or slice, got {type(idx)}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_groups\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'GroupedArray(n_data={self.data.size:,}, n_groups={self.n_groups:,})'\n",
    "    \n",
    "    def compute_forecasts(self, h, func, *args):\n",
    "        out = np.full(h * self.n_groups, np.nan, dtype=np.float32)\n",
    "        for i, grp in enumerate(self):\n",
    "            out[h * i : h * (i + 1)] = func(grp, h, *args)\n",
    "        return out\n",
    "    \n",
    "    def split(self, n_chunks):\n",
    "        return [self[x[0] : x[-1] + 1] for x in np.array_split(range(self.n_groups), n_chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _grouped_array_from_df(df):\n",
    "    df = df.set_index('ds', append=True)\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df = df.sort_index()\n",
    "    data = df['y'].values.astype(np.float32)\n",
    "    indices_sizes = df.index.get_level_values('unique_id').value_counts(sort=False)\n",
    "    indices = indices_sizes.index\n",
    "    sizes = indices_sizes.values\n",
    "    cum_sizes = sizes.cumsum()\n",
    "    dates = df.index.get_level_values('ds')[cum_sizes - 1]\n",
    "    indptr = np.append(0, cum_sizes).astype(np.int32)\n",
    "    return GroupedArray(data, indptr), indices, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%time ga, *_ = _grouped_array_from_df(series)\n",
    "ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2618fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%time yy = ga.compute_forecasts(14, ses, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2982417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%timeit ga.compute_forecasts(14, ses, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff9488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _build_forecast_name(model, *args) -> str:\n",
    "    model_name = f'{model.__name__}'\n",
    "    func_params = inspect.signature(model).parameters\n",
    "    func_args = list(func_params.items())[2:]  # remove input array and horizon\n",
    "    changed_params = [\n",
    "        f'{name}-{value}'\n",
    "        for value, (name, arg) in zip(args, func_args)\n",
    "        if arg.default != value\n",
    "    ]\n",
    "    if changed_params:\n",
    "        model_name += '_' + '_'.join(changed_params)\n",
    "    return model_name\n",
    "\n",
    "def _as_tuple(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x\n",
    "    return (x, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StatsForecast:\n",
    "    \n",
    "    def __init__(self, df, models, freq, n_jobs=1):\n",
    "        self.ga, self.uids, self.last_dates = _grouped_array_from_df(df)\n",
    "        self.models = models\n",
    "        self.freq = pd.tseries.frequencies.to_offset(freq)\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "    def forecast(self, h):\n",
    "        if self.n_jobs == 1:\n",
    "            fcsts = self._sequential_forecast(h)\n",
    "        else:\n",
    "            fcsts = self._data_parallel_forecast(h)\n",
    "        dates = np.hstack([\n",
    "            pd.date_range(last_date + self.freq, periods=h, freq=self.freq)\n",
    "            for last_date in self.last_dates            \n",
    "        ])\n",
    "        idx = pd.Index(np.repeat(self.uids, h), name='unique_id')\n",
    "        return pd.DataFrame({'ds': dates, **fcsts}, index=idx)\n",
    "        \n",
    "    def _sequential_forecast(self, h):\n",
    "        fcsts = {}\n",
    "        logger.info('Computing forecasts')\n",
    "        for model_args in self.models:\n",
    "            model, *args = _as_tuple(model_args)\n",
    "            model_name = _build_forecast_name(model, *args)\n",
    "            fcsts[model_name] = self.ga.compute_forecasts(h, model, *args)\n",
    "            logger.info(f'Computed forecasts for {model_name}.')\n",
    "        return fcsts\n",
    "    \n",
    "    def _data_parallel_forecast(self, h):\n",
    "        fcsts = {}\n",
    "        logger.info('Computing forecasts')\n",
    "        gas = self.ga.split(self.n_jobs)\n",
    "        with ProcessPoolExecutor(self.n_jobs) as executor:\n",
    "            for model_args in self.models:\n",
    "                model, *args = _as_tuple(model_args)\n",
    "                model_name = _build_forecast_name(model, *args)\n",
    "                futures = []\n",
    "                for ga in gas:\n",
    "                    future = executor.submit(ga.compute_forecasts, h, model, *args)\n",
    "                    futures.append(future)\n",
    "                fcsts[model_name] = np.hstack([f.result() for f in futures])\n",
    "                logger.info(f'Computed forecasts for {model_name}.')\n",
    "        return fcsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    series,\n",
    "    [adida, (ses, 0.1), (ses, 0.2), (ses, 0.3), historic_average, croston_classic],\n",
    "    freq='D',\n",
    ")\n",
    "%time res1 = fcst.forecast(14)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee505b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    series,\n",
    "    [adida, (ses, 0.1), (ses, 0.2), (ses, 0.3), historic_average, croston_classic],\n",
    "    freq='D',\n",
    "    n_jobs=2,\n",
    ")\n",
    "%time res2 = fcst.forecast(14)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa265e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(res1, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0032ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test monthly data\n",
    "series = generate_series(10_000, freq='M', min_length=10, max_length=20, equal_ends=True)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad18918",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    series,\n",
    "    [adida, (ses, 0.1), (ses, 0.2), (ses, 0.3), historic_average, croston_classic],\n",
    "    freq='M',\n",
    ")\n",
    "%time res1 = fcst.forecast(4)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    series,\n",
    "    [adida, (ses, 0.1), (ses, 0.2), (ses, 0.3), historic_average, croston_classic],\n",
    "    freq='M',\n",
    "    n_jobs=2,\n",
    ")\n",
    "%time res2 = fcst.forecast(4)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650df0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(res1, res2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
