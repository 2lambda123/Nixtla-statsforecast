{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp distributed.fugue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15392f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa25a4",
   "metadata": {},
   "source": [
    "# FugueBackend\n",
    "\n",
    "> The computational efficiency of `StatsForecast` can be tracked to its two core components:<br>1. Its `models` written in NumBa that optimizes Python code to reach C speeds.<br>2. Its `core.StatsForecast` class that enables distributed computing.<br><br>Here we use [Fugue](https://github.com/fugue-project/fugue) which is a unified interface for `Dask` and `Spark`.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06732b96-bd80-4a4d-b9a2-4f95c7a82331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fugue import transform, DataFrame, FugueWorkflow, ExecutionEngine\n",
    "from fugue.collections.yielded import Yielded\n",
    "from fugue.constants import FUGUE_CONF_WORKFLOW_EXCEPTION_INJECT\n",
    "from statsforecast.core import _StatsForecast, ParallelBackend, make_backend\n",
    "from triad import Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a14ea-b3e7-466c-bd38-ab94ebbd279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _cotransform(\n",
    "    df1: Any,\n",
    "    df2: Any,\n",
    "    using: Any,\n",
    "    schema: Any = None,\n",
    "    params: Any = None,\n",
    "    partition: Any = None,\n",
    "    engine: Any = None,\n",
    "    engine_conf: Any = None,\n",
    "    force_output_fugue_dataframe: bool = False,\n",
    "    as_local: bool = False,\n",
    ") -> Any:\n",
    "    dag = FugueWorkflow(compile_conf={FUGUE_CONF_WORKFLOW_EXCEPTION_INJECT: 0})\n",
    "    \n",
    "    src = dag.create_data(df1).zip(dag.create_data(df2), partition=partition)\n",
    "    tdf = src.transform(\n",
    "        using=using,\n",
    "        schema=schema,\n",
    "        params=params,\n",
    "        pre_partition=partition,\n",
    "    )\n",
    "    tdf.yield_dataframe_as(\"result\", as_local=as_local)\n",
    "    dag.run(engine, conf=engine_conf)\n",
    "    result = dag.yields[\"result\"].result  # type:ignore\n",
    "    if force_output_fugue_dataframe or isinstance(df1, (DataFrame, Yielded)):\n",
    "        return result\n",
    "    return result.as_pandas() if result.is_local else result.native  # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d5b82-2be9-41f5-8cd0-3903d0761e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FugueBackend(ParallelBackend):\n",
    "    \"\"\"FugueBackend for Distributed Computation.\n",
    "    [Source code](https://github.com/Nixtla/statsforecast/blob/main/statsforecast/distributed/fugue.py).\n",
    "\n",
    "    This class uses [Fugue](https://github.com/fugue-project/fugue) backend capable of distributing \n",
    "    computation on Spark and Dask without any rewrites.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `engine`: fugue.ExecutionEngine, a selection between spark and dask.<br>\n",
    "    `conf`: fugue.Config, engine configuration.<br>\n",
    "    `**transform_kwargs`: additional kwargs for Fugue's transform method.<br>\n",
    "\n",
    "    **Notes:**<br>\n",
    "    A short introduction to Fugue, with examples on how to scale pandas code to scale pandas \n",
    "    based code to Spark or Dask is available [here](https://fugue-tutorials.readthedocs.io/tutorials/quick_look/ten_minutes.html).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            engine: Any = None,\n",
    "            conf: Any = None,\n",
    "            **transform_kwargs: Any\n",
    "        ):        \n",
    "        self._engine = engine\n",
    "        self._conf = conf\n",
    "        self._transform_kwargs = dict(transform_kwargs)\n",
    "\n",
    "    def __getstate__(self) -> Dict[str, Any]:\n",
    "        return {}\n",
    "\n",
    "    def forecast(\n",
    "            self, \n",
    "            df,\n",
    "            models,\n",
    "            freq,\n",
    "            fallback_model = None,\n",
    "            X_df = None,\n",
    "            **kwargs: Any,\n",
    "        ) -> Any:\n",
    "        \"\"\"Memory Efficient core.StatsForecast predictions with FugueBackend.\n",
    "\n",
    "        This method uses Fugue's transform function, in combination with \n",
    "        `core.StatsForecast`'s forecast to efficiently fit a list of StatsForecast models.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `df`: pandas.DataFrame, with columns [`unique_id`, `ds`, `y`] and exogenous.<br>\n",
    "        `freq`: str, frequency of the data, [panda's available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).<br>\n",
    "        `models`: List[typing.Any], list of instantiated objects `StatsForecast.models`.<br>\n",
    "        `fallback_model`: Any, Model to be used if a model fails.<br>\n",
    "        `X_df`: pandas.DataFrame, with [unique_id, ds] columns and dfâ€™s future exogenous.\n",
    "        `**kwargs`: Additional `core.StatsForecast` parameters. Example forecast horizon `h`.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `fcsts_df`: pandas.DataFrame, with `models` columns for point predictions and probabilistic\n",
    "        predictions for all fitted `models`.<br>\n",
    "        \n",
    "        **References:**<br>\n",
    "        For more information check the \n",
    "        [Fugue's transform](https://fugue-tutorials.readthedocs.io/tutorials/beginner/introduction.html#fugue-transform)\n",
    "        tutorial.<br>\n",
    "        The [core.StatsForecast's forecast](https://nixtla.github.io/statsforecast/core.html#statsforecast.forecast)\n",
    "        method documentation.<br>\n",
    "        Or the list of available [StatsForecast's models](https://nixtla.github.io/statsforecast/models.html).\n",
    "        \"\"\"\n",
    "        schema = \"*-y+\" + str(self._get_output_schema(models))\n",
    "        if X_df is None:\n",
    "            return transform(\n",
    "                df,\n",
    "                self._forecast_series,\n",
    "                params=dict(models=models, freq=freq, \n",
    "                            kwargs=kwargs, fallback_model=fallback_model),\n",
    "                schema=schema,\n",
    "                partition={\"by\": \"unique_id\"},\n",
    "                engine=self._engine,\n",
    "                engine_conf=self._conf,\n",
    "                **self._transform_kwargs,\n",
    "            )\n",
    "        else:\n",
    "            schema = \"unique_id:str,ds:str,\" + str(self._get_output_schema(models))\n",
    "            return _cotransform(\n",
    "                df,\n",
    "                X_df,\n",
    "                self._forecast_series_X,\n",
    "                params=dict(models=models, freq=freq, \n",
    "                            kwargs=kwargs, fallback_model=fallback_model),\n",
    "                schema=schema,\n",
    "                partition={\"by\": \"unique_id\"},\n",
    "                engine=self._engine,\n",
    "                engine_conf=self._conf,\n",
    "                **self._transform_kwargs,\n",
    "            )\n",
    "            \n",
    "\n",
    "    def cross_validation(\n",
    "            self, \n",
    "            df,\n",
    "            models,\n",
    "            freq,\n",
    "            fallback_model=None,\n",
    "            **kwargs: Any, \n",
    "        ) -> Any:\n",
    "        \"\"\"Temporal Cross-Validation with core.StatsForecast and FugueBackend.\n",
    "\n",
    "        This method uses Fugue's transform function, in combination with \n",
    "        `core.StatsForecast`'s cross-validation to efficiently fit a list of StatsForecast \n",
    "        models through multiple training windows, in either chained or rolled manner.\n",
    "\n",
    "        `StatsForecast.models`' speed along with Fugue's distributed computation allow to \n",
    "        overcome this evaluation technique high computational costs. Temporal cross-validation \n",
    "        provides better model's generalization measurements by increasing the test's length \n",
    "        and diversity.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `df`: pandas.DataFrame, with columns [`unique_id`, `ds`, `y`] and exogenous.<br>\n",
    "        `freq`: str, frequency of the data, [panda's available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).<br>\n",
    "        `models`: List[typing.Any], list of instantiated objects `StatsForecast.models`.<br>\n",
    "        `fallback_model`: Any, Model to be used if a model fails.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `fcsts_df`: pandas.DataFrame, with `models` columns for point predictions and probabilistic\n",
    "        predictions for all fitted `models`.<br>\n",
    "        \n",
    "        **References:**<br>\n",
    "        The [core.StatsForecast's cross validation](https://nixtla.github.io/statsforecast/core.html#statsforecast.cross_validation)\n",
    "        method documentation.<br>\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Temporal Cross-Validation\"](https://otexts.com/fpp3/tscv.html).\n",
    "        \"\"\"\n",
    "        schema = \"*-y+\" + str(self._get_output_schema(models, mode=\"cv\"))\n",
    "        return transform(\n",
    "            df,\n",
    "            self._cv,\n",
    "            params=dict(models=models, freq=freq, \n",
    "                        kwargs=kwargs, \n",
    "                        fallback_model=fallback_model),\n",
    "            schema=schema,\n",
    "            partition={\"by\": \"unique_id\"},\n",
    "            engine=self._engine,\n",
    "            engine_conf=self._conf,\n",
    "            **self._transform_kwargs,\n",
    "        )\n",
    "\n",
    "    def _forecast_series(self, df: pd.DataFrame, models, freq, fallback_model, kwargs) -> pd.DataFrame:\n",
    "        model = _StatsForecast(df=df, models=models, freq=freq, \n",
    "                               fallback_model=fallback_model, n_jobs=1)\n",
    "        return model.forecast(**kwargs).reset_index()\n",
    "    \n",
    "    # schema: unique_id:str, ds:str, *\n",
    "    def _forecast_series_X(self, df: pd.DataFrame, X_df: pd.DataFrame, models, freq, fallback_model, kwargs) -> pd.DataFrame:\n",
    "        model = _StatsForecast(df=df, models=models, freq=freq, \n",
    "                               fallback_model=fallback_model, n_jobs=1)\n",
    "        if len(X_df) != kwargs['h']:\n",
    "            raise Exception(\n",
    "                'Please be sure that your exogenous variables `X_df` '\n",
    "                'have the same length than your forecast horizon `h`'\n",
    "            )\n",
    "        return model.forecast(X_df=X_df, **kwargs).reset_index()\n",
    "\n",
    "    def _cv(self, df: pd.DataFrame, models, freq, fallback_model, kwargs) -> pd.DataFrame:\n",
    "        model = _StatsForecast(df=df, models=models, freq=freq, \n",
    "                               fallback_model=fallback_model, n_jobs=1)\n",
    "        return model.cross_validation(**kwargs).reset_index()\n",
    "\n",
    "    def _get_output_schema(self, models, mode=\"forecast\") -> Schema:\n",
    "        cols: List[Any]\n",
    "        cols = [(repr(model), np.float32) for model in models]\n",
    "        if mode == \"cv\":\n",
    "            cols = [(\"cutoff\", \"datetime\"), (\"y\", np.float32)] + cols\n",
    "        return Schema(cols)\n",
    "    \n",
    "\n",
    "@make_backend.candidate(lambda obj, *args, **kwargs: isinstance(obj, ExecutionEngine))\n",
    "def _make_fugue_backend(obj:ExecutionEngine, *args, **kwargs) -> ParallelBackend:\n",
    "    print(\"make fugue\")\n",
    "    return FugueBackend(obj, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53913de1-81b9-401c-93a2-83e42047e471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/statsforecast/blob/main/statsforecast/distributed/fugue.py#L47){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FugueBackend\n",
       "\n",
       ">      FugueBackend (engine:Any=None, conf:Any=None, **transform_kwargs:Any)\n",
       "\n",
       "FugueBackend for Distributed Computation.\n",
       "[Source code](https://github.com/Nixtla/statsforecast/blob/main/statsforecast/distributed/fugue.py).\n",
       "\n",
       "This class uses [Fugue](https://github.com/fugue-project/fugue) backend capable of distributing \n",
       "computation on Spark and Dask without any rewrites.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`engine`: fugue.ExecutionEngine, a selection between spark and dask.<br>\n",
       "`conf`: fugue.Config, engine configuration.<br>\n",
       "`**transform_kwargs`: additional kwargs for Fugue's transform method.<br>\n",
       "\n",
       "**Notes:**<br>\n",
       "A short introduction to Fugue, with examples on how to scale pandas code to scale pandas \n",
       "based code to Spark or Dask is available [here](https://fugue-tutorials.readthedocs.io/tutorials/quick_look/ten_minutes.html)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/statsforecast/blob/main/statsforecast/distributed/fugue.py#L47){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FugueBackend\n",
       "\n",
       ">      FugueBackend (engine:Any=None, conf:Any=None, **transform_kwargs:Any)\n",
       "\n",
       "FugueBackend for Distributed Computation.\n",
       "[Source code](https://github.com/Nixtla/statsforecast/blob/main/statsforecast/distributed/fugue.py).\n",
       "\n",
       "This class uses [Fugue](https://github.com/fugue-project/fugue) backend capable of distributing \n",
       "computation on Spark and Dask without any rewrites.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`engine`: fugue.ExecutionEngine, a selection between spark and dask.<br>\n",
       "`conf`: fugue.Config, engine configuration.<br>\n",
       "`**transform_kwargs`: additional kwargs for Fugue's transform method.<br>\n",
       "\n",
       "**Notes:**<br>\n",
       "A short introduction to Fugue, with examples on how to scale pandas code to scale pandas \n",
       "based code to Spark or Dask is available [here](https://fugue-tutorials.readthedocs.io/tutorials/quick_look/ten_minutes.html)."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(FugueBackend, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037f72d-4ace-44e8-b4d5-b8399d5e294d",
   "metadata": {},
   "source": [
    "## Dask Distributed Predictions\n",
    "\n",
    "Here we provide an example for the distribution of the `StatsForecast` predictions using `Fugue` to execute the code in a Dask cluster.\n",
    "\n",
    "To do it we instantiate the `FugueBackend` class with a `DaskExecutionEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df29ce-c1ac-44d9-829e-47096adf2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from fugue_dask import DaskExecutionEngine\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series\n",
    "\n",
    "# Generate Synthetic Panel Data\n",
    "df = generate_series(10).reset_index()\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = dd.from_pandas(df, npartitions=10)\n",
    "\n",
    "# Instantiate FugueBackend with DaskExecutionEngine\n",
    "dask_client = Client()\n",
    "engine = DaskExecutionEngine(dask_client=dask_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832937cc-2b7b-4ddc-84d0-e68a650bdc12",
   "metadata": {},
   "source": [
    "We have simply create the class to the usual `StatsForecast` instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08c1f2-3b0a-460f-a1a6-1d25d982104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "sf = StatsForecast(models=[Naive()], freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a44ec-787f-4ef7-8129-71409d2dd32a",
   "metadata": {},
   "source": [
    "### Distributed Forecast\n",
    "\n",
    "For extremely fast distributed predictions we use FugueBackend as backend that operates like the original [StatsForecast.forecast](https://nixtla.github.io/statsforecast/core.html#statsforecast.forecast) method.\n",
    "\n",
    "It receives as input a pandas.DataFrame with columns [`unique_id`,`ds`,`y`] and exogenous, where the `ds` (datestamp) column should be of a format expected by Pandas. The `y` column must be numeric, and represents the measurement we wish to forecast. And the `unique_id` uniquely identifies the series in the panel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2454a-7683-40d1-8828-877dba0345fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make fugue\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>Naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-09-02</td>\n",
       "      <td>1.076548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-09-03</td>\n",
       "      <td>1.076548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-09-04</td>\n",
       "      <td>1.076548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-09-05</td>\n",
       "      <td>1.076548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>1.076548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-14</td>\n",
       "      <td>3.150799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-15</td>\n",
       "      <td>3.150799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-16</td>\n",
       "      <td>3.150799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-17</td>\n",
       "      <td>3.150799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-18</td>\n",
       "      <td>3.150799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds     Naive\n",
       "0          6 2000-09-02  1.076548\n",
       "1          6 2000-09-03  1.076548\n",
       "2          6 2000-09-04  1.076548\n",
       "3          6 2000-09-05  1.076548\n",
       "4          6 2000-09-06  1.076548\n",
       "..       ...        ...       ...\n",
       "7          1 2000-04-14  3.150799\n",
       "8          1 2000-04-15  3.150799\n",
       "9          1 2000-04-16  3.150799\n",
       "10         1 2000-04-17  3.150799\n",
       "11         1 2000-04-18  3.150799\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Distributed predictions with FugueBackend.\n",
    "sf.forecast(df=df, h=12).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e7b42-8129-472a-99fd-0725ae4cb8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make fugue\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "sf = StatsForecast(models=[Naive()], freq='D', fallback_model=Naive())\n",
    "dask_fcst = sf.forecast(df=df, h=12).compute()\n",
    "fcst_stats = sf.forecast(df=df.compute(), h=12)\n",
    "test_eq(dask_fcst.sort_values(by=['unique_id', 'ds']).reset_index(drop=True), \n",
    "        fcst_stats.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964caa9d-d580-44a7-9115-2522e9b64ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "class ReturnX:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, y, X):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, h, X):\n",
    "        mean = X\n",
    "        return X\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'ReturnX'\n",
    "    \n",
    "    def forecast(self, y, h, X=None, X_future=None, fitted=False):\n",
    "        return {'mean': X_future.flatten()}\n",
    "    \n",
    "    def new(self):\n",
    "        b = type(self).__new__(type(self))\n",
    "        b.__dict__.update(self.__dict__)\n",
    "        return b\n",
    "    \n",
    "df_w_ex = pd.DataFrame(\n",
    "    {\n",
    "        'ds': np.hstack([np.arange(10), np.arange(10)]),\n",
    "        'y': np.random.rand(20),\n",
    "        'x': np.arange(20, dtype=np.float32),\n",
    "    },\n",
    "    index=pd.Index([0] * 10 + [1] * 10, name='unique_id'),\n",
    ").reset_index()\n",
    "train_mask = df_w_ex['ds'] < 6\n",
    "train_df = dd.from_pandas(df_w_ex[train_mask], npartitions=10)\n",
    "test_df = df_w_ex[~train_mask]\n",
    "xreg = dd.from_pandas(test_df.drop(columns='y').reset_index(drop=True), npartitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee084bc4-7303-4dd6-99df-5a23fa7cb419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make fugue\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "fcst_x = StatsForecast(models=[ReturnX()], freq='D')\n",
    "res = fcst_x.forecast(df=train_df, \n",
    "                      X_df=xreg, \n",
    "                      h=4).compute()\n",
    "expected_res = xreg.rename(columns={'x': 'ReturnX'}).compute()\n",
    "# we expect strings for unique_id, and ds using exogenous\n",
    "expected_res[['unique_id', 'ds']] = expected_res[['unique_id', 'ds']].astype(str)\n",
    "pd.testing.assert_frame_equal(res.sort_values('unique_id').reset_index(drop=True), \n",
    "                              expected_res, \n",
    "                              check_dtype=False, \n",
    "                              check_index_type=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4f3de-910d-46eb-842b-579935cfbd10",
   "metadata": {},
   "source": [
    "### Distributed Cross-Validation\n",
    "\n",
    "For extremely fast distributed temporcal cross-validation we use `cross_validation` method that operates like the original [StatsForecast.cross_validation](https://nixtla.github.io/statsforecast/core.html#statsforecast) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d0a2f-8f3b-45cd-9f25-d8db281db3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make fugue\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "      <th>Naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-08-20</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>3.400908</td>\n",
       "      <td>2.336505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-08-21</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>4.092657</td>\n",
       "      <td>2.336505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-08-22</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>5.207562</td>\n",
       "      <td>2.336505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-08-23</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>6.259993</td>\n",
       "      <td>2.336505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-08-24</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>0.225904</td>\n",
       "      <td>2.336505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-02</td>\n",
       "      <td>2000-03-25</td>\n",
       "      <td>6.363522</td>\n",
       "      <td>5.073473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>2000-03-25</td>\n",
       "      <td>0.135164</td>\n",
       "      <td>5.073473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-04</td>\n",
       "      <td>2000-03-25</td>\n",
       "      <td>1.065741</td>\n",
       "      <td>5.073473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-05</td>\n",
       "      <td>2000-03-25</td>\n",
       "      <td>2.027687</td>\n",
       "      <td>5.073473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-06</td>\n",
       "      <td>2000-03-25</td>\n",
       "      <td>3.150799</td>\n",
       "      <td>5.073473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds     cutoff         y     Naive\n",
       "0          6 2000-08-20 2000-08-19  3.400908  2.336505\n",
       "1          6 2000-08-21 2000-08-19  4.092657  2.336505\n",
       "2          6 2000-08-22 2000-08-19  5.207562  2.336505\n",
       "3          6 2000-08-23 2000-08-19  6.259993  2.336505\n",
       "4          6 2000-08-24 2000-08-19  0.225904  2.336505\n",
       "..       ...        ...        ...       ...       ...\n",
       "19         1 2000-04-02 2000-03-25  6.363522  5.073473\n",
       "20         1 2000-04-03 2000-03-25  0.135164  5.073473\n",
       "21         1 2000-04-04 2000-03-25  1.065741  5.073473\n",
       "22         1 2000-04-05 2000-03-25  2.027687  5.073473\n",
       "23         1 2000-04-06 2000-03-25  3.150799  5.073473\n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Distributed cross-validation with FugueBackend.\n",
    "fcst.cross_validation(df=df, h=12, n_windows=2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95e09b-cb70-4232-8ffa-b26fc8aea557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make fugue\n",
      "make fugue\n",
      "make fugue\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series\n",
    "\n",
    "# Generate Synthetic Panel Data.\n",
    "df = generate_series(10).reset_index()\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = dd.from_pandas(df, npartitions=10)\n",
    "\n",
    "# Distribute predictions.\n",
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = sf.forecast(df=df, h=12).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "fcst_stats = sf.forecast(df=df.compute(), h=12)\n",
    "test_eq(fcst_fugue, fcst_stats.reset_index())\n",
    "\n",
    "# Distribute cross-validation predictions.\n",
    "fcst = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = fcst.cross_validation(df=df, h=12).compute().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = StatsForecast(models=[Naive()], freq='D').cross_validation(df=df.compute(), h=12)\n",
    "test_eq(fcst_fugue, fcst_stats.reset_index())\n",
    "\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "    \n",
    "#cross validation fallback model\n",
    "fcst = StatsForecast(models=[FailNaive()], freq='D', fallback_model=Naive())\n",
    "fcst_fugue = fcst.cross_validation(df=df, h=12).compute().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = StatsForecast(models=[Naive()], freq='D').cross_validation(df=df.compute(), h=12)\n",
    "test_eq(fcst_fugue, fcst_stats.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1084e8-c722-48d5-a038-8d7e530773bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repartition: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 443.16it/s]\n",
      "_0 _State.RUNNING -> _State.FAILED  Dataset(num_blocks=2, num_rows=2376, schema={unique_id: object, ds: datetime64[ns], y: float64}) cannot convert to a LocalDataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make fugue\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Dataset(num_blocks=2, num_rows=2376, schema={unique_id: object, ds: datetime64[ns], y: float64}) cannot convert to a LocalDataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Distribute predictions.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m sf \u001b[38;5;241m=\u001b[39m StatsForecast(models\u001b[38;5;241m=\u001b[39m[Naive()], freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m fcst_fugue \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas()\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m fcst_stats \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mforecast(df\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mcompute(), h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m     17\u001b[0m test_eq(fcst_fugue, fcst_stats\u001b[38;5;241m.\u001b[39mreset_index())\n",
      "File \u001b[0;32m~/projects/statsforecast/statsforecast/core.py:1492\u001b[0m, in \u001b[0;36mStatsForecast.forecast\u001b[0;34m(self, h, df, X_df, level, fitted, sort_df)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fa\u001b[38;5;241m.\u001b[39mengine_context(infer_by\u001b[38;5;241m=\u001b[39m[df]) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1491\u001b[0m     backend \u001b[38;5;241m=\u001b[39m make_backend(e)\n\u001b[0;32m-> 1492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfallback_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfallback_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfitted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfitted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 67\u001b[0m, in \u001b[0;36mFugueBackend.forecast\u001b[0;34m(self, df, models, freq, fallback_model, X_df, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*-y+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_schema(models))\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forecast_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfallback_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfallback_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mby\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munique_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_conf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_id:str,ds:str,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_schema(models))\n",
      "File \u001b[0;32m~/miniconda3/envs/statsforecast/lib/python3.9/site-packages/fugue/workflow/api.py:174\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(df, using, schema, params, partition, callback, ignore_errors, persist, as_local, save_path, checkpoint, engine, engine_conf, as_fugue)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m         tdf\u001b[38;5;241m.\u001b[39msave(save_path, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 174\u001b[0m \u001b[43mdag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_execution_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint:\n\u001b[1;32m    176\u001b[0m     result \u001b[38;5;241m=\u001b[39m dag\u001b[38;5;241m.\u001b[39myields[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mresult  \u001b[38;5;66;03m# type:ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/statsforecast/lib/python3.9/site-packages/fugue/workflow/workflow.py:1598\u001b[0m, in \u001b[0;36mFugueWorkflow.run\u001b[0;34m(self, engine, conf, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m ctb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1597\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1598\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(ctb)\n\u001b[1;32m   1599\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FugueWorkflowResult(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myields)\n",
      "File \u001b[0;32m~/miniconda3/envs/statsforecast/lib/python3.9/site-packages/fugue/dataframe/utils.py:145\u001b[0m, in \u001b[0;36mto_local_df\u001b[0;34m(df, schema)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, Iterable):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IterableDataFrame(df, schema)\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot convert to a LocalDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Dataset(num_blocks=2, num_rows=2376, schema={unique_id: object, ds: datetime64[ns], y: float64}) cannot convert to a LocalDataFrame"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-02 16:03:32,855 E 89052 2492632] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-02_15-59-46_292230_88143 is over 95% full, available space: 399159296; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-02 16:03:42,953 E 89052 2492632] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-02_15-59-46_292230_88143 is over 95% full, available space: 399056896; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-02 16:03:53,053 E 89052 2492632] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-02_15-59-46_292230_88143 is over 95% full, available space: 666705920; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-02 16:04:03,147 E 89052 2492632] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-02_15-59-46_292230_88143 is over 95% full, available space: 664178688; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-02 16:04:13,151 E 89052 2492632] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-02_15-59-46_292230_88143 is over 95% full, available space: 663838720; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# test ray integration\n",
    "import ray\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series\n",
    "\n",
    "# Generate Synthetic Panel Data.\n",
    "df = generate_series(10).reset_index()\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = ray.data.from_pandas(df).repartition(2)\n",
    "\n",
    "# Distribute predictions.\n",
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = sf.forecast(df=df, h=12).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "fcst_stats = sf.forecast(df=df.compute(), h=12)\n",
    "test_eq(fcst_fugue, fcst_stats.reset_index())\n",
    "\n",
    "# Distribute cross-validation predictions.\n",
    "fcst = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = fcst.cross_validation(df=df, h=12).compute().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = StatsForecast(models=[Naive()], freq='D').cross_validation(df=df.compute(), h=12)\n",
    "test_eq(fcst_fugue, fcst_stats.reset_index())\n",
    "\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "    \n",
    "#cross validation fallback model\n",
    "fcst = StatsForecast(models=[FailNaive()], freq='D', fallback_model=Naive())\n",
    "fcst_fugue = fcst.cross_validation(df=df, h=12).compute().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = StatsForecast(models=[Naive()], freq='D').cross_validation(df=df.compute(), h=12)\n",
    "test_eq(fcst_fugue, fcst_stats.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628146a-57b0-4b4b-8377-045b08dd2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "fcst_x = StatsForecast(models=[ReturnX()], freq='D', backend=backend)\n",
    "res = fcst_x.forecast(df=train_df, \n",
    "                      X_df=xreg, \n",
    "                      h=4)\n",
    "expected_res = xreg.rename(columns={'x': 'ReturnX'})\n",
    "pd.testing.assert_frame_equal(res.sort_values('unique_id').reset_index(drop=True), \n",
    "                              expected_res, \n",
    "                              check_dtype=False, \n",
    "                              check_index_type=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
