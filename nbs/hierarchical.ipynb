{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dba3df0-5f5f-4645-80cf-acb6f2ff7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp hierarchical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1045633d-6ddd-4e98-a316-b07d333206a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6faac6-8bf6-4173-8ca8-3acd39e3d4d4",
   "metadata": {},
   "source": [
    "# Hierarchical Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f252aa-88e4-41f2-93eb-ccf0eeac9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c06e3b-5315-4fcf-8642-618e2970a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c915637b-ae73-4f2c-ae4b-8b3b05b30536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from statsforecast.core import StatsForecast, _as_tuple, _build_forecast_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8988c8a9-f9a6-4a54-b058-6744db1b72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _to_summing_matrix(df: pd.DataFrame):\n",
    "    \"\"\"Transforms the bottom DataFrame `df` to a summing matrix S.\"\"\"\n",
    "    categories = [df[col].unique() for col in df.columns]\n",
    "    S = OneHotEncoder(categories=categories, sparse=False, dtype=np.float32).fit_transform(df).T\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2422c143-7ffe-45ec-84c4-b53ea0badb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _aggregate_key(df: pd.DataFrame, keys: List[List[str]], agg_fn: Callable = np.sum):\n",
    "    \"\"\"Aggregates `df` according to `keys` using `agg_fn`.\"\"\"\n",
    "    max_len_idx = np.argmax([len(key) for key in keys])\n",
    "    bottom_comb = keys[max_len_idx]\n",
    "    orig_cols = df.drop(labels=['ds', 'y'], axis=1).columns.to_list()\n",
    "    df_keys = []\n",
    "    for key in keys:\n",
    "        df_key = df.groupby(key + ['ds'])['y'].apply(agg_fn).reset_index()\n",
    "        df_key['unique_id'] = df_key[key].agg('_'.join, axis=1)\n",
    "        if key == bottom_comb:\n",
    "            bottom_keys = df_key['unique_id'].unique()\n",
    "        df_keys.append(df_key)\n",
    "    df_keys = pd.concat(df_keys)\n",
    "    S_df = df_keys[['unique_id'] + bottom_comb].drop_duplicates().reset_index(drop=True)\n",
    "    S_df = S_df.set_index('unique_id')\n",
    "    S_df = S_df.fillna('agg')\n",
    "    keys_cols = []\n",
    "    for key in keys:\n",
    "        key_col = '_'.join(key) \n",
    "        S_df[key_col] = S_df[key].agg('_'.join, axis=1)\n",
    "        keys_cols.append(key_col)\n",
    "    y_df = df_keys[['unique_id', 'ds', 'y']].set_index('unique_id')\n",
    "    #S definition\n",
    "    S = _to_summing_matrix(S_df.loc[bottom_keys, keys_cols])\n",
    "    return S_df[keys_cols], S, bottom_keys, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "17e32eb4-b464-4023-a6f1-a84aa6a7e61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "hiers_grouped = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]\n",
    "S_df, S, bottom_keys, y_df = _aggregate_key(df, hiers_grouped)\n",
    "test_eq(len(y_df), 34_000)\n",
    "test_eq(y_df.index.nunique(), 425)\n",
    "test_eq(S.shape, (425, 304))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ec40e78-2669-4cdb-be2a-f0b266fd07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "hiers = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'State', 'Region']\n",
    "]\n",
    "S_df, S, bottom_keys, y_df = _aggregate_key(df, hiers)\n",
    "test_eq(len(y_df), 6_800)\n",
    "test_eq(y_df.index.nunique(), 85)\n",
    "test_eq(S.shape, (85, 76))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "80046463-27ee-4305-b55e-4bd50a356d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reconcile(S: np.ndarray, P: np.ndarray, W: np.ndarray, \n",
    "               y_hat: np.ndarray, SP: np.ndarray = None):\n",
    "    if SP is None:\n",
    "        SP = S @ P\n",
    "    return np.matmul(SP, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "80b6901b-4710-4757-b94a-2ad2599b261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bottom_up(S: np.ndarray, y_hat: np.ndarray):\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    P = np.eye(n_bottom, n_hiers, k=(n_hiers - n_bottom), dtype=np.float32)\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cd48d95c-150c-450a-b3d5-af6476807aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def top_down(S: np.ndarray, y_hat: np.ndarray, hfcst: HierarchicalStatsForecast,\n",
    "             bottom_keys: np.ndarray, method: str):\n",
    "    idx_top = int(S.sum(axis=1).argmax())\n",
    "    idx_btm, = np.where(S.sum(axis=1) == 1.)\n",
    "    \n",
    "    n_hiers, n_bottom = S.shape\n",
    "    if len(idx_btm) != n_bottom + 1:\n",
    "        raise Exception('Top down reconciliation requires strictly hierarchical structures.')\n",
    "    \n",
    "    if method == 'forecast_proportions':\n",
    "        raise NotImplementedError(f'Method {method} not implemented yet')\n",
    "    else:\n",
    "        y_top = hfcst.fcst.ga[idx_top]\n",
    "        y_btm = np.hstack(hfcst.fcst.ga[int(idx)] for idx in idx_btm)\n",
    "        print(y_top.shape, y_btm.shape)\n",
    "        if method == 'average_proportions':\n",
    "            prop = np.mean(y_btm / y_top, axis=0)\n",
    "            print(prop.shape)\n",
    "        elif method == 'proportion_averages':\n",
    "            ...\n",
    "        else:\n",
    "            raise Exception(f'Unknown method {method}')\n",
    "    P = np.zeros_like(S).T\n",
    "    P[:, idx_top] = prop\n",
    "    print(P.shape)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a379be76-6f41-4316-9fa6-7689bfc63c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3ff1db87-f749-437f-a4df-ead2080c9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def min_trace(S: np.ndarray, y_hat: np.ndarray, method: str):\n",
    "    n_hiers, n_bottom = S.shape\n",
    "    if method == 'ols':\n",
    "        # this should be modified once we have residuals\n",
    "        W = np.eye(n_hiers)\n",
    "    elif method == 'wls_struct':\n",
    "        W = np.diag(S @ np.ones((n_bottom,)))\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "    \n",
    "    eigenvalues, _ = np.linalg.eig(W)\n",
    "    if any(eigenvalues < 1e-8):\n",
    "        raise Exception('min_trace needs covariance matrix to be positive definite.')\n",
    "        \n",
    "    R = S.T @ np.linalg.inv(W)\n",
    "    P = np.linalg.inv(R @ S) @ R\n",
    "    \n",
    "    return _reconcile(S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d938b6ae-1d8a-4c88-a152-6f2541a6217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HierarchicalStatsForecast:\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, keys: List[List[str]], \n",
    "                 models: List, \n",
    "                 reconcile_fns: List[Callable],\n",
    "                 freq: str,\n",
    "                 n_jobs: int = 1, ray_address: Optional[str] = None):\n",
    "        self.reconcile_fns = reconcile_fns\n",
    "        self.S_df, self.S, _,  y_df = _aggregate_key(df, keys=keys)\n",
    "        self.fcst = StatsForecast(df=y_df, models=models, freq=freq, \n",
    "                                  n_jobs=n_jobs, ray_address=ray_address,\n",
    "                                  sort_df=False)\n",
    "    \n",
    "    def forecast(self, h: int,\n",
    "                 xreg: Optional[pd.DataFrame] = None, \n",
    "                 level: Optional[Tuple] = None):\n",
    "        fcsts = self.fcst.forecast(h=h, xreg=xreg, level=level)\n",
    "        model_names = fcsts.drop(columns=['ds'], axis=1).columns.to_list()\n",
    "        for model_name in model_names:\n",
    "            fcsts_model = fcsts[model_name].values.reshape(-1, h)\n",
    "            for reconcile_fn_args in self.reconcile_fns:\n",
    "                reconcile_fn, *args = _as_tuple(reconcile_fn_args)\n",
    "                reconcile_fn_name = _build_forecast_name(reconcile_fn, *args, idx_remove=2)\n",
    "                fcsts_model = reconcile_fn(self.S, fcsts_model, *args)\n",
    "                fcsts[f'{reconcile_fn_name}_{model_name}'] = fcsts_model.flatten()\n",
    "        return fcsts\n",
    "    \n",
    "    def cross_validation(self, h: int, test_size: int, \n",
    "                         input_size: Optional[int] = None):\n",
    "        fcsts = self.fcst.cross_validation(h=h, test_size=test_size, input_size=input_size)\n",
    "        model_names = fcsts.drop(columns=['ds', 'cutoff', 'y'], axis=1).columns.to_list()\n",
    "        cutoffs = fcsts['cutoff'].unique()\n",
    "        for model_name in model_names:\n",
    "            for cutoff in cutoffs:\n",
    "                cutoff_idx = fcsts['cutoff'] == cutoff\n",
    "                fcsts_model = fcsts.loc[cutoff_idx, model_name].values.reshape(-1, h)\n",
    "                for reconcile_fn_args in self.reconcile_fns:\n",
    "                    reconcile_fn, *args = _as_tuple(reconcile_fn_args)\n",
    "                    reconcile_fn_name = _build_forecast_name(reconcile_fn, *args, idx_remove=2)\n",
    "                    fcsts_model = reconcile_fn(self.S, fcsts_model, *args)\n",
    "                    fcsts.loc[cutoff_idx, f'{reconcile_fn_name}_{model_name}'] = fcsts_model.flatten()\n",
    "        return fcsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f1abe82a-6221-4b27-8990-0f547597344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from statsforecast.models import naive\n",
    "# transform ds to int\n",
    "ds_int = df[['ds']].drop_duplicates().assign(ds_int = lambda df: np.arange(len(df)) + 1)\n",
    "df = df.merge(ds_int, how='left', on=['ds']).drop('ds', axis=1)\n",
    "df = df.rename(columns={'ds_int': 'ds'})\n",
    "# hierarchical\n",
    "hier_fcst = HierarchicalStatsForecast(df, \n",
    "                                      keys=hierarchies,\n",
    "                                      models=[naive],\n",
    "                                      reconcile_fns=[bottom_up, (min_trace, 'ols'), (min_trace, 'wls_struct')],\n",
    "                                      freq='D', \n",
    "                                      n_jobs=-1)\n",
    "hier_fcsts = hier_fcst.cross_validation(12, test_size=12)\n",
    "# bottom_up with naive model should be return same forecasts\n",
    "pd.testing.assert_series_equal(hier_fcsts['naive'], hier_fcsts['bottom_up_naive'], check_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "60ef656e-0d02-4cce-a648-a9baf13d2a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive 27016.84\n",
      "bottom_up_naive 27016.777\n",
      "min_trace_method-ols_naive 27016.775500323183\n",
      "min_trace_method-wls_struct_naive 27016.775500323154\n"
     ]
    }
   ],
   "source": [
    "for model in hier_fcsts.drop(columns=['ds', 'cutoff', 'y']):\n",
    "    print(model, np.mean((hier_fcsts['y'] - hier_fcsts[model]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94c47f-a340-46bf-9ac4-f51dc900a6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
