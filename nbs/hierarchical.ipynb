{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba3df0-5f5f-4645-80cf-acb6f2ff7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045633d-6ddd-4e98-a316-b07d333206a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6faac6-8bf6-4173-8ca8-3acd39e3d4d4",
   "metadata": {},
   "source": [
    "# Hierarchical Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f252aa-88e4-41f2-93eb-ccf0eeac9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c06e3b-5315-4fcf-8642-618e2970a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915637b-ae73-4f2c-ae4b-8b3b05b30536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from statsforecast.core import StatsForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988c8a9-f9a6-4a54-b058-6744db1b72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_summing_matrix(df: pd.DataFrame):\n",
    "    \"\"\"Transforms the bottom DataFrame `df` to a S matrix.\"\"\"\n",
    "    s_mat = []\n",
    "    categories = [df[col].unique() for col in df.columns]\n",
    "    s_mat = OneHotEncoder(categories=categories, sparse=False, dtype=np.float32).fit_transform(df).T\n",
    "    return s_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2422c143-7ffe-45ec-84c4-b53ea0badb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _aggregate_key(df: pd.DataFrame, keys: List[List[str]], agg_fn: Callable = np.sum):\n",
    "    \"\"\"Aggregates `df` according to `keys` using `agg_fn`.\"\"\"\n",
    "    df = df.copy()\n",
    "    max_len_idx = np.argmax([len(key) for key in keys])\n",
    "    bottom_comb = keys[max_len_idx]\n",
    "    orig_cols = df.drop(labels=['ds', 'y'], axis=1).columns.to_list()\n",
    "    df_keys = []\n",
    "    for key in keys:\n",
    "        df_key = df.groupby(key + ['ds'])['y'].apply(agg_fn).reset_index()\n",
    "        df_key['unique_id'] = df_key[key].agg('_'.join, axis=1)\n",
    "        if key == bottom_comb:\n",
    "            bottom_keys = df_key['unique_id'].unique()\n",
    "        df_keys.append(df_key)\n",
    "    df_keys = pd.concat(df_keys)\n",
    "    s_df = df_keys[['unique_id'] + bottom_comb].drop_duplicates().reset_index(drop=True)\n",
    "    s_df = s_df.set_index('unique_id')\n",
    "    s_df = s_df.fillna('agg')\n",
    "    keys_cols = []\n",
    "    for key in keys:\n",
    "        key_col = '_'.join(key) \n",
    "        s_df[key_col] = s_df[key].agg('_'.join, axis=1)\n",
    "        keys_cols.append(key_col)\n",
    "    y_df = df_keys[['unique_id', 'ds', 'y']].set_index('unique_id')\n",
    "    #s_mat definition\n",
    "    s_mat = _to_summing_matrix(s_df.loc[bottom_keys, keys_cols])\n",
    "    return s_df[keys_cols], s_mat, bottom_keys, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e32eb4-b464-4023-a6f1-a84aa6a7e61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "hierarchies = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]\n",
    "s_df, s_mat, bottom_keys, y_df = _aggregate_key(df, hierarchies)\n",
    "test_eq(len(y_df), 34_000)\n",
    "test_eq(y_df.index.nunique(), 425)\n",
    "test_eq(s_mat.shape, (425, 304))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6901b-4710-4757-b94a-2ad2599b261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bottom_up(y_hat: np.ndarray, s_mat: np.ndarray):\n",
    "    # size of y_hat = n_levels, horizon\n",
    "    _, h = y_hat.shape\n",
    "    n_levels, n_bottom = s_mat.shape\n",
    "    g_mat = np.eye(n_bottom, n_levels, k=(n_levels - n_bottom), dtype=np.float32)\n",
    "    s_g_mat = s_mat @ g_mat\n",
    "    return np.matmul(s_g_mat, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938b6ae-1d8a-4c88-a152-6f2541a6217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HierarchicalStatsForecast:\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, keys: List[List[str]], \n",
    "                 models: List, freq: str, \n",
    "                 n_jobs: int = 1, ray_address: Optional[str] = None):\n",
    "        self.s_df, self.s_mat, _,  y_df = _aggregate_key(df, keys=keys)\n",
    "        self.fcst = StatsForecast(df=y_df, models=models, freq=freq, \n",
    "                                  n_jobs=n_jobs, ray_address=ray_address,\n",
    "                                  sort_df=False)\n",
    "    \n",
    "    def forecast(self, h: int, reconcile_fns: List[Callable] = [bottom_up],\n",
    "                 xreg: Optional[pd.DataFrame] = None, \n",
    "                 level: Optional[Tuple] = None):\n",
    "        fcsts = self.fcst.forecast(h=h, xreg=xreg, level=level)\n",
    "        model_names = fcsts.drop(columns=['ds'], axis=1).columns.to_list()\n",
    "        for model_name in model_names:\n",
    "            fcsts_model = fcsts[model_name].values.reshape(-1, h)\n",
    "            for reconcile_fn in reconcile_fns:\n",
    "                reconcile_fn_name = reconcile_fn.__name__\n",
    "                fcsts_model = reconcile_fn(fcsts_model, self.s_mat)\n",
    "                fcsts[f'{reconcile_fn_name}_{model_name}'] = fcsts_model.flatten()\n",
    "        return fcsts\n",
    "    \n",
    "    def cross_validation(self, h: int, test_size: int, \n",
    "                         input_size: Optional[int] = None,\n",
    "                         reconcile_fns: List[Callable] = [bottom_up]):\n",
    "        fcsts = self.fcst.cross_validation(h=h, test_size=test_size, input_size=input_size)\n",
    "        model_names = fcsts.drop(columns=['ds', 'cutoff', 'y'], axis=1).columns.to_list()\n",
    "        cutoffs = fcsts['cutoff'].unique()\n",
    "        for model_name in model_names:\n",
    "            for cutoff in cutoffs:\n",
    "                cutoff_idx = fcsts['cutoff'] == cutoff\n",
    "                fcsts_model = fcsts.loc[cutoff_idx, model_name].values.reshape(-1, h)\n",
    "                for reconcile_fn in reconcile_fns:\n",
    "                    reconcile_fn_name = reconcile_fn.__name__\n",
    "                    fcsts_model = reconcile_fn(fcsts_model, self.s_mat)\n",
    "                    fcsts.loc[cutoff_idx, f'{reconcile_fn_name}_{model_name}'] = fcsts_model.flatten()\n",
    "        return fcsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abe82a-6221-4b27-8990-0f547597344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from statsforecast.models import naive\n",
    "# transform ds to int\n",
    "ds_int = df[['ds']].drop_duplicates().assign(ds_int = lambda df: np.arange(len(df)) + 1)\n",
    "df = df.merge(ds_int, how='left', on=['ds']).drop('ds', axis=1)\n",
    "df = df.rename(columns={'ds_int': 'ds'})\n",
    "# hierarchical\n",
    "hier_fcst = HierarchicalStatsForecast(df, \n",
    "                                      keys=hierarchies,\n",
    "                                      models=[naive],\n",
    "                                      freq='D', \n",
    "                                      n_jobs=-1)\n",
    "hier_fcsts = hier_fcst.cross_validation(12, test_size=12)\n",
    "# bottom_up with naive model should be return same forecasts\n",
    "pd.testing.assert_series_equal(hier_fcsts['naive'], hier_fcsts['bottom_up_naive'], check_names=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
