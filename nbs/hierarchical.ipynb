{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba3df0-5f5f-4645-80cf-acb6f2ff7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045633d-6ddd-4e98-a316-b07d333206a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6faac6-8bf6-4173-8ca8-3acd39e3d4d4",
   "metadata": {},
   "source": [
    "# Hierarchical Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f252aa-88e4-41f2-93eb-ccf0eeac9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c06e3b-5315-4fcf-8642-618e2970a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915637b-ae73-4f2c-ae4b-8b3b05b30536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import partial\n",
    "from inspect import signature\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.moment_helpers import cov2corr\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from statsforecast.core import StatsForecast, _as_tuple, _build_forecast_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988c8a9-f9a6-4a54-b058-6744db1b72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _to_summing_matrix(df: pd.DataFrame):\n",
    "    \"\"\"Transforms the bottom DataFrame `df` to a summing matrix S.\"\"\"\n",
    "    categories = [df[col].unique() for col in df.columns]\n",
    "    cat_sizes = [len(cats) for cats in categories]\n",
    "    idx_max_cat_size = np.argmax(cat_sizes)\n",
    "    cat_sizes = np.cumsum(cat_sizes)\n",
    "    idx_bottom = np.arange(cat_sizes[idx_max_cat_size - 1], cat_sizes[idx_max_cat_size])\n",
    "    encoder = OneHotEncoder(categories=categories, sparse=False, dtype=np.float32)\n",
    "    S = encoder.fit_transform(df).T\n",
    "    return S, idx_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2422c143-7ffe-45ec-84c4-b53ea0badb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _aggregate_key(df: pd.DataFrame, keys: List[List[str]], agg_fn: Callable = np.sum):\n",
    "    \"\"\"Aggregates `df` according to `keys` using `agg_fn`.\"\"\"\n",
    "    max_len_idx = np.argmax([len(key) for key in keys])\n",
    "    bottom_comb = keys[max_len_idx]\n",
    "    orig_cols = df.drop(labels=['ds', 'y'], axis=1).columns.to_list()\n",
    "    df_keys = []\n",
    "    for key in keys:\n",
    "        df_key = df.groupby(key + ['ds'])['y'].apply(agg_fn).reset_index()\n",
    "        df_key['unique_id'] = df_key[key].agg('_'.join, axis=1)\n",
    "        if key == bottom_comb:\n",
    "            bottom_keys = df_key['unique_id'].unique()\n",
    "        df_keys.append(df_key)\n",
    "    df_keys = pd.concat(df_keys)\n",
    "    S_df = df_keys[['unique_id'] + bottom_comb].drop_duplicates().reset_index(drop=True)\n",
    "    S_df = S_df.set_index('unique_id')\n",
    "    S_df = S_df.fillna('agg')\n",
    "    keys_cols = []\n",
    "    for key in keys:\n",
    "        key_col = '_'.join(key) \n",
    "        S_df[key_col] = S_df[key].agg('_'.join, axis=1)\n",
    "        keys_cols.append(key_col)\n",
    "    y_df = df_keys[['unique_id', 'ds', 'y']].set_index('unique_id')\n",
    "    #S definition\n",
    "    S, idx_bottom = _to_summing_matrix(S_df.loc[bottom_keys, keys_cols])\n",
    "    return S_df[keys_cols], S, idx_bottom, bottom_keys, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e32eb4-b464-4023-a6f1-a84aa6a7e61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/tourism.csv')\n",
    "df = df.rename({'Trips': 'y', 'Quarter': 'ds'}, axis=1)\n",
    "df.insert(0, 'Country', 'Australia')\n",
    "hiers_grouped = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'Purpose'], \n",
    "    ['Country', 'State', 'Region'], \n",
    "    ['Country', 'State', 'Purpose'], \n",
    "    ['Country', 'State', 'Region', 'Purpose']\n",
    "]\n",
    "S_df, S, idx_bottom, bottom_keys, y_df = _aggregate_key(df, hiers_grouped)\n",
    "test_eq(len(y_df), 34_000)\n",
    "test_eq(y_df.index.nunique(), 425)\n",
    "test_eq(S.shape, (425, 304))\n",
    "test_eq(idx_bottom.size, 304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec40e78-2669-4cdb-be2a-f0b266fd07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "hiers = [\n",
    "    ['Country'],\n",
    "    ['Country', 'State'], \n",
    "    ['Country', 'State', 'Region']\n",
    "]\n",
    "S_df, S, idx_bottom, bottom_keys, y_df = _aggregate_key(df, hiers)\n",
    "test_eq(len(y_df), 6_800)\n",
    "test_eq(y_df.index.nunique(), 85)\n",
    "test_eq(S.shape, (85, 76))\n",
    "test_eq(idx_bottom.size, 76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80046463-27ee-4305-b55e-4bd50a356d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reconcile(S: np.ndarray, P: np.ndarray, W: np.ndarray, \n",
    "               y_hat: np.ndarray, SP: np.ndarray = None):\n",
    "    if SP is None:\n",
    "        SP = S @ P\n",
    "    return np.matmul(SP, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6901b-4710-4757-b94a-2ad2599b261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bottom_up(hfcst: HierarchicalStatsForecast, y_hat: np.ndarray):\n",
    "    n_hiers, n_bottom = hfcst.S.shape\n",
    "    P = np.eye(n_bottom, n_hiers, k=(n_hiers - n_bottom), dtype=np.float32)\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(hfcst.S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48d95c-150c-450a-b3d5-af6476807aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def top_down(hfcst: HierarchicalStatsForecast, \n",
    "             y_hat: np.ndarray,\n",
    "             method: str):\n",
    "    n_hiers, n_bottom = hfcst.S.shape\n",
    "    idx_top = int(hfcst.S.sum(axis=1).argmax())\n",
    "    #add strictly hierarchical assert\n",
    "    \n",
    "    if method == 'forecast_proportions':\n",
    "        raise NotImplementedError(f'Method {method} not implemented yet')\n",
    "    else:\n",
    "        y_top = hfcst.fcst.ga[idx_top]\n",
    "        y_btm = np.hstack(hfcst.fcst.ga[int(idx)] for idx in hfcst.idx_bottom)\n",
    "        if method == 'average_proportions':\n",
    "            prop = np.mean(y_btm / y_top, axis=0)\n",
    "        elif method == 'proportion_averages':\n",
    "            prop = np.mean(y_btm, axis=0) / np.mean(y_top)\n",
    "        else:\n",
    "            raise Exception(f'Unknown method {method}')\n",
    "    P = np.zeros_like(hfcst.S).T\n",
    "    P[:, idx_top] = prop\n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    return _reconcile(hfcst.S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e43ff-9c00-46c6-a674-077191d5a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crossprod(x):\n",
    "    return x.T @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1db87-f749-437f-a4df-ead2080c9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def min_trace(hfcst: HierarchicalStatsForecast, y_hat: np.ndarray, method: str,\n",
    "              residuals: np.ndarray = None):\n",
    "    # shape residuals (obs, n_hiers)\n",
    "    res_methods = ['wls_var', 'mint_cov', 'mint_shrink']\n",
    "    if method in res_methods and residuals is None:\n",
    "        raise ValueError(f\"For methods {', '.join(res_methods)} you need to pass residuals\")\n",
    "    n_hiers, n_bottom = hfcst.S.shape\n",
    "    if method == 'ols':\n",
    "        W = np.eye(n_hiers)\n",
    "    elif method == 'wls_struct':\n",
    "        W = np.diag(hfcst.S @ np.ones((n_bottom,)))\n",
    "    elif method in res_methods:\n",
    "        n, _ = residuals.shape\n",
    "        masked_res = np.ma.array(residuals, mask=np.isnan(residuals))\n",
    "        covm = np.ma.cov(masked_res, rowvar=False, allow_masked=True).data\n",
    "        if method == 'wls_var':\n",
    "            W = np.diag(np.diag(covm))\n",
    "        elif method == 'mint_cov':\n",
    "            W = covm\n",
    "        elif method == 'mint_shrink':\n",
    "            tar = np.diag(np.diag(covm))\n",
    "            corm = cov2corr(covm)\n",
    "            xs = np.divide(residuals, np.sqrt(np.diag(covm)))\n",
    "            xs = xs[~np.isnan(xs).any(axis=1), :]\n",
    "            v = (1 / (n * (n - 1))) * (crossprod(xs ** 2) - (1 / n) * (crossprod(xs) ** 2))\n",
    "            np.fill_diagonal(v, 0)\n",
    "            corapn = cov2corr(tar)\n",
    "            d = (corm - corapn) ** 2\n",
    "            lmd = v.sum() / d.sum()\n",
    "            lmd = max(min(lmd, 1), 0)\n",
    "            W = lmd * tar + (1 - lmd) * covm\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "    \n",
    "    eigenvalues, _ = np.linalg.eig(W)\n",
    "    if any(eigenvalues < 1e-8):\n",
    "        raise Exception('min_trace needs covariance matrix to be positive definite.')\n",
    "        \n",
    "    R = hfcst.S.T @ np.linalg.inv(W)\n",
    "    P = np.linalg.inv(R @ hfcst.S) @ R\n",
    "    \n",
    "    return _reconcile(hfcst.S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6a8ee-4751-4707-a77d-bf24e8ff81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def empirical_risk_minimization(hfcst: HierarchicalStatsForecast,\n",
    "                                y_hat: np.ndarray, \n",
    "                                method: str,\n",
    "                                lambda_reg: float = 1e-3):\n",
    "    n_hiers, n_bottom = hfcst.S.shape\n",
    "    if method in ['exact', 'svd']:\n",
    "        B = y_hat.T @ hfcst.S @ np.linalg.inv(hfcst.S.T @ hfcst.S).T\n",
    "        if method == 'exact':\n",
    "            P = B.T @ y_hat.T @ np.linalg.inv(y_hat @ y_hat.T + lambda_reg * np.eye(n_hiers))\n",
    "        elif method == 'svd':\n",
    "            ...\n",
    "        else:\n",
    "            raise ValueError(f'Unkown reconciliation method {method}')\n",
    "    else:\n",
    "        raise ValueError(f'Unkown reconciliation method {method}')\n",
    "        \n",
    "    W = np.eye(n_hiers, dtype=np.float32)\n",
    "    \n",
    "    return _reconcile(hfcst.S, P, W, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938b6ae-1d8a-4c88-a152-6f2541a6217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HierarchicalStatsForecast:\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, keys: List[List[str]], \n",
    "                 models: List, \n",
    "                 reconcile_fns: List[Callable],\n",
    "                 freq: str,\n",
    "                 n_jobs: int = 1, ray_address: Optional[str] = None):\n",
    "        self.reconcile_fns = reconcile_fns\n",
    "        self.S_df, self.S, self.idx_bottom, _,  y_df = _aggregate_key(df, keys=keys)\n",
    "        self.fcst = StatsForecast(df=y_df, models=models, freq=freq, \n",
    "                                  n_jobs=n_jobs, ray_address=ray_address,\n",
    "                                  sort_df=False)\n",
    "    \n",
    "    def forecast(self, h: int,\n",
    "                 xreg: Optional[pd.DataFrame] = None, \n",
    "                 level: Optional[Tuple] = None):\n",
    "        fcsts = self.fcst.forecast(h=h, xreg=xreg, level=level)\n",
    "        model_names = fcsts.drop(columns=['ds'], axis=1).columns.to_list()\n",
    "        for model_name in model_names:\n",
    "            fcsts_model = fcsts[model_name].values.reshape(-1, h)\n",
    "            for reconcile_fn_args in self.reconcile_fns:\n",
    "                reconcile_fn, *args = _as_tuple(reconcile_fn_args)\n",
    "                reconcile_fn_name = _build_forecast_name(reconcile_fn, *args, idx_remove=2)\n",
    "                fcsts_model = reconcile_fn(self, fcsts_model, *args)\n",
    "                fcsts[f'{reconcile_fn_name}_{model_name}'] = fcsts_model.flatten()\n",
    "        return fcsts\n",
    "    \n",
    "    def cross_validation(self, h: int, test_size: int, \n",
    "                         input_size: Optional[int] = None):\n",
    "        fcsts = self.fcst.cross_validation(h=h, test_size=test_size, input_size=input_size, residuals=True)\n",
    "        res = self.fcst.cross_validation_residuals()\n",
    "        model_names = fcsts.drop(columns=['ds', 'cutoff', 'y'], axis=1).columns.to_list()\n",
    "        cutoffs = fcsts['cutoff'].unique()\n",
    "        for reconcile_fn_args in self.reconcile_fns:\n",
    "            reconcile_fn, *args = _as_tuple(reconcile_fn_args)\n",
    "            reconcile_fn_name = _build_forecast_name(reconcile_fn, *args, idx_remove=2)\n",
    "            has_res = 'residuals' in signature(reconcile_fn).parameters\n",
    "            for cutoff in cutoffs:\n",
    "                cutoff_idx = fcsts['cutoff'] == cutoff\n",
    "                for model_name in model_names:\n",
    "                    fcsts_model = fcsts.loc[cutoff_idx, model_name].values.reshape(-1, h)\n",
    "                    if has_res:\n",
    "                        res_cutoff_idx = res['cutoff'] == cutoff\n",
    "                        res_model = res.loc[res_cutoff_idx].pivot(columns='ds', values=model_name).values.T\n",
    "                        fcsts_reconciled = reconcile_fn(self, fcsts_model, *args, residuals=res_model)\n",
    "                    else:\n",
    "                        fcsts_reconciled = reconcile_fn(self, fcsts_model, *args)\n",
    "                    fcsts.loc[cutoff_idx, f'{model_name}/{reconcile_fn_name}'] = fcsts_reconciled.flatten()\n",
    "        return fcsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abe82a-6221-4b27-8990-0f547597344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from statsforecast.models import naive, auto_arima\n",
    "# transform ds to int\n",
    "ds_int = df[['ds']].drop_duplicates().assign(ds_int = lambda df: np.arange(len(df)) + 1)\n",
    "df = df.merge(ds_int, how='left', on=['ds']).drop('ds', axis=1)\n",
    "df = df.rename(columns={'ds_int': 'ds'})\n",
    "# hierarchical\n",
    "hier_fcst = HierarchicalStatsForecast(df, \n",
    "                                      keys=hiers,\n",
    "                                      models=[naive, (auto_arima, 4)],\n",
    "                                      reconcile_fns=[\n",
    "                                          bottom_up, \n",
    "                                          #(min_trace, 'ols'), \n",
    "                                          #(min_trace, 'wls_struct'),\n",
    "                                          #(min_trace, 'wls_var'),\n",
    "                                          #(min_trace, 'mint_cov'),\n",
    "                                          #(min_trace, 'mint_shrink'),\n",
    "                                          (empirical_risk_minimization, 'exact')\n",
    "                                          #(top_down, 'average_proportions'), \n",
    "                                          #(top_down, 'proportion_averages'),\n",
    "\n",
    "                                      ],\n",
    "                                      freq='D', \n",
    "                                      n_jobs=-1)\n",
    "with np.errstate(invalid='ignore'):\n",
    "    hier_fcsts = hier_fcst.cross_validation(12, test_size=12)\n",
    "# bottom_up with naive model should be return same forecasts\n",
    "pd.testing.assert_series_equal(hier_fcsts['naive'], hier_fcsts['naive/bottom_up'], check_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef656e-0d02-4cce-a648-a9baf13d2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ = hier_fcsts.copy()\n",
    "for model in hier_fcsts.drop(columns=['ds', 'cutoff', 'y']):\n",
    "    eval_[model] = (hier_fcsts['y'] - hier_fcsts[model]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840366b-97c4-4ca5-9778-9b024a488fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ = eval_.drop(columns=['ds', 'cutoff', 'y']).mean().rename('StatsForecast').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee4043-9b93-4d21-a51a-7dd9d3a8b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ = eval_.rename_axis('method').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e660d8-7ee8-432b-b4e9-92db39ad8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_[['model', 'reconciliation']] = eval_['method'].str.split('/', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2478eb-ccf7-485b-ab30-0790a3dd44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ = eval_[['model', 'reconciliation', 'StatsForecast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549f3e4-5b91-4c7c-acb7-8abcef14b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ = eval_.sort_values(['model', 'reconciliation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9af324-d1f7-438e-a582-e85b1e6c63c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_['R'] = [194000, 74055, 135950, 175946, 80133, 76289, 76289, 76289, 76289, 76289]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2833db1-b555-4a00-ad29-c31ae7f09399",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c882347-ecb4-4110-b895-868f455fc633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
