{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Uniserie models implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from itertools import count\n",
    "from numbers import Number\n",
    "from sys import float_info\n",
    "from typing import Collection, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from statsforecast.arima import auto_arima_f, forecast_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def _ses_fcst_mse(x: np.ndarray, alpha: float) -> Tuple[float, float]:\n",
    "    \"\"\"Perform simple exponential smoothing on a series.\n",
    "\n",
    "    This function returns the one step ahead prediction\n",
    "    as well as the mean squared error of the fit.\n",
    "    \"\"\"\n",
    "    smoothed = x[0]\n",
    "    n = x.size\n",
    "    mse = 0.\n",
    "\n",
    "    for i in range(1, n):\n",
    "        smoothed = (alpha * x[i - 1] + (1 - alpha) * smoothed).item()\n",
    "        error = x[i] - smoothed\n",
    "        mse += error * error\n",
    "\n",
    "    mse /= n\n",
    "    forecast = alpha * x[-1] + (1 - alpha) * smoothed\n",
    "    return forecast, mse\n",
    "\n",
    "\n",
    "def _ses_mse(alpha: float, x: np.ndarray) -> float:\n",
    "    \"\"\"Compute the mean squared error of a simple exponential smoothing fit.\"\"\"\n",
    "    _, mse = _ses_fcst_mse(x, alpha)\n",
    "    return mse\n",
    "\n",
    "\n",
    "@njit\n",
    "def _ses_forecast(x: np.ndarray, alpha: float) -> float:\n",
    "    \"\"\"One step ahead forecast with simple exponential smoothing.\"\"\"\n",
    "    forecast, _ = _ses_fcst_mse(x, alpha)\n",
    "    return forecast\n",
    "\n",
    "\n",
    "@njit\n",
    "def _demand(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract the positive elements of a vector.\"\"\"\n",
    "    return x[x > 0]\n",
    "\n",
    "\n",
    "@njit\n",
    "def _intervals(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the intervals between non zero elements of a vector.\"\"\"\n",
    "    y = []\n",
    "\n",
    "    ctr = 1\n",
    "    for val in x:\n",
    "        if val == 0:\n",
    "            ctr += 1\n",
    "        else:\n",
    "            y.append(ctr)\n",
    "            ctr = 1\n",
    "\n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "@njit\n",
    "def _probability(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the element probabilities of being non zero.\"\"\"\n",
    "    return (x != 0).astype(np.int32)\n",
    "\n",
    "\n",
    "def _optimized_ses_forecast(x: np.ndarray,\n",
    "                            bounds: Sequence[Tuple[float, float]] = [(0.1, 0.3)]\n",
    "                            ) -> float:\n",
    "    \"\"\"Searches for the optimal alpha and computes SES one step forecast.\"\"\"\n",
    "    alpha = minimize(\n",
    "        fun=_ses_mse,\n",
    "        x0=(0,),\n",
    "        args=(x,),\n",
    "        bounds=bounds,\n",
    "        method='L-BFGS-B'\n",
    "    ).x[0]\n",
    "    forecast = _ses_forecast(x, alpha)\n",
    "    return forecast\n",
    "\n",
    "\n",
    "@njit\n",
    "def _chunk_sums(array: np.ndarray, chunk_size: int) -> np.ndarray:\n",
    "    \"\"\"Splits an array into chunks and returns the sum of each chunk.\"\"\"\n",
    "    n = array.size\n",
    "    n_chunks = n // chunk_size\n",
    "    sums = np.empty(n_chunks)\n",
    "    for i, start in enumerate(range(0, n, chunk_size)):\n",
    "        sums[i] = array[start : start + chunk_size].sum()\n",
    "    return sums\n",
    "\n",
    "@njit\n",
    "def embed(x: np.array, p: Union[Tuple, int]) -> np.array:\n",
    "    \"\"\"Embeds the time series x into a low-dimensional Euclidean space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array\n",
    "        Time series.\n",
    "    p: Iterable or int\n",
    "        Embedding dimension.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    [1] embed(x, p) = embed(x, [0, 1, ..., p - 1])\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [1] https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/embed\n",
    "    \"\"\"\n",
    "    is_p_int = isinstance(p, int)\n",
    "\n",
    "    if is_p_int and p == 0:\n",
    "        raise Exception('Embedding dimension should not be 0')\n",
    "\n",
    "    rolls = range(p) if is_p_int else p\n",
    "    min_p = p - 1 if is_p_int else max(p)\n",
    "    x_embed = np.full((len(x), len(rolls)), np.nan)\n",
    "    for i, k in enumerate(rolls):\n",
    "        x_embed[:, i] = np.roll(x, k)\n",
    "    x_embed = x_embed[min_p:]\n",
    "\n",
    "    return x_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1., 0.],\n",
       "       [3., 2., 1.],\n",
       "       [4., 3., 2.],\n",
       "       [5., 4., 3.],\n",
       "       [6., 5., 4.],\n",
       "       [7., 6., 5.],\n",
       "       [8., 7., 6.],\n",
       "       [9., 8., 7.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(x, (0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "x = np.arange(10)\n",
    "for emb in [embed(x, 3), embed(x, (0, 1, 2))]:\n",
    "    np.testing.assert_equal(emb[:, 0], x[2:])\n",
    "    np.testing.assert_equal(emb[:, 1], x[1:-1])\n",
    "    np.testing.assert_equal(emb[:, 2], x[:-2])\n",
    "    \n",
    "def test_embed_equality(y, p):\n",
    "    equivalent_list = tuple(range(p))\n",
    "    np.testing.assert_equal(embed(y, p), embed(y, equivalent_list))\n",
    "    \n",
    "y = np.arange(100)\n",
    "for i in range(1, 10): \n",
    "    test_embed_equality(y, i)\n",
    "    \n",
    "def test_p_zero():\n",
    "    embed(y, 0)\n",
    "    \n",
    "test_fail(test_p_zero, contains='dimension should not be 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def quantile_auto_regression(X, h, future_xreg, tau, ar_terms, \n",
    "                             add_constant=True, \n",
    "                             max_diffs=10):\n",
    "    min_ar, max_ar = np.min(ar_terms), np.max(ar_terms)\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    last_y_train = y[-1]\n",
    "    is_constant = np.var(y) == 0\n",
    "    # Convert y to an stationary process\n",
    "    differences = 0\n",
    "    for _ in range(max_diffs):\n",
    "        _, pval, *_ = adfuller(y)\n",
    "        if pval < 0.05:\n",
    "            break\n",
    "        y = np.diff(y, 1)\n",
    "        differences += 1\n",
    "    design_mat = embed(y, (0, *ar_terms))\n",
    "    y_train, X_train = design_mat[:, 0], design_mat[:, 1:]\n",
    "    if add_constant:\n",
    "        X_train = np.hstack([X_train, np.ones((len(X_train), 1))])\n",
    "    if np.linalg.cond(X_train) > 1 / float_info.epsilon and not is_constant:\n",
    "        raise Exception('X matrix is ill-conditioned '\n",
    "                        'try reducing number of ar_terms '\n",
    "                        'or setting add_constant=False.')\n",
    "    model_ = QuantReg(y_train, X_train).fit(tau)\n",
    "    y_hat = y_train\n",
    "    len_train = y_train.shape[0]\n",
    "    forecast_size = len_train + h\n",
    "    while y_hat.size < forecast_size:\n",
    "        y_hat_placeholder = np.zeros(min_ar)\n",
    "        y_hat = np.concatenate([y_hat, y_hat_placeholder])\n",
    "        y_test = embed(y_hat, ar_terms)[-min_ar:]\n",
    "        if add_constant:\n",
    "            y_test = np.hstack([y_test, np.ones((len(y_test), 1))])\n",
    "        y_hat[-min_ar:] = model_.predict(y_test)\n",
    "    y_hat = y_hat[len_train:forecast_size]\n",
    "    if differences:\n",
    "        for i in range(differences): y_hat = y_hat.cumsum()\n",
    "        y_hat += last_y_train\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def ses(X, h, future_xreg, alpha):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    fcst, _ = _ses_fcst_mse(y, alpha)\n",
    "    return np.full(h, fcst, np.float32)\n",
    "\n",
    "\n",
    "def adida(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return np.repeat(np.float32(0), h)\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean()\n",
    "    aggregation_level = round(mean_interval)\n",
    "    lost_remainder_data = len(y) % aggregation_level\n",
    "    y_cut = y[lost_remainder_data:]\n",
    "    aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "    sums_forecast = _optimized_ses_forecast(aggregation_sums)\n",
    "    forecast = sums_forecast / aggregation_level\n",
    "    return np.repeat(forecast, h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def historic_average(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    return np.repeat(y.mean(), h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def croston_classic(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    yd = _demand(y)\n",
    "    yi = _intervals(y)\n",
    "    ydp = _ses_forecast(yd, 0.1)\n",
    "    yip = _ses_forecast(yi, 0.1)\n",
    "    return ydp / yip\n",
    "\n",
    "\n",
    "@njit\n",
    "def croston_sba(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    return 0.95 * croston_classic(y, h, future_xreg)\n",
    "\n",
    "\n",
    "def croston_optimized(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    yd = _demand(y)\n",
    "    yi = _intervals(y)\n",
    "    ydp = _optimized_ses_forecast(yd)\n",
    "    yip = _optimized_ses_forecast(yi)\n",
    "    return ydp / yip\n",
    "\n",
    "\n",
    "@njit\n",
    "def seasonal_window_average(\n",
    "    X: np.ndarray,\n",
    "    h: int,\n",
    "    future_xreg,\n",
    "    season_length: int,\n",
    "    window_size: int,\n",
    ") -> np.ndarray:\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    min_samples = season_length * window_size\n",
    "    if y.size < min_samples:\n",
    "        return np.full(h, np.nan, np.float32)\n",
    "    season_avgs = np.zeros(season_length, np.float32)\n",
    "    for i, value in enumerate(y[-min_samples:]):\n",
    "        season = i % season_length\n",
    "        season_avgs[season] += value / window_size\n",
    "    out = np.empty(h, np.float32)\n",
    "    for i in range(h):\n",
    "        out[i] = season_avgs[i % season_length]\n",
    "    return out\n",
    "\n",
    "\n",
    "@njit\n",
    "def seasonal_naive(X, h, future_xreg, season_length):\n",
    "    return seasonal_window_average(X, h, future_xreg, season_length, 1)\n",
    "\n",
    "\n",
    "def imapa(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return np.repeat(np.float32(0), h)\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean().item()\n",
    "    max_aggregation_level = round(mean_interval)\n",
    "    forecasts = np.empty(max_aggregation_level, np.float32)\n",
    "    for aggregation_level in range(1, max_aggregation_level + 1):\n",
    "        lost_remainder_data = len(y) % aggregation_level\n",
    "        y_cut = y[lost_remainder_data:]\n",
    "        aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "        forecast = _optimized_ses_forecast(aggregation_sums)\n",
    "        forecasts[aggregation_level - 1] = (forecast / aggregation_level)\n",
    "    forecast = forecasts.mean()\n",
    "    return np.repeat(forecast, h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def naive(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    return np.repeat(y[-1], h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def random_walk_with_drift(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    slope = (y[-1] - y[0]) / (y.size - 1)\n",
    "    return slope * (1 + np.arange(h)) + y[-1]\n",
    "\n",
    "\n",
    "@njit\n",
    "def window_average(X, h, future_xreg, window_size):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if y.size < window_size:\n",
    "        return np.full(h, np.nan, np.float32)\n",
    "    wavg = y[-window_size:].mean()\n",
    "    return np.repeat(wavg, h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def seasonal_exponential_smoothing(X, h, future_xreg, season_length, alpha):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if y.size < season_length:\n",
    "        return np.full(h, np.nan, np.float32)\n",
    "    season_vals = np.empty(season_length, np.float32)\n",
    "    for i in range(season_length):\n",
    "        season_vals[i] = _ses_forecast(y[i::season_length], alpha)\n",
    "    out = np.empty(h, np.float32)\n",
    "    for i in range(h):\n",
    "        out[i] = season_vals[i % season_length]\n",
    "    return out\n",
    "\n",
    "\n",
    "@njit\n",
    "def tsb(X, h, future_xreg, alpha_d, alpha_p):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return np.repeat(np.float32(0), h)\n",
    "    yd = _demand(y)\n",
    "    yp = _probability(y)\n",
    "    ypf = _ses_forecast(yp, alpha_p)\n",
    "    ydf = _ses_forecast(yd, alpha_d)\n",
    "    forecast = np.float32(ypf * ydf)\n",
    "    return np.repeat(forecast, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def auto_arima(X: np.ndarray, h: int, future_xreg=None, season_length: int = 1, \n",
    "               approximation: bool = False, level: Optional[Tuple[int]] = None) -> np.ndarray:\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    xreg = X[:, 1:] if (X.ndim == 2 and X.shape[1] > 1) else None\n",
    "    mod = auto_arima_f(\n",
    "        y, \n",
    "        xreg=xreg,\n",
    "        period=season_length, \n",
    "        approximation=approximation,\n",
    "        allowmean=False, allowdrift=False #not implemented yet\n",
    "    )\n",
    "    fcst = forecast_arima(mod, h, xreg=future_xreg, level=level)\n",
    "    if level is None:\n",
    "        return fcst['mean']\n",
    "    return {\n",
    "        'mean': fcst['mean'],\n",
    "        **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "        **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima(ap, 12, season_length=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = np.arange(1, ap.size + 1)\n",
    "X = np.vstack([ap, np.log(drift), np.sqrt(drift)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdrift = np.arange(ap.size + 1, ap.size + 7 + 1).reshape(-1, 1)\n",
    "newxreg = np.concatenate([np.log(newdrift), np.sqrt(newdrift)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima(X, 7, future_xreg=newxreg, season_length=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(auto_arima(ap, 12, season_length=12, level=(80, 95)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
