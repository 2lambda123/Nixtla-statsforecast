{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Uniserie models implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from itertools import count\n",
    "from numbers import Number\n",
    "from typing import Collection, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "from statsforecast.arima import auto_arima_f, forecast_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def _ses_fcst_mse(x: np.ndarray, alpha: float) -> Tuple[float, float]:\n",
    "    \"\"\"Perform simple exponential smoothing on a series.\n",
    "\n",
    "    This function returns the one step ahead prediction\n",
    "    as well as the mean squared error of the fit.\n",
    "    \"\"\"\n",
    "    smoothed = x[0]\n",
    "    n = x.size\n",
    "    mse = 0.\n",
    "\n",
    "    for i in range(1, n):\n",
    "        smoothed = (alpha * x[i - 1] + (1 - alpha) * smoothed).item()\n",
    "        error = x[i] - smoothed\n",
    "        mse += error * error\n",
    "\n",
    "    mse /= n\n",
    "    forecast = alpha * x[-1] + (1 - alpha) * smoothed\n",
    "    return forecast, mse\n",
    "\n",
    "\n",
    "def _ses_mse(alpha: float, x: np.ndarray) -> float:\n",
    "    \"\"\"Compute the mean squared error of a simple exponential smoothing fit.\"\"\"\n",
    "    _, mse = _ses_fcst_mse(x, alpha)\n",
    "    return mse\n",
    "\n",
    "\n",
    "@njit\n",
    "def _ses_forecast(x: np.ndarray, alpha: float) -> float:\n",
    "    \"\"\"One step ahead forecast with simple exponential smoothing.\"\"\"\n",
    "    forecast, _ = _ses_fcst_mse(x, alpha)\n",
    "    return forecast\n",
    "\n",
    "\n",
    "@njit\n",
    "def _demand(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract the positive elements of a vector.\"\"\"\n",
    "    return x[x > 0]\n",
    "\n",
    "\n",
    "@njit\n",
    "def _intervals(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the intervals between non zero elements of a vector.\"\"\"\n",
    "    y = []\n",
    "\n",
    "    ctr = 1\n",
    "    for val in x:\n",
    "        if val == 0:\n",
    "            ctr += 1\n",
    "        else:\n",
    "            y.append(ctr)\n",
    "            ctr = 1\n",
    "\n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "@njit\n",
    "def _probability(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the element probabilities of being non zero.\"\"\"\n",
    "    return (x != 0).astype(np.int32)\n",
    "\n",
    "\n",
    "def _optimized_ses_forecast(x: np.ndarray,\n",
    "                            bounds: Sequence[Tuple[float, float]] = [(0.1, 0.3)]\n",
    "                            ) -> float:\n",
    "    \"\"\"Searches for the optimal alpha and computes SES one step forecast.\"\"\"\n",
    "    alpha = minimize(\n",
    "        fun=_ses_mse,\n",
    "        x0=(0,),\n",
    "        args=(x,),\n",
    "        bounds=bounds,\n",
    "        method='L-BFGS-B'\n",
    "    ).x[0]\n",
    "    forecast = _ses_forecast(x, alpha)\n",
    "    return forecast\n",
    "\n",
    "\n",
    "@njit\n",
    "def _chunk_sums(array: np.ndarray, chunk_size: int) -> np.ndarray:\n",
    "    \"\"\"Splits an array into chunks and returns the sum of each chunk.\"\"\"\n",
    "    n = array.size\n",
    "    n_chunks = n // chunk_size\n",
    "    sums = np.empty(n_chunks)\n",
    "    for i, start in enumerate(range(0, n, chunk_size)):\n",
    "        sums[i] = array[start : start + chunk_size].sum()\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def ses(X, h, future_xreg, alpha):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    fcst, _ = _ses_fcst_mse(y, alpha)\n",
    "    return np.full(h, fcst, np.float32)\n",
    "\n",
    "\n",
    "def adida(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return np.repeat(np.float32(0), h)\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean()\n",
    "    aggregation_level = round(mean_interval)\n",
    "    lost_remainder_data = len(y) % aggregation_level\n",
    "    y_cut = y[lost_remainder_data:]\n",
    "    aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "    sums_forecast = _optimized_ses_forecast(aggregation_sums)\n",
    "    forecast = sums_forecast / aggregation_level\n",
    "    return np.repeat(forecast, h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def historic_average(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    return np.repeat(y.mean(), h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def croston_classic(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    yd = _demand(y)\n",
    "    yi = _intervals(y)\n",
    "    ydp = _ses_forecast(yd, 0.1)\n",
    "    yip = _ses_forecast(yi, 0.1)\n",
    "    return ydp / yip\n",
    "\n",
    "\n",
    "@njit\n",
    "def croston_sba(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    return 0.95 * croston_classic(y, h, future_xreg)\n",
    "\n",
    "\n",
    "def croston_optimized(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    yd = _demand(y)\n",
    "    yi = _intervals(y)\n",
    "    ydp = _optimized_ses_forecast(yd)\n",
    "    yip = _optimized_ses_forecast(yi)\n",
    "    return ydp / yip\n",
    "\n",
    "\n",
    "@njit\n",
    "def seasonal_window_average(\n",
    "    X: np.ndarray,\n",
    "    h: int,\n",
    "    future_xreg,\n",
    "    season_length: int,\n",
    "    window_size: int,\n",
    ") -> np.ndarray:\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    min_samples = season_length * window_size\n",
    "    if y.size < min_samples:\n",
    "        return np.full(h, np.nan, np.float32)\n",
    "    season_avgs = np.zeros(season_length, np.float32)\n",
    "    for i, value in enumerate(y[-min_samples:]):\n",
    "        season = i % season_length\n",
    "        season_avgs[season] += value / window_size\n",
    "    out = np.empty(h, np.float32)\n",
    "    for i in range(h):\n",
    "        out[i] = season_avgs[i % season_length]\n",
    "    return out\n",
    "\n",
    "\n",
    "@njit\n",
    "def seasonal_naive(X, h, future_xreg, season_length):\n",
    "    return seasonal_window_average(X, h, future_xreg, season_length, 1)\n",
    "\n",
    "\n",
    "def imapa(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return np.repeat(np.float32(0), h)\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean().item()\n",
    "    max_aggregation_level = round(mean_interval)\n",
    "    forecasts = np.empty(max_aggregation_level, np.float32)\n",
    "    for aggregation_level in range(1, max_aggregation_level + 1):\n",
    "        lost_remainder_data = len(y) % aggregation_level\n",
    "        y_cut = y[lost_remainder_data:]\n",
    "        aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "        forecast = _optimized_ses_forecast(aggregation_sums)\n",
    "        forecasts[aggregation_level - 1] = (forecast / aggregation_level)\n",
    "    forecast = forecasts.mean()\n",
    "    return np.repeat(forecast, h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def _naive(X, h, future_xreg, return_se):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    mean = np.repeat(y[-1], h)\n",
    "    if not return_se:\n",
    "        return mean, None\n",
    "    residuals = y - np.roll(y, -1)\n",
    "    residuals = residuals[1:]\n",
    "    se = np.sqrt(np.mean(residuals**2))\n",
    "    se = np.array([se * np.sqrt(h_) for h_ in range(1, h+1)])\n",
    "    return mean, se\n",
    "\n",
    "\n",
    "def naive(X, h, future_xreg, level=None):\n",
    "    if level is None:\n",
    "        mean, se = _naive(X=X, h=h, future_xreg=future_xreg, return_se=False)\n",
    "        return mean\n",
    "    mean, se = _naive(X=X, h=h, future_xreg=future_xreg, return_se=True)\n",
    "    quantiles = norm.ppf(0.5 * (1 + np.asarray(level) / 100))\n",
    "    lo = {\n",
    "        f'lo-{l}%': mean.reshape(-1, 1) - quantiles * se.reshape(-1, 1)\n",
    "        for l in level\n",
    "    }\n",
    "    hi = {\n",
    "        f'hi-{l}%': mean.reshape(-1, 1) + quantiles * se.reshape(-1, 1)\n",
    "        for l in level\n",
    "    }\n",
    "    return {\n",
    "        'mean': mean,\n",
    "        **lo,\n",
    "        **hi,\n",
    "    }    \n",
    "\n",
    "\n",
    "@njit\n",
    "def random_walk_with_drift(X, h, future_xreg):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    slope = (y[-1] - y[0]) / (y.size - 1)\n",
    "    return slope * (1 + np.arange(h)) + y[-1]\n",
    "\n",
    "\n",
    "@njit\n",
    "def window_average(X, h, future_xreg, window_size):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if y.size < window_size:\n",
    "        return np.full(h, np.nan, np.float32)\n",
    "    wavg = y[-window_size:].mean()\n",
    "    return np.repeat(wavg, h)\n",
    "\n",
    "\n",
    "@njit\n",
    "def seasonal_exponential_smoothing(X, h, future_xreg, season_length, alpha):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if y.size < season_length:\n",
    "        return np.full(h, np.nan, np.float32)\n",
    "    season_vals = np.empty(season_length, np.float32)\n",
    "    for i in range(season_length):\n",
    "        season_vals[i] = _ses_forecast(y[i::season_length], alpha)\n",
    "    out = np.empty(h, np.float32)\n",
    "    for i in range(h):\n",
    "        out[i] = season_vals[i % season_length]\n",
    "    return out\n",
    "\n",
    "\n",
    "@njit\n",
    "def tsb(X, h, future_xreg, alpha_d, alpha_p):\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return np.repeat(np.float32(0), h)\n",
    "    yd = _demand(y)\n",
    "    yp = _probability(y)\n",
    "    ypf = _ses_forecast(yp, alpha_p)\n",
    "    ydf = _ses_forecast(yd, alpha_d)\n",
    "    forecast = np.float32(ypf * ydf)\n",
    "    return np.repeat(forecast, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def auto_arima(X: np.ndarray, h: int, future_xreg=None, season_length: int = 1, \n",
    "               approximation: bool = False, level: Optional[Tuple[int]] = None) -> np.ndarray:\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    xreg = X[:, 1:] if (X.ndim == 2 and X.shape[1] > 1) else None\n",
    "    mod = auto_arima_f(\n",
    "        y, \n",
    "        xreg=xreg,\n",
    "        period=season_length, \n",
    "        approximation=approximation,\n",
    "        allowmean=False, allowdrift=False #not implemented yet\n",
    "    )\n",
    "    fcst = forecast_arima(mod, h, xreg=future_xreg, level=level)\n",
    "    if level is None:\n",
    "        return fcst['mean']\n",
    "    return {\n",
    "        'mean': fcst['mean'],\n",
    "        **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in level},\n",
    "        **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([444.30005077, 418.2100203 , 446.23703401, 488.22892853,\n",
       "       499.23136059, 562.23063085, 649.23084981, 633.23078411,\n",
       "       535.23080382, 488.23079791, 417.23079968, 459.23079915])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_arima(ap, 12, season_length=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = np.arange(1, ap.size + 1)\n",
    "X = np.vstack([ap, np.log(drift), np.sqrt(drift)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdrift = np.arange(ap.size + 1, ap.size + 7 + 1).reshape(-1, 1)\n",
    "newxreg = np.concatenate([np.log(newdrift), np.sqrt(newdrift)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([444.3798589 , 418.34255927, 446.43035833, 488.47964491,\n",
       "       499.53980088, 562.59593789, 649.65256062])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_arima(X, 7, future_xreg=newxreg, season_length=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>lo-80</th>\n",
       "      <th>lo-95</th>\n",
       "      <th>hi-80</th>\n",
       "      <th>hi-95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>444.300051</td>\n",
       "      <td>429.182317</td>\n",
       "      <td>421.179472</td>\n",
       "      <td>459.417784</td>\n",
       "      <td>467.420629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418.210020</td>\n",
       "      <td>399.756915</td>\n",
       "      <td>389.988431</td>\n",
       "      <td>436.663126</td>\n",
       "      <td>446.431610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>446.237034</td>\n",
       "      <td>424.256469</td>\n",
       "      <td>412.620660</td>\n",
       "      <td>468.217599</td>\n",
       "      <td>479.853408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488.228929</td>\n",
       "      <td>463.405840</td>\n",
       "      <td>450.265291</td>\n",
       "      <td>513.052017</td>\n",
       "      <td>526.192566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499.231361</td>\n",
       "      <td>471.807503</td>\n",
       "      <td>457.290190</td>\n",
       "      <td>526.655218</td>\n",
       "      <td>541.172531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>562.230631</td>\n",
       "      <td>532.446502</td>\n",
       "      <td>516.679736</td>\n",
       "      <td>592.014760</td>\n",
       "      <td>607.781525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>649.230850</td>\n",
       "      <td>617.256215</td>\n",
       "      <td>600.329866</td>\n",
       "      <td>681.205484</td>\n",
       "      <td>698.131833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>633.230784</td>\n",
       "      <td>599.207510</td>\n",
       "      <td>581.196677</td>\n",
       "      <td>667.254058</td>\n",
       "      <td>685.264891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>535.230804</td>\n",
       "      <td>499.275106</td>\n",
       "      <td>480.241310</td>\n",
       "      <td>571.186501</td>\n",
       "      <td>590.220298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>488.230798</td>\n",
       "      <td>450.441457</td>\n",
       "      <td>430.436989</td>\n",
       "      <td>526.020138</td>\n",
       "      <td>546.024607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>417.230800</td>\n",
       "      <td>377.692737</td>\n",
       "      <td>356.762551</td>\n",
       "      <td>456.768863</td>\n",
       "      <td>477.699049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>459.230799</td>\n",
       "      <td>418.018156</td>\n",
       "      <td>396.201501</td>\n",
       "      <td>500.443442</td>\n",
       "      <td>522.260098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean       lo-80       lo-95       hi-80       hi-95\n",
       "0   444.300051  429.182317  421.179472  459.417784  467.420629\n",
       "1   418.210020  399.756915  389.988431  436.663126  446.431610\n",
       "2   446.237034  424.256469  412.620660  468.217599  479.853408\n",
       "3   488.228929  463.405840  450.265291  513.052017  526.192566\n",
       "4   499.231361  471.807503  457.290190  526.655218  541.172531\n",
       "5   562.230631  532.446502  516.679736  592.014760  607.781525\n",
       "6   649.230850  617.256215  600.329866  681.205484  698.131833\n",
       "7   633.230784  599.207510  581.196677  667.254058  685.264891\n",
       "8   535.230804  499.275106  480.241310  571.186501  590.220298\n",
       "9   488.230798  450.441457  430.436989  526.020138  546.024607\n",
       "10  417.230800  377.692737  356.762551  456.768863  477.699049\n",
       "11  459.230799  418.018156  396.201501  500.443442  522.260098"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(auto_arima(ap, 12, season_length=12, level=(80, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7x/1l3vkh3x4_q3s4r36b60s8f00000gn/T/ipykernel_74707/1519087658.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/statsforecast/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/statsforecast/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     return arrays_to_mgr(\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/statsforecast/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/statsforecast/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             val = sanitize_array(\n\u001b[0;32m--> 590\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m             )\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/statsforecast/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m     \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/statsforecast/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;31m# i.e. PandasDtype(\"O\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(naive(ap, 12, None, level=(80,90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
