{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "> Models currently supported by StatsForecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StatsForecast offers a wide variety of models grouped in the following categories:\n",
    "\n",
    "*  **Auto Forecast:** Automatic forecasting tools search for the best parameters and select the best possible model for a series of time series. These tools are useful for large collections of univariate time series. Includes automatic versions of: Arima, ETS, Theta, CES.\n",
    "\n",
    "* **Exponential Smoothing:**  Uses a weighted average of all past observations where the weights decrease exponentially into the past. Suitable for data with clear trend and/or seasonality. Use the `SimpleExponential` family  for data with no clear trend or seasonality. Examples: SES, Holt's Winters, SSO.\n",
    "\n",
    "* **Benchmark models:** classical models for establishing baselines. Examples: Mean, Naive, Random Walk\n",
    "\n",
    "* **Intermittent or Sparse models:** suited for series with very few non-zero observations. Examples: CROSTON, ADIDA, IMAPA\n",
    "\n",
    "* **Multiple Seasonalities:** suited for signals with more than one clear seasonality. Useful for low-frequency data like electricity and logs. Examples: MSTL. \n",
    "\n",
    "* **Theta Models:**  fit two theta lines to a deseasonalized time series, using different techniques to obtain and combine the two theta lines to produce the final forecasts. Examples: Theta, DynamicTheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import add_docs, show_doc\n",
    "from fastcore.test import test_eq, test_close, test_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import warnings\n",
    "from inspect import signature\n",
    "from math import trunc\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from statsforecast.arima import auto_arima_f, forecast_arima, fitted_arima\n",
    "from statsforecast.ces import auto_ces, forecast_ces\n",
    "from statsforecast.ets import (\n",
    "    ets_f, forecast_ets, \n",
    "    forward_ets\n",
    ")\n",
    "from statsforecast.mstl import mstl\n",
    "from statsforecast.theta import (\n",
    "    auto_theta, forecast_theta, \n",
    "    forward_theta\n",
    ")\n",
    "from statsforecast.utils import (\n",
    "    _seasonal_naive, _repeat_val_seas, \n",
    "    _naive, _repeat_val, _quantiles, \n",
    "    _calculate_sigma, _calculate_intervals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from datetime import date, timedelta\n",
    "\n",
    "def _plot_insample_pi(fcst):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (20,7))\n",
    "\n",
    "    sdate = date(1949,1,1) # start date \n",
    "    edate = date(1961,1,1) # end date\n",
    "    dates = pd.date_range(sdate,edate-timedelta(days=1),freq='m')\n",
    "\n",
    "    df = pd.DataFrame({'dates': dates,\n",
    "                       'actual': ap,\n",
    "                       'fitted': fcst['fitted'],\n",
    "                       'fitted_lo_80': fcst['fitted-lo-80'], \n",
    "                       'fitted_lo_95': fcst['fitted-lo-95'], \n",
    "                       'fitted_hi_80': fcst['fitted-hi-80'],\n",
    "                       'fitted_hi_95': fcst['fitted-hi-95']})\n",
    "    plt.plot(df.dates, df.actual, color='firebrick', label='Actual value', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted, color='navy', label='Fitted values', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted_lo_80, color='darkorange', label='fitted-lo-80', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted_lo_95, color='deepskyblue', label='fitted-lo-95', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted_hi_80, color='darkorange', label='fitted-hi-80', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted_hi_95, color='deepskyblue', label='fitted-hi-95', linewidth=3)\n",
    "    plt.fill_between(df.dates, df.fitted_lo_95, df.fitted_hi_95, color = 'deepskyblue', alpha = 0.2)\n",
    "    plt.fill_between(df.dates, df.fitted_lo_80, df.fitted_hi_80, color = 'darkorange', alpha = 0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "def _plot_fcst(fcst): \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (20,7))\n",
    "    plt.plot(np.arange(0, len(ap)), ap)\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['mean'], label='mean')\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['lo-95'], color = 'r', label='lo-95')\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['hi-95'], color = 'r', label='hi-95')\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['lo-80'], color = 'g', label='lo-80')\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['hi-80'], color = 'g', label='hi-80')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class _TS:\n",
    "    \n",
    "    def new(self):\n",
    "        b = type(self).__new__(type(self))\n",
    "        b.__dict__.update(self.__dict__)\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _add_fitted_pi(res, se, level):\n",
    "    level = sorted(level)\n",
    "    level = np.asarray(level)\n",
    "    quantiles = _quantiles(level=level)\n",
    "    lo = res['fitted'].reshape(-1, 1) - quantiles * se.reshape(-1, 1)\n",
    "    hi = res['fitted'].reshape(-1, 1) + quantiles * se.reshape(-1, 1)\n",
    "    lo = lo[:, ::-1]\n",
    "    lo = {f'fitted-lo-{l}': lo[:, i] for i, l in enumerate(reversed(level))}\n",
    "    hi = {f'fitted-hi-{l}': hi[:, i] for i, l in enumerate(level)}\n",
    "    res = {**res, **lo, **hi}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 1. Automatic Forecasting </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoARIMA(_TS):\n",
    "    \"\"\"AutoARIMA model.\n",
    "\n",
    "    Automatically selects the best ARIMA (AutoRegressive Integrated Moving Average) \n",
    "    model using an information criterion. Default is Akaike Information Criterion (AICc). \n",
    "    \n",
    "    **Parameters:**<br>\n",
    "    `d`: int, order of first-differencing.<br>\n",
    "    `D`: int, order of seasonal-differencing.<br>\n",
    "    `max_p`: int, max autorregresives p.<br>\n",
    "    `max_q`: int, max moving averages q.<br>\n",
    "    `max_P`: int, max seasonal autorregresives P.<br>\n",
    "    `max_Q`: int, max seasonal moving averages Q.<br>\n",
    "    `max_order`: int, max p+q+P+Q value if not stepwise selection.<br>\n",
    "    `max_d`: int, max non-seasonal differences.<br>\n",
    "    `max_D`: int, max seasonal differences.<br>\n",
    "    `start_p`: int, starting value of p in stepwise procedure.<br>\n",
    "    `start_q`: int, starting value of q in stepwise procedure.<br>\n",
    "    `start_P`: int, starting value of P in stepwise procedure.<br>\n",
    "    `start_Q`: int, starting value of Q in stepwise procedure.<br>\n",
    "    `stationary`: bool, if True, restricts search to stationary models.<br>\n",
    "    `seasonal`: bool, if False, restricts search to non-seasonal models.<br>\n",
    "    `ic`: str, information criterion to be used in model selection.<br>\n",
    "    `stepwise`: bool, if True, will do stepwise selection (faster).<br>\n",
    "    `nmodels`: int, number of models considered in stepwise search.<br>\n",
    "    `trace`: bool, if True, the searched ARIMA models is reported.<br>\n",
    "    `approximation`: bool, if True, conditional sums-of-squares estimation, final MLE.<br>\n",
    "    `method`: str, fitting method between maximum likelihood or sums-of-squares.<br>\n",
    "    `truncate`: int, observations truncated series used in model selection.<br>\n",
    "    `test`: str (default 'kpss'), unit root test to use. See `ndiffs` for details.<br>\n",
    "    `test_kwargs`: str optional (default None), unit root test additional arguments.<br>\n",
    "    `seasonal_test`: str (default 'seas'), selection method for seasonal differences.<br>\n",
    "    `seasonal_test_kwargs`: dict (optional), seasonal unit root test arguments.<br>\n",
    "    `allowdrift`: bool (default True), If True, drift models terms considered.<br>\n",
    "    `allowmean`: bool (default True), If True, non-zero mean models considered.<br>\n",
    "    `blambda`: float optional (default None), Box-Cox transformation parameter.<br>\n",
    "    `biasadj`: bool (default False), Use adjusted back-transformed mean Box-Cox.<br>\n",
    "    `parallel`: bool, If True and stepwise=False, then parallel search.<br>\n",
    "    `num_cores`: int, amount of parallel processes to be used if parallel=True.<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `alias`: str, Custom name of the model. Default `AutoARIMA`.<br>\n",
    "    \n",
    "    **Note:**<br>\n",
    "    This implementation is a mirror of Hyndman's [forecast::auto.arima](https://github.com/robjhyndman/forecast).\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Rob J. Hyndman, Yeasmin Khandakar (2008). \"Automatic Time Series Forecasting: The forecast package for R\"](https://www.jstatsoft.org/article/view/v027i03).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        d: Optional[int] = None,\n",
    "        D: Optional[int] = None,\n",
    "        max_p: int = 5,\n",
    "        max_q: int = 5,\n",
    "        max_P: int = 2,\n",
    "        max_Q: int = 2,\n",
    "        max_order: int = 5,\n",
    "        max_d: int = 2,\n",
    "        max_D: int = 1,\n",
    "        start_p: int = 2,\n",
    "        start_q: int = 2,\n",
    "        start_P: int = 1,\n",
    "        start_Q: int = 1,\n",
    "        stationary: bool = False,\n",
    "        seasonal: bool = True,\n",
    "        ic: str = 'aicc',\n",
    "        stepwise: bool = True,\n",
    "        nmodels: int = 94,\n",
    "        trace: bool = False,\n",
    "        approximation: Optional[bool] = False,\n",
    "        method: Optional[str] = None,\n",
    "        truncate: Optional[bool] = None,\n",
    "        test: str = 'kpss',\n",
    "        test_kwargs: Optional[str] = None,\n",
    "        seasonal_test: str = 'seas',\n",
    "        seasonal_test_kwargs: Optional[Dict] = None,\n",
    "        allowdrift: bool = False,\n",
    "        allowmean: bool = False,\n",
    "        blambda: Optional[float] = None,\n",
    "        biasadj: bool = False,\n",
    "        parallel: bool = False,\n",
    "        num_cores: int = 2,\n",
    "        season_length: int = 1,\n",
    "        alias: str = 'AutoARIMA'\n",
    "    ):\n",
    "        self.d=d\n",
    "        self.D=D\n",
    "        self.max_p=max_p\n",
    "        self.max_q=max_q\n",
    "        self.max_P=max_P\n",
    "        self.max_Q=max_Q\n",
    "        self.max_order=max_order\n",
    "        self.max_d=max_d\n",
    "        self.max_D=max_D\n",
    "        self.start_p=start_p\n",
    "        self.start_q=start_q\n",
    "        self.start_P=start_P\n",
    "        self.start_Q=start_Q\n",
    "        self.stationary=stationary\n",
    "        self.seasonal=seasonal\n",
    "        self.ic=ic\n",
    "        self.stepwise=stepwise\n",
    "        self.nmodels=nmodels\n",
    "        self.trace=trace\n",
    "        self.approximation=approximation\n",
    "        self.method=method\n",
    "        self.truncate=truncate\n",
    "        self.test=test\n",
    "        self.test_kwargs=test_kwargs\n",
    "        self.seasonal_test=seasonal_test\n",
    "        self.seasonal_test_kwargs=seasonal_test_kwargs\n",
    "        self.allowdrift=allowdrift\n",
    "        self.allowmean=allowmean\n",
    "        self.blambda=blambda\n",
    "        self.biasadj=biasadj\n",
    "        self.parallel=parallel\n",
    "        self.num_cores=num_cores\n",
    "        self.season_length=season_length\n",
    "        self.alias = alias\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the AutoARIMA model.\n",
    "\n",
    "        Fit an AutoARIMA to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: AutoARIMA fitted model.\n",
    "        \"\"\"\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            self.model_ = auto_arima_f(\n",
    "                x=y,\n",
    "                d=self.d,\n",
    "                D=self.D,\n",
    "                max_p=self.max_p,\n",
    "                max_q=self.max_q,\n",
    "                max_P=self.max_P,\n",
    "                max_Q=self.max_Q,\n",
    "                max_order=self.max_order,\n",
    "                max_d=self.max_d,\n",
    "                max_D=self.max_D,\n",
    "                start_p=self.start_p,\n",
    "                start_q=self.start_q,\n",
    "                start_P=self.start_P,\n",
    "                start_Q=self.start_Q,\n",
    "                stationary=self.stationary,\n",
    "                seasonal=self.seasonal,\n",
    "                ic=self.ic,\n",
    "                stepwise=self.stepwise,\n",
    "                nmodels=self.nmodels,\n",
    "                trace=self.trace,\n",
    "                approximation=self.approximation,\n",
    "                method=self.method,\n",
    "                truncate=self.truncate,\n",
    "                xreg=X,\n",
    "                test=self.test,\n",
    "                test_kwargs=self.test_kwargs,\n",
    "                seasonal_test=self.seasonal_test,\n",
    "                seasonal_test_kwargs=self.seasonal_test_kwargs,\n",
    "                allowdrift=self.allowdrift,\n",
    "                allowmean=self.allowmean,\n",
    "                blambda=self.blambda,\n",
    "                biasadj=self.biasadj,\n",
    "                parallel=self.parallel,\n",
    "                num_cores=self.num_cores,\n",
    "                period=self.season_length\n",
    "            )\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "            self, \n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted AutoArima.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        fcst = forecast_arima(self.model_, h=h, xreg=X, level=level)\n",
    "        mean = fcst['mean']\n",
    "        if level is None:\n",
    "            return {'mean': mean}\n",
    "        level = sorted(level)\n",
    "        return {\n",
    "            'mean': mean,\n",
    "            **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "            **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "        }\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        \"\"\"Access fitted AutoArima insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = fitted_arima(self.model_)\n",
    "        res = {'fitted': mean}\n",
    "        if level is not None:\n",
    "            se = np.sqrt(self.model_['sigma2'])\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient AutoARIMA predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            mod = auto_arima_f(\n",
    "                x=y,\n",
    "                d=self.d,\n",
    "                D=self.D,\n",
    "                max_p=self.max_p,\n",
    "                max_q=self.max_q,\n",
    "                max_P=self.max_P,\n",
    "                max_Q=self.max_Q,\n",
    "                max_order=self.max_order,\n",
    "                max_d=self.max_d,\n",
    "                max_D=self.max_D,\n",
    "                start_p=self.start_p,\n",
    "                start_q=self.start_q,\n",
    "                start_P=self.start_P,\n",
    "                start_Q=self.start_Q,\n",
    "                stationary=self.stationary,\n",
    "                seasonal=self.seasonal,\n",
    "                ic=self.ic,\n",
    "                stepwise=self.stepwise,\n",
    "                nmodels=self.nmodels,\n",
    "                trace=self.trace,\n",
    "                approximation=self.approximation,\n",
    "                method=self.method,\n",
    "                truncate=self.truncate,\n",
    "                xreg=X,\n",
    "                test=self.test,\n",
    "                test_kwargs=self.test_kwargs,\n",
    "                seasonal_test=self.seasonal_test,\n",
    "                seasonal_test_kwargs=self.seasonal_test_kwargs,\n",
    "                allowdrift=self.allowdrift,\n",
    "                allowmean=self.allowmean,\n",
    "                blambda=self.blambda,\n",
    "                biasadj=self.biasadj,\n",
    "                parallel=self.parallel,\n",
    "                num_cores=self.num_cores,\n",
    "                period=self.season_length\n",
    "            )\n",
    "        fcst = forecast_arima(mod, h, xreg=X_future, level=level)\n",
    "        res = {'mean': fcst['mean']}\n",
    "        if fitted:\n",
    "            res['fitted'] = fitted_arima(mod)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            res = {\n",
    "                **res,\n",
    "                **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "                **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "            }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = np.sqrt(mod['sigma2'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "def test_class(cls_, x, h, skip_insample=False, level=None, test_forward=False):\n",
    "    cls_ = cls_.fit(x)\n",
    "    fcst_cls = cls_.predict(h=h)\n",
    "    test_eq(len(fcst_cls['mean']), h)\n",
    "    # test fit + predict equals forecast\n",
    "    test_eq(\n",
    "        cls_.forecast(y=x, h=h)['mean'],\n",
    "        fcst_cls['mean']\n",
    "    )\n",
    "    if not skip_insample:\n",
    "        test_eq(len(cls_.predict_in_sample()['fitted']), len(x))\n",
    "        assert isinstance(cls_.predict_in_sample()['fitted'], np.ndarray)\n",
    "        np.testing.assert_array_equal(\n",
    "            cls_.forecast(y=x, h=h, fitted=True)['fitted'],\n",
    "            cls_.predict_in_sample()['fitted'], \n",
    "        )\n",
    "        if test_forward:\n",
    "            np.testing.assert_array_equal(\n",
    "                cls_.forward(y=x, h=h, fitted=True)['fitted'],\n",
    "                cls_.predict_in_sample()['fitted'], \n",
    "            )\n",
    "    \n",
    "    def check_dict_equals(dict_1, dict_2):\n",
    "        if not dict_1.keys() == dict_2.keys():\n",
    "            return False\n",
    "        return all(np.array_equal(dict_1[key], dict_2[key], equal_nan=True) for key in dict_1)\n",
    "    \n",
    "    if test_forward:\n",
    "        if not check_dict_equals(cls_.predict(h=h), cls_.forward(y=x, h=h)):\n",
    "            raise Exception('predict and forward methods are not equal')\n",
    "    \n",
    "    if level is not None:\n",
    "        fcst_cls = cls_.predict(h=h, level=level)\n",
    "        fcst_forecast = cls_.forecast(y=x, h=h, level=level)\n",
    "        if not check_dict_equals(fcst_cls, fcst_forecast):\n",
    "            raise Exception('predict and forecast methods are not equal with levels')\n",
    "            \n",
    "        if test_forward:\n",
    "            if not check_dict_equals(cls_.predict(h=h, level=level), \n",
    "                                     cls_.forward(y=x, h=h, level=level)):\n",
    "                raise Exception('predict and forward methods are not equal with levels')\n",
    "        \n",
    "        if not skip_insample:\n",
    "            fcst_cls = cls_.predict_in_sample(level=level)\n",
    "            fcst_forecast = cls_.forecast(y=x, h=h, level=level, fitted=True)\n",
    "            fcst_forecast = {key: val for key, val in fcst_forecast.items() if 'fitted' in key}\n",
    "            if not check_dict_equals(fcst_cls, fcst_forecast):\n",
    "                raise Exception(\n",
    "                    'predict and forecast methods are not equal with ' \n",
    "                    'levels for fitted values '\n",
    "                )\n",
    "            if test_forward:\n",
    "                fcst_forward = cls_.forecast(y=x, h=h, level=level, fitted=True)\n",
    "                fcst_forward = {key: val for key, val in fcst_forward.items() if 'fitted' in key}\n",
    "                if not check_dict_equals(fcst_cls, fcst_forward):\n",
    "                    raise Exception(\n",
    "                        'predict and forward methods are not equal with ' \n",
    "                        'levels for fitted values '\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "arima = AutoARIMA(season_length=12) \n",
    "test_class(arima, x=ap, h=12, level=[90, 80])\n",
    "fcst_arima = arima.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoARIMA()),\n",
    "    'AutoARIMA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoARIMA(alias='AutoARIMA_seasonality')),\n",
    "    'AutoARIMA_seasonality'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoARIMA's usage example\n",
    "\n",
    "from statsforecast.models import AutoARIMA\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "arima = AutoARIMA(season_length=4)\n",
    "arima = arima.fit(y=ap)\n",
    "y_hat_dict = arima.predict(h=4, level=[80])\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoETS(_TS):\n",
    "    \"\"\"Automatic Exponential Smoothing model.\n",
    "\n",
    "    Automatically selects the best ETS (Error, Trend, Seasonality) \n",
    "    model using an information criterion. Default is Akaike Information Criterion (AICc), while particular models are estimated using maximum likelihood.\n",
    "    The state-space equations can be determined based on their $M$ multiplicative, $A$ additive, \n",
    "    $Z$ optimized or $N$ ommited components. The `model` string parameter defines the ETS equations: \n",
    "    E in [$M, A, Z$], T in [$N, A, M, Z$], and S in [$N, A, M, Z$].\n",
    "    \n",
    "    For example when model='ANN' (additive error, no trend, and no seasonality), ETS will \n",
    "    explore only a simple exponential smoothing.\n",
    "    \n",
    "    If the component is selected as 'Z', it operates as a placeholder to ask the AutoETS model\n",
    "    to figure out the best parameter.\n",
    "    \n",
    "    **Parameters:**<br>\n",
    "    `model`: str, controlling state-space-equations.<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `damped`: bool, a parameter that 'dampens' the trend. <br>\n",
    "    `alias`: str, Custom name of the model. Default `AutoETS`.<br>\n",
    "    \n",
    "    **Note:**<br>\n",
    "    This implementation is a mirror of Hyndman's [forecast::ets](https://github.com/robjhyndman/forecast).\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Rob J. Hyndman, Yeasmin Khandakar (2008). \"Automatic Time Series Forecasting: The forecast package for R\"](https://www.jstatsoft.org/article/view/v027i03).\n",
    "    \n",
    "    [Hyndman, Rob, et al (2008). \"Forecasting with exponential smoothing: the state space approach\"](https://robjhyndman.com/expsmooth/).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int = 1,\n",
    "            model: str = 'ZZZ',\n",
    "            damped: Optional[bool] = None,\n",
    "            alias: str = 'AutoETS',\n",
    "        ):\n",
    "        self.season_length = season_length\n",
    "        self.model = model\n",
    "        self.damped = damped\n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the Exponential Smoothing model.\n",
    "\n",
    "        Fit an Exponential Smoothing model to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: Exponential Smoothing fitted model.\n",
    "        \"\"\"\n",
    "        self.model_ = ets_f(y, m=self.season_length, model=self.model, damped=self.damped)\n",
    "        self.model_['actual_residuals'] = y - self.model_['fitted']\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            level: Optional[List[int]] = None \n",
    "        ):\n",
    "        \"\"\"Predict with fitted Exponential Smoothing.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        fcst = forecast_ets(self.model_, h=h, level=level)\n",
    "        mean = fcst['mean']\n",
    "        if level is None:\n",
    "            return {'mean': mean}\n",
    "        level = sorted(level)\n",
    "        return {\n",
    "            'mean': mean,\n",
    "            **{f'lo-{l}': fcst[f'lo-{l}'] for l in reversed(level)},\n",
    "            **{f'hi-{l}': fcst[f'hi-{l}'] for l in level},\n",
    "        }\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        \"\"\"Access fitted Exponential Smoothing insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            residuals = self.model_['actual_residuals']\n",
    "            se = _calculate_sigma(residuals, len(residuals) - self.model_['n_params'])\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient Exponential Smoothing predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mod = ets_f(y, m=self.season_length, model=self.model, damped=self.damped)\n",
    "        fcst = forecast_ets(mod, h=h, level=level)\n",
    "        keys = ['mean']\n",
    "        if fitted:\n",
    "            keys.append('fitted')\n",
    "        res = {key: fcst[key] for key in keys}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            res = {\n",
    "                **res,\n",
    "                **{f'lo-{l}': fcst[f'lo-{l}'] for l in reversed(level)},\n",
    "                **{f'hi-{l}': fcst[f'hi-{l}'] for l in level},\n",
    "            }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = _calculate_sigma(y - mod['fitted'], len(y) - mod['n_params'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forward(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Apply fitted AutoTheta to a new time series.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'model_'):\n",
    "            raise Exception('You have to use the `fit` method first')\n",
    "        mod = forward_ets(self.model_, y=y)\n",
    "        fcst = forecast_ets(mod, h=h, level=level)\n",
    "        keys = ['mean']\n",
    "        if fitted:\n",
    "            keys.append('fitted')\n",
    "        res = {key: fcst[key] for key in keys}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            res = {\n",
    "                **res,\n",
    "                **{f'lo-{l}': fcst[f'lo-{l}'] for l in reversed(level)},\n",
    "                **{f'hi-{l}': fcst[f'hi-{l}'] for l in level},\n",
    "            }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = _calculate_sigma(y - mod['fitted'], len(y) - mod['n_params'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "autoets = AutoETS(season_length=12)\n",
    "test_class(autoets, x=ap, h=12, level=[90, 80], test_forward=True)\n",
    "fcst_ets = autoets.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoETS()),\n",
    "    'AutoETS'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoETS(alias='AutoETS_custom')),\n",
    "    'AutoETS_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "autoets = AutoETS(season_length=12, model='AAA')\n",
    "test_class(autoets, x=ap, h=12, level=[90, 80])\n",
    "fcst_ets = autoets.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| hide \n",
    "# Test whether forecast and fit-predict generate the same result \n",
    "models = ['ANNN', 'AANN', 'ANAN', 'AAAN', 'AAND', 'AAAD', # class 1 \n",
    "          'MNNN', 'MANN', 'MAND', 'MNAN', 'MAAN', 'MAAD', # class 2 \n",
    "          'MNMN', 'MAMN', 'MAMD'] # class 3 \n",
    "\n",
    "for k in range(0,len(models)): \n",
    "    mod = models[k][0:3]\n",
    "    damped_val = models[k][-1]\n",
    "    if damped_val == 'N': \n",
    "        damped = False\n",
    "    else: \n",
    "        damped = True\n",
    "        \n",
    "    ets = AutoETS(season_length=12, model=mod, damped=damped) \n",
    "    test_class(ets, x=ap, h=13, level=[90, 80], test_forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoETS' usage example\n",
    "\n",
    "from statsforecast.models import AutoETS\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "# Multiplicative trend, optimal error and seasonality\n",
    "autoets = AutoETS(model='ZMZ',  \n",
    "              season_length=4)\n",
    "autoets = autoets.fit(y=ap)\n",
    "y_hat_dict = autoets.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ETS(AutoETS):\n",
    "    @classmethod\n",
    "    def _warn(cls):\n",
    "        warnings.warn(\n",
    "            '`ETS` will be deprecated in future versions of `StatsForecast`. Please use `AutoETS` instead.',\n",
    "            category=FutureWarning,\n",
    "            stacklevel=2\n",
    "        )\n",
    "        \n",
    "    def __init__(self, season_length: int = 1, model: str = 'ZZZ', \n",
    "                 damped: Optional[bool] = None,\n",
    "                 alias: str = 'ETS'):\n",
    "        ETS._warn()\n",
    "        self.season_length = season_length\n",
    "        self.model = model\n",
    "        self.damped = damped\n",
    "        self.alias = alias\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets = ETS(model='ZMZ', season_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ets = ETS(model='ZMZ', season_length=4)\n",
    "autoets = AutoETS(model='ZMZ',  \n",
    "              season_length=4)\n",
    "test_eq(ets.forecast(y=ap, h=12)['mean'], \n",
    "        autoets.forecast(y=ap, h=12)['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(ETS()),\n",
    "    'ETS'\n",
    ")\n",
    "test_eq(\n",
    "    repr(ETS(alias='ETS_custom')),\n",
    "    'ETS_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoCES(_TS):\n",
    "    \"\"\"Complex Exponential Smoothing model.\n",
    "\n",
    "    Automatically selects the best Complex Exponential Smoothing\n",
    "    model using an information criterion. Default is Akaike Information Criterion (AICc), while particular \n",
    "    models are estimated using maximum likelihood.\n",
    "    The state-space equations can be determined based on their $S$ simple, $P$ parial, \n",
    "    $Z$ optimized or $N$ ommited components. The `model` string parameter defines the \n",
    "    kind of CES model: $N$ for simple CES (withous seasonality), $S$ for simple seasonality (lagged CES),\n",
    "    $P$ for partial seasonality (without complex part), $F$ for full seasonality (lagged CES\n",
    "    with real and complex seasonal parts).\n",
    "    \n",
    "    If the component is selected as 'Z', it operates as a placeholder to ask the AutoCES model\n",
    "    to figure out the best parameter.\n",
    "    \n",
    "    **Parameters:**<br>\n",
    "    `model`: str, controlling state-space-equations.<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `alias`: str, Custom name of the model. Default `CES`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Svetunkov, Ivan & Kourentzes, Nikolaos. (2015). \"Complex Exponential Smoothing\". 10.13140/RG.2.1.3757.2562. ](https://onlinelibrary.wiley.com/doi/full/10.1002/nav.22074).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int = 1,\n",
    "            model: str = 'Z',\n",
    "            alias: str = 'CES'\n",
    "        ):\n",
    "        self.season_length = season_length\n",
    "        self.model = model\n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the Complex Exponential Smoothing model.\n",
    "\n",
    "        Fit the Comples Exponential Smoothing model to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: Complex Exponential Smoothing fitted model.\n",
    "        \"\"\"\n",
    "        self.model_ = auto_ces(y, m=self.season_length, model=self.model)\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted Exponential Smoothing.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = forecast_ces(self.model_, h=h)['mean']\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted Exponential Smoothing insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient Complex Exponential Smoothing predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mod = auto_ces(y, m=self.season_length, model=self.model)\n",
    "        fcst = forecast_ces(mod, h)\n",
    "        keys = ['mean']\n",
    "        if fitted:\n",
    "            keys.append('fitted')\n",
    "        res = {key: fcst[key] for key in keys}\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ces = AutoCES(season_length=12)\n",
    "test_class(ces, x=ap, h=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoCES()),\n",
    "    'CES'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoCES(alias='AutoCES_custom')),\n",
    "    'AutoCES_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CES' usage example\n",
    "\n",
    "from statsforecast.models import AutoCES\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "# Multiplicative trend, optimal error and seasonality\n",
    "ces = AutoCES(model='Z',  \n",
    "              season_length=4)\n",
    "ces = ces.fit(y=ap)\n",
    "y_hat_dict = ces.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoTheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoTheta(_TS):\n",
    "    \"\"\"AutoTheta model.\n",
    "\n",
    "    Automatically selects the best Theta (Standard Theta Model ('STM'),\n",
    "    Optimized Theta Model ('OTM'), Dynamic Standard Theta Model ('DSTM'),\n",
    "    Dynamic Optimized Theta Model ('DOTM')) model using mse. \n",
    "    \n",
    "    **Parameters:**<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `decomposition_type`: str, Sesonal decomposition type, 'multiplicative' (default) or 'additive'.<br>\n",
    "    `model`: str, controlling Theta Model. By default searchs the best model.<br>\n",
    "    `alias`: str, Custom name of the model. Default `AutoTheta`.<br>\n",
    "  \n",
    "    **References:**<br>\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting](https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        season_length: int = 1,\n",
    "        decomposition_type: str = 'multiplicative',\n",
    "        model: Optional[str] = None,\n",
    "        alias: str = 'AutoTheta'\n",
    "    ):\n",
    "        self.season_length = season_length\n",
    "        self.decomposition_type = decomposition_type\n",
    "        self.model = model\n",
    "        self.alias = alias\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the AutoTheta model.\n",
    "\n",
    "        Fit an AutoTheta model to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: AutoTheta fitted model.\n",
    "        \"\"\"\n",
    "        self.model_ = auto_theta(y=y, m=self.season_length, \n",
    "                                 model=self.model, \n",
    "                                 decomposition_type=self.decomposition_type)\n",
    "        self.model_['fitted'] = y - self.model_['residuals']\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "            self, \n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted AutoTheta.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        fcst = forecast_theta(self.model_, h=h, level=level)\n",
    "        return fcst\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        \"\"\"Access fitted AutoTheta insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            se = np.std(self.model_['residuals'][3:], ddof=1)\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient AutoTheta predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mod = auto_theta(\n",
    "            y=y, \n",
    "            m=self.season_length, \n",
    "            model=self.model, \n",
    "            decomposition_type=self.decomposition_type\n",
    "        )\n",
    "        res = forecast_theta(mod, h, level=level)\n",
    "        if fitted:\n",
    "            res['fitted'] = y - mod['residuals']\n",
    "        if level is not None and fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = np.std(mod['residuals'][3:], ddof=1)\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forward(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Apply fitted AutoTheta to a new time series.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'model_'):\n",
    "            raise Exception('You have to use the `fit` method first')\n",
    "        mod = forward_theta(self.model_, y=y)\n",
    "        res = forecast_theta(mod, h, level=level)\n",
    "        if fitted:\n",
    "            res['fitted'] = y - mod['residuals']\n",
    "        if level is not None and fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = np.std(mod['residuals'][3:], ddof=1)\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "theta = AutoTheta(season_length=12)\n",
    "test_class(theta, x=ap, h=12, level=[80, 90], test_forward=True)\n",
    "fcst_theta = theta.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "theta.forward(np.zeros(10), h=12, level=[80, 90], fitted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoTheta()),\n",
    "    'AutoTheta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoTheta(alias='AutoTheta_custom')),\n",
    "    'AutoTheta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoTheta's usage example\n",
    "\n",
    "from statsforecast.models import AutoTheta\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "theta = AutoTheta(season_length=4)\n",
    "theta = theta.fit(y=ap)\n",
    "y_hat_dict = theta.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 2. ExponentialSmoothing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@njit\n",
    "def _ses_fcst_mse(x: np.ndarray, alpha: float) -> Tuple[float, float, np.ndarray]:\n",
    "    \"\"\"Perform simple exponential smoothing on a series.\n",
    "\n",
    "    This function returns the one step ahead prediction\n",
    "    as well as the mean squared error of the fit.\n",
    "    \"\"\"\n",
    "    smoothed = x[0]\n",
    "    n = x.size\n",
    "    mse = 0.\n",
    "    fitted = np.full(n, np.nan, np.float32)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        smoothed = (alpha * x[i - 1] + (1 - alpha) * smoothed).item()\n",
    "        error = x[i] - smoothed\n",
    "        mse += error * error\n",
    "        fitted[i] = smoothed\n",
    "\n",
    "    mse /= n\n",
    "    forecast = alpha * x[-1] + (1 - alpha) * smoothed\n",
    "    return forecast, mse, fitted\n",
    "\n",
    "\n",
    "def _ses_mse(alpha: float, x: np.ndarray) -> float:\n",
    "    \"\"\"Compute the mean squared error of a simple exponential smoothing fit.\"\"\"\n",
    "    _, mse, _ = _ses_fcst_mse(x, alpha)\n",
    "    return mse\n",
    "\n",
    "\n",
    "@njit\n",
    "def _ses_forecast(x: np.ndarray, alpha: float) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"One step ahead forecast with simple exponential smoothing.\"\"\"\n",
    "    forecast, _, fitted = _ses_fcst_mse(x, alpha)\n",
    "    return forecast, fitted\n",
    "\n",
    "\n",
    "@njit\n",
    "def _demand(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract the positive elements of a vector.\"\"\"\n",
    "    return x[x > 0]\n",
    "\n",
    "\n",
    "@njit\n",
    "def _intervals(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the intervals between non zero elements of a vector.\"\"\"\n",
    "    y = []\n",
    "\n",
    "    ctr = 1\n",
    "    for val in x:\n",
    "        if val == 0:\n",
    "            ctr += 1\n",
    "        else:\n",
    "            y.append(ctr)\n",
    "            ctr = 1\n",
    "\n",
    "    return np.array(y)\n",
    "\n",
    "\n",
    "@njit\n",
    "def _probability(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the element probabilities of being non zero.\"\"\"\n",
    "    return (x != 0).astype(np.int32)\n",
    "\n",
    "\n",
    "def _optimized_ses_forecast(\n",
    "        x: np.ndarray,\n",
    "        bounds: Sequence[Tuple[float, float]] = [(0.1, 0.3)]\n",
    "    ) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Searches for the optimal alpha and computes SES one step forecast.\"\"\"\n",
    "    alpha = minimize(\n",
    "        fun=_ses_mse,\n",
    "        x0=(0,),\n",
    "        args=(x,),\n",
    "        bounds=bounds,\n",
    "        method='L-BFGS-B'\n",
    "    ).x[0]\n",
    "    forecast, fitted = _ses_forecast(x, alpha)\n",
    "    return forecast, fitted\n",
    "\n",
    "\n",
    "@njit\n",
    "def _chunk_sums(array: np.ndarray, chunk_size: int) -> np.ndarray:\n",
    "    \"\"\"Splits an array into chunks and returns the sum of each chunk.\"\"\"\n",
    "    n = array.size\n",
    "    n_chunks = n // chunk_size\n",
    "    sums = np.empty(n_chunks)\n",
    "    for i, start in enumerate(range(0, n, chunk_size)):\n",
    "        sums[i] = array[start : start + chunk_size].sum()\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _ses(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "        alpha: float, # smoothing parameter\n",
    "    ): \n",
    "    fcst, _, fitted_vals = _ses_fcst_mse(y, alpha)\n",
    "    mean = _repeat_val(val=fcst, h=h)\n",
    "    fcst = {'mean': mean}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimpleExponentialSmoothing(_TS):\n",
    "    \"\"\"SimpleExponentialSmoothing model.\n",
    "\n",
    "    Uses a weighted average of all past observations where the weights decrease exponentially into the past. \n",
    "    Suitable for data with no clear trend or seasonality. \n",
    "    Assuming there are $t$ observations, the one-step forecast is given by: $\\hat{y}_{t+1} = \\\\alpha y_t + (1-\\\\alpha) \\hat{y}_{t-1}$\n",
    "\n",
    "    The rate $0 \\leq \\\\alpha \\leq 1$ at which the weights decrease is called the smoothing parameter. When $\\\\alpha = 1$, SES is equal to the naive method.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `alpha`: float, smoothing parameter.<br>\n",
    "    `alias`: str, Custom name of the model. Default `SES`.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Charles C Holt (1957). “Forecasting seasonals and trends by exponentially weighted moving averages”](https://doi.org/10.1016/j.ijforecast).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            alpha: float,\n",
    "            alias: str = 'SES'\n",
    "        ):\n",
    "        self.alpha = alpha\n",
    "        self.alias = alias\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the SimpleExponentialSmoothing model.\n",
    "\n",
    "        Fit an SimpleExponentialSmoothing to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: SimpleExponentialSmoothing fitted model.\n",
    "        \"\"\"\n",
    "        mod = _ses(y=y, alpha=self.alpha, h=1, fitted=True)\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted SimpleExponentialSmoothing.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted SimpleExponentialSmoothing insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient SimpleExponentialSmoothing predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _ses(y=y, h=h, fitted=fitted, alpha=self.alpha)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ses = SimpleExponentialSmoothing(alpha=0.1)\n",
    "test_class(ses, x=ap, h=12)\n",
    "#more tests\n",
    "ses = ses.fit(ap)\n",
    "fcst_ses = ses.predict(12)\n",
    "test_close(fcst_ses['mean'], np.repeat(460.3028, 12), eps=1e-4)\n",
    "#to recover these residuals from R\n",
    "#you have to pass initial=\"simple\"\n",
    "#in the `ses` function\n",
    "np.testing.assert_allclose(\n",
    "    ses.predict_in_sample()['fitted'][[0, 1, -1]], \n",
    "    np.array([np.nan, 118 - 6., 432 + 31.447525])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SimpleExponentialSmoothing(alpha=0.1)),\n",
    "    'SES'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SimpleExponentialSmoothing(alpha=0.1, alias='SES_custom')),\n",
    "    'SES_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleExponentialSmoothing's usage example\n",
    "\n",
    "from statsforecast.models import SimpleExponentialSmoothing\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "ses = SimpleExponentialSmoothing(alpha=0.5)\n",
    "ses = ses.fit(y=ap)\n",
    "y_hat_dict = ses.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSmoothOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _ses_optimized(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ):\n",
    "    fcst_, fitted_vals = _optimized_ses_forecast(y, [(0.01, 0.99)])\n",
    "    mean = _repeat_val(val=fcst_, h=h)\n",
    "    fcst = {'mean': mean}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimpleExponentialSmoothingOptimized(_TS):\n",
    "    \"\"\"SimpleExponentialSmoothing model.\n",
    "\n",
    "    Uses a weighted average of all past observations where the weights decrease exponentially into the past. \n",
    "    Suitable for data with no clear trend or seasonality. \n",
    "    Assuming there are $t$ observations, the one-step forecast is given by: $\\hat{y}_{t+1} = \\\\alpha y_t + (1-\\\\alpha) \\hat{y}_{t-1}$\n",
    "\n",
    "    The smoothing parameter $\\\\alpha^*$ is optimized by square error minimization.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `alias`: str, Custom name of the model. Default `SESOpt`.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Charles C Holt (1957). “Forecasting seasonals and trends by exponentially weighted moving averages”](https://doi.org/10.1016/j.ijforecast).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, alias: str = 'SESOpt'):\n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the SimpleExponentialSmoothingOptimized model.\n",
    "\n",
    "        Fit an SimpleExponentialSmoothingOptimized to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: SimpleExponentialSmoothingOptimized fitted model.\n",
    "        \"\"\"\n",
    "        mod = _ses_optimized(y=y, h=1, fitted=True)\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted SimpleExponentialSmoothingOptimized.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "\n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted SimpleExponentialSmoothingOptimized insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient SimpleExponentialSmoothingOptimized predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _ses_optimized(y=y, h=h, fitted=fitted)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ses_op = SimpleExponentialSmoothingOptimized()\n",
    "test_class(ses_op, x=ap, h=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SimpleExponentialSmoothingOptimized()),\n",
    "    'SESOpt'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SimpleExponentialSmoothingOptimized(alias='SESOpt_custom')),\n",
    "    'SESOpt_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleExponentialSmoothingOptimized's usage example\n",
    "\n",
    "from statsforecast.models import SimpleExponentialSmoothingOptimized\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "seso = SimpleExponentialSmoothingOptimized()\n",
    "seso = seso.fit(y=ap)\n",
    "y_hat_dict = seso.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeasonalSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _seasonal_exponential_smoothing(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "        season_length: int, # length of season\n",
    "        alpha: float, # smoothing parameter\n",
    "    ):\n",
    "    if y.size < season_length:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    season_vals = np.empty(season_length, np.float32)\n",
    "    fitted_vals = np.full(y.size, np.nan, np.float32)\n",
    "    for i in range(season_length):\n",
    "        season_vals[i], fitted_vals[i::season_length] = _ses_forecast(y[i::season_length], alpha)\n",
    "    out = _repeat_val_seas(season_vals=season_vals, h=h, season_length=season_length)\n",
    "    fcst = {'mean': out}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeasonalExponentialSmoothing(_TS):\n",
    "    \"\"\"SeasonalExponentialSmoothing model.\n",
    "\n",
    "    Uses a weighted average of all past observations where the weights decrease exponentially into the past. \n",
    "    Suitable for data with no clear trend or seasonality. \n",
    "    Assuming there are $t$ observations and season $s$, the one-step forecast is given by: \n",
    "    $\\hat{y}_{t+1,s} = \\\\alpha y_t + (1-\\\\alpha) \\hat{y}_{t-1,s}$\n",
    "\n",
    "    **Note:**<br>\n",
    "    This method is an extremely simplified of Holt-Winter's method where the trend and level are set to zero.\n",
    "    And a single seasonal smoothing parameter $\\\\alpha$ is shared across seasons.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `alpha`: float, smoothing parameter.<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `alias`: str, Custom name of the model. Default `SeasonalES`.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Charles. C. Holt (1957). \"Forecasting seasonals and trends by exponentially weighted moving averages\", ONR Research Memorandum, Carnegie Institute of Technology 52.](https://www.sciencedirect.com/science/article/abs/pii/S0169207003001134).\n",
    "\n",
    "    [Peter R. Winters (1960). \"Forecasting sales by exponentially weighted moving averages\". Management Science](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.3.324).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int,\n",
    "            alpha: float,\n",
    "            alias: str = 'SeasonalES'\n",
    "        ):\n",
    "        self.season_length = season_length\n",
    "        self.alpha = alpha\n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the SeasonalExponentialSmoothing model.\n",
    "\n",
    "        Fit an SeasonalExponentialSmoothing to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: SeasonalExponentialSmoothing fitted model.\n",
    "        \"\"\"\n",
    "        mod = _seasonal_exponential_smoothing(\n",
    "            y=y, \n",
    "            season_length=self.season_length, \n",
    "            alpha=self.alpha,\n",
    "            fitted=True,\n",
    "            h=self.season_length,\n",
    "        )\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted SeasonalExponentialSmoothing.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val_seas(self.model_['mean'], season_length=self.season_length, h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted SeasonalExponentialSmoothing insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient SeasonalExponentialSmoothing predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _seasonal_exponential_smoothing(\n",
    "            y=y, h=h, fitted=fitted, \n",
    "            alpha=self.alpha,\n",
    "            season_length=self.season_length\n",
    "        )\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "seas_es = SeasonalExponentialSmoothing(season_length=12, alpha=1.)\n",
    "test_class(seas_es, x=ap, h=12)\n",
    "test_eq(seas_es.predict_in_sample()['fitted'][-3:],  np.array([461 - 54., 390 - 28., 432 - 27.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SeasonalExponentialSmoothing(season_length=12, alpha=1.)),\n",
    "    'SeasonalES'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SeasonalExponentialSmoothing(season_length=12, alpha=1., alias='SeasonalES_custom')),\n",
    "    'SeasonalES_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeasonalExponentialSmoothing's usage example\n",
    "\n",
    "from statsforecast.models import SeasonalExponentialSmoothing\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = SeasonalExponentialSmoothing(alpha=0.5, season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeasonalSmoothOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _seasonal_ses_optimized(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool , # fitted values\n",
    "        season_length: int, # season length\n",
    "    ): \n",
    "    if y.size < season_length:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    season_vals = np.empty(season_length, np.float32)\n",
    "    fitted_vals = np.full(y.size, np.nan, np.float32)\n",
    "    for i in range(season_length):\n",
    "        season_vals[i], fitted_vals[i::season_length] = _optimized_ses_forecast(y[i::season_length], [(0.01, 0.99)])\n",
    "    out = _repeat_val_seas(season_vals=season_vals, h=h, season_length=season_length)\n",
    "    fcst = {'mean': out}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeasonalExponentialSmoothingOptimized(_TS):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int,\n",
    "            alias: str = 'SeasESOpt'\n",
    "        ):\n",
    "        \"\"\"SeasonalExponentialSmoothingOptimized model.\n",
    "\n",
    "        Uses a weighted average of all past observations where the weights decrease exponentially into the past. \n",
    "        Suitable for data with no clear trend or seasonality. \n",
    "        Assuming there are $t$ observations and season $s$, the one-step forecast is given by: \n",
    "        $\\hat{y}_{t+1,s} = \\\\alpha y_t + (1-\\\\alpha) \\hat{y}_{t-1,s}$\n",
    "        \n",
    "        The smoothing parameter $\\\\alpha^*$ is optimized by square error minimization.        \n",
    "\n",
    "        **Note:**<br>\n",
    "        This method is an extremely simplified of Holt-Winter's method where the trend and level are set to zero.\n",
    "        And a single seasonal smoothing parameter $\\\\alpha$ is shared across seasons.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "        `alias`: str, Custom name of the model. Default `SeasESOpt`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Charles. C. Holt (1957). \"Forecasting seasonals and trends by exponentially weighted moving averages\", ONR Research Memorandum, Carnegie Institute of Technology 52.](https://www.sciencedirect.com/science/article/abs/pii/S0169207003001134).\n",
    "\n",
    "        [Peter R. Winters (1960). \"Forecasting sales by exponentially weighted moving averages\". Management Science](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.3.324).\n",
    "        \"\"\"\n",
    "        self.season_length = season_length\n",
    "        self.alias = alias\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the SeasonalExponentialSmoothingOptimized model.\n",
    "\n",
    "        Fit an SeasonalExponentialSmoothingOptimized to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: SeasonalExponentialSmoothingOptimized fitted model.\n",
    "        \"\"\"\n",
    "        mod = _seasonal_ses_optimized(\n",
    "            y=y, \n",
    "            season_length=self.season_length, \n",
    "            fitted=True,\n",
    "            h=self.season_length,\n",
    "        )\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted SeasonalExponentialSmoothingOptimized.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val_seas(self.model_['mean'], season_length=self.season_length, h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted SeasonalExponentialSmoothingOptimized insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient SeasonalExponentialSmoothingOptimized predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _seasonal_ses_optimized(\n",
    "            y=y, h=h, fitted=fitted, \n",
    "            season_length=self.season_length\n",
    "        )\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "seas_es_opt = SeasonalExponentialSmoothingOptimized(season_length=12)\n",
    "test_class(seas_es_opt, x=ap, h=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SeasonalExponentialSmoothingOptimized(season_length=12)),\n",
    "    'SeasESOpt'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SeasonalExponentialSmoothingOptimized(season_length=12, alias='SeasESOpt_custom')),\n",
    "    'SeasESOpt_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeasonalExponentialSmoothingOptimized's usage example\n",
    "\n",
    "from statsforecast.models import SeasonalExponentialSmoothingOptimized\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = SeasonalExponentialSmoothingOptimized(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt's method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Holt(AutoETS): \n",
    "    \"\"\" Holt's method. \n",
    "\n",
    "    Also known as double exponential smoothing, Holt's method is an extension of exponential smoothing for series with a trend.\n",
    "    This implementation returns the corresponding `ETS` model with additive (A) or multiplicative (M) errors (so either 'AAN' or 'MAN'). \n",
    "\n",
    "    **Parameters:**<br>\n",
    "     `season_length`: int, number of observations per unit of time. Ex: 12 Monthly data. <br>  \n",
    "     `error_type`: The type of error of the ETS model. Can be additive (A) or multiplicative (M). <br> \n",
    "     `alias`: str, Custom name of the model. Default `Holt`.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    - [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Methods with trend\"](https://otexts.com/fpp3/holt.html).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int = 1, \n",
    "            error_type: str = 'A',\n",
    "            alias: str = 'Holt'\n",
    "        ): \n",
    "\n",
    "        self.season_length = season_length\n",
    "        self.error_type = error_type\n",
    "        self.alias = alias\n",
    "        model = error_type + 'AN'\n",
    "        super().__init__(season_length, model, alias=alias)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "holt = Holt(season_length=12, error_type='A')\n",
    "fcast_holt = holt.forecast(ap,12)\n",
    "\n",
    "ets = AutoETS(season_length=12, model='AAN')\n",
    "fcast_ets = ets.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_holt, \n",
    "    fcast_ets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "holt = Holt(season_length=12, error_type='A')\n",
    "holt.fit(ap)\n",
    "fcast_holt = holt.predict(12)\n",
    "\n",
    "ets = AutoETS(season_length=12, model='AAN')\n",
    "fcast_ets = ets.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_holt, \n",
    "    fcast_ets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(Holt()),\n",
    "    'Holt'\n",
    ")\n",
    "test_eq(\n",
    "    repr(Holt(alias='Holt_custom')),\n",
    "    'Holt_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.forecast, name='Holt.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.fit, name='Holt.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.predict, name='Holt.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.predict_in_sample, name='Holt.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.forward, name='Holt.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holt's usage example\n",
    "\n",
    "#from statsforecast.models import Holt\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = Holt(season_length=12, error_type='A')\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt-Winters' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class HoltWinters(AutoETS): \n",
    "    \"\"\" Holt-Winters' method. \n",
    "    \n",
    "    Also known as triple exponential smoothing, Holt-Winters' method is an extension of exponential smoothing for series that contain both trend and seasonality.\n",
    "    This implementation returns the corresponding `ETS` model with additive (A) or multiplicative (M) errors (so either 'AAA' or 'MAM'). \n",
    "    \n",
    "    **Parameters:**<br>\n",
    "     `season_length`: int, number of observations per unit of time. Ex: 12 Monthly data. <br>  \n",
    "     `error_type`: The type of error of the ETS model. Can be additive (A) or multiplicative (M). <br> \n",
    "    `alias`: str, Custom name of the model. Default `HoltWinters`.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    - [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Methods with seasonality\"](https://otexts.com/fpp3/holt-winters.html).\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int = 1, # season length\n",
    "            error_type: str = 'A', # error type\n",
    "            alias: str = 'HoltWinters'\n",
    "        ): \n",
    "        self.season_length = season_length\n",
    "        self.error_type = error_type\n",
    "        self.alias = alias\n",
    "        model = error_type + 'A' + error_type\n",
    "        super().__init__(season_length, model, alias=alias)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "hw = HoltWinters(season_length=12, error_type='A')\n",
    "fcast_hw = hw.forecast(ap,12)\n",
    "\n",
    "ets = AutoETS(season_length=12, model='AAA')\n",
    "fcast_ets = ets.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_hw, \n",
    "    fcast_ets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "hw = HoltWinters(season_length=12, error_type='A')\n",
    "hw.fit(ap)\n",
    "fcast_hw = hw.predict(12)\n",
    "\n",
    "ets = AutoETS(season_length=12, model='AAA')\n",
    "fcast_ets = ets.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_hw, \n",
    "    fcast_ets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(HoltWinters()),\n",
    "    'HoltWinters'\n",
    ")\n",
    "test_eq(\n",
    "    repr(HoltWinters(alias='HoltWinters_custom')),\n",
    "    'HoltWinters_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.forecast, name='HoltWinters.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.fit, name='HoltWinters.fit', title_level=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.predict, name='HoltWinters.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.predict_in_sample, name= 'HoltWinters.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.forward, name='HoltWinters.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holt-Winters' usage example\n",
    "\n",
    "#from statsforecast.models import HoltWinters\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = HoltWinters(season_length=12, error_type='A')\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 3. Baseline Models </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistoricAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _historic_average(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ):\n",
    "    mean = _repeat_val(val=y.mean(), h=h)\n",
    "    fcst = {'mean': mean}\n",
    "    if fitted:\n",
    "        #fitted_vals = np.full(y.size, np.nan, np.float32) # one-step ahead\n",
    "        #fitted_vals[1:] = y.cumsum()[:-1] / np.arange(1, y.size) \n",
    "        fitted_vals = _repeat_val(val=y.mean(), h=len(y))\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HistoricAverage(_TS):\n",
    "\n",
    "    def __init__(self, alias: str = 'HistoricAverage'):\n",
    "        \"\"\"HistoricAverage model.\n",
    "\n",
    "        Also known as mean method. Uses a simple average of all past observations. \n",
    "        Assuming there are $t$ observations, the one-step forecast is given by: \n",
    "        $$ \\hat{y}_{t+1} = \\\\frac{1}{t} \\sum_{j=1}^t y_j $$\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alias`: str, Custom name of the model. Default `HistoricAverage`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "        \"\"\"\n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the HistoricAverage model.\n",
    "\n",
    "        Fit an HistoricAverage to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: HistoricAverage fitted model.\n",
    "        \"\"\"        \n",
    "        mod = _historic_average(y, h=1, fitted=True)\n",
    "        mod = dict(mod) \n",
    "        residuals = y - mod['fitted']\n",
    "        mod['sigma'] = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "        mod['n'] = len(y)\n",
    "        self.model_ = mod\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self, \n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted HistoricAverage.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is not None: \n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(1 + (1 / self.model_['n']))\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        \"\"\"Access fitted HistoricAverage insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(1 + (1 / self.model_['n']))\n",
    "            res = _add_fitted_pi(res, se=sigmah, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient HistoricAverage predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _historic_average(y=y, h=h, fitted=fitted or (level is not None))\n",
    "        res = {'mean': out['mean']}\n",
    "        \n",
    "        if fitted:\n",
    "            res['fitted'] = out['fitted']\n",
    "        \n",
    "        if level is not None: \n",
    "            residuals = y - out['fitted']\n",
    "            sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "            sigmah = sigma * np.sqrt(1 + (1 / len(y)))\n",
    "            pred_int = _calculate_intervals(out, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                res = _add_fitted_pi(res=res, se=sigmah, level=level)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ha = HistoricAverage()\n",
    "test_class(ha, x=ap, h=12, level=[80, 90])\n",
    "#more tests\n",
    "ha.fit(ap)\n",
    "fcst_ha = ha.predict(12)\n",
    "test_close(fcst_ha['mean'], np.repeat(ap.mean(), 12), eps=1e-5)\n",
    "np.testing.assert_almost_equal(\n",
    "    ha.predict_in_sample()['fitted'][:4],\n",
    "    #np.array([np.nan, 112., 115., 120.6666667]), \n",
    "    np.array([280.2986,280.2986,280.2986,280.2986]), \n",
    "    decimal=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "ha = HistoricAverage()\n",
    "fcst_ha = ha.forecast(ap,12,None,None,(80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_ha['lo-80'],\n",
    "    np.repeat(126.0227,12),\n",
    "    decimal=4\n",
    ")\n",
    "_plot_insample_pi(fcst_ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(HistoricAverage()),\n",
    "    'HistoricAverage'\n",
    ")\n",
    "test_eq(\n",
    "    repr(HistoricAverage(alias='HistoricAverage_custom')),\n",
    "    'HistoricAverage_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HistoricAverage's usage example\n",
    "\n",
    "from statsforecast.models import HistoricAverage\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = HistoricAverage()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Naive(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'Naive'):\n",
    "        \"\"\"Naive model.\n",
    "\n",
    "         A random walk model, defined as $\\hat{y}_{t+1} = y_t$ $\\forall t$\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alias`: str, Custom name of the model. Default `Naive`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "        \"\"\"\n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the Naive model.\n",
    "\n",
    "        Fit an Naive to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: Naive fitted model.\n",
    "        \"\"\"\n",
    "        mod = _naive(y, h=1, fitted=True)\n",
    "        mod = dict(mod) \n",
    "        residuals = y - mod['fitted']\n",
    "        sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "        mod['sigma'] = sigma\n",
    "        self.model_ = mod\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "            self, \n",
    "            h: int, # forecasting horizon \n",
    "            X: Optional[np.ndarray] = None, # exogenous regressors\n",
    "            level: Optional[Tuple[int]] = None # confidence level\n",
    "        ):\n",
    "        \"\"\"Predict with fitted Naive.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is not None: \n",
    "            steps = np.arange(1,h+1)\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(steps)\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        \"\"\"Access fitted Naive insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient Naive predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _naive(y=y, h=h, fitted=fitted or (level is not None))\n",
    "        res = {'mean': out['mean']}\n",
    "        \n",
    "        if fitted:\n",
    "            res['fitted'] = out['fitted']\n",
    "        \n",
    "        if level is not None: \n",
    "            steps = np.arange(1,h+1)\n",
    "            residuals = y - out['fitted']\n",
    "            sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "            sigmah = sigma * np.sqrt(steps)\n",
    "            pred_int = _calculate_intervals(out, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "                \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - forecast\n",
    "naive = Naive()\n",
    "naive.forecast(ap, 12)\n",
    "naive.forecast(ap, 12, None, None, (80,95), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - fit & predict\n",
    "naive.fit(ap)\n",
    "naive.predict(12)\n",
    "naive.predict(12, None, (80,95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "naive = Naive()\n",
    "test_class(naive, x=ap, h=12, level=[90, 80])\n",
    "naive.fit(ap)\n",
    "fcst_naive = naive.predict(12)\n",
    "test_close(fcst_naive['mean'], np.repeat(ap[-1], 12), eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "naive = Naive()\n",
    "fcst_naive = naive.forecast(ap,12,None,None,(80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_naive['lo-80'],\n",
    "    np.array([388.7984, 370.9037, 357.1726, 345.5967, 335.3982, 326.1781, 317.6992, 309.8073, 302.3951, 295.3845, 288.7164, 282.3452]),\n",
    "    decimal=4\n",
    ") # this is almost equal since Hyndman's forecasts are rounded up to 4 decimals\n",
    "_plot_insample_pi(fcst_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(Naive()),\n",
    "    'Naive'\n",
    ")\n",
    "test_eq(\n",
    "    repr(Naive(alias='Naive_custom')),\n",
    "    'Naive_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive's usage example\n",
    "\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = Naive()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomWalkWithDrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _random_walk_with_drift(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ): \n",
    "    slope = (y[-1] - y[0]) / (y.size - 1)\n",
    "    mean = slope * (1 + np.arange(h)) + y[-1]\n",
    "    fcst = {'mean': mean.astype(np.float32), \n",
    "            'slope': np.array([slope], dtype=np.float32), \n",
    "            'last_y': np.array([y[-1]], dtype=np.float32)}\n",
    "    if fitted:\n",
    "        fitted_vals = np.full(y.size, np.nan, dtype=np.float32)\n",
    "        fitted_vals[1:] = (slope + y[:-1]).astype(np.float32)\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RandomWalkWithDrift(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'RWD'):\n",
    "        \"\"\"RandomWalkWithDrift model.\n",
    "\n",
    "        A variation of the naive method allows the forecasts to change over time. \n",
    "        The amout of change, called drift, is the average change seen in the historical data. \n",
    "\n",
    "        $$ \\hat{y}_{t+1} = y_t+\\\\frac{1}{t-1}\\sum_{j=1}^t (y_j-y_{j-1}) = y_t+ \\\\frac{y_t-y_1}{t-1} $$\n",
    "\n",
    "        From the previous equation, we can see that this is equivalent to extrapolating a line between \n",
    "        the first and the last observation. \n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alias`: str, Custom name of the model. Default `RWD`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "        \"\"\"\n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the RandomWalkWithDrift model.\n",
    "\n",
    "        Fit an RandomWalkWithDrift to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: RandomWalkWithDrift fitted model.\n",
    "        \"\"\"        \n",
    "        mod = _random_walk_with_drift(y, h=1, fitted=True)\n",
    "        mod = dict(mod) \n",
    "        residuals = y - mod['fitted']\n",
    "        sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "        mod['sigma'] = sigma\n",
    "        mod['n'] = len(y)\n",
    "        self.model_ = mod\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int, \n",
    "            X: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None\n",
    "        ):\n",
    "        \"\"\"Predict with fitted RandomWalkWithDrift.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        hrange = np.arange(h, dtype=np.float32)\n",
    "        mean = self.model_['slope'] * (1 + hrange) + self.model_['last_y']\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is not None: \n",
    "            steps = np.arange(1, h + 1)\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(steps * (1 + steps / (self.model_['n'] - 1)))\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        \"\"\"Access fitted RandomWalkWithDrift insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient RandomWalkWithDrift predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _random_walk_with_drift(y=y, h=h, fitted=fitted or (level is not None))\n",
    "        res = {'mean': out['mean']}\n",
    "        \n",
    "        if fitted:\n",
    "            res['fitted'] = out['fitted']\n",
    "        \n",
    "        if level is not None: \n",
    "            steps = np.arange(1, h + 1)\n",
    "            residuals = y - out['fitted']\n",
    "            sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "            sigmah = sigma * np.sqrt(steps * (1 + steps / (len(y) - 1)))\n",
    "            pred_int = _calculate_intervals(out, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "\n",
    "\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - forecast\n",
    "rwd = RandomWalkWithDrift()\n",
    "rwd.forecast(ap, 12)\n",
    "rwd.forecast(ap, 12, None, None, (80,95), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - fit & predict \n",
    "rwd = RandomWalkWithDrift()\n",
    "rwd.fit(ap)\n",
    "rwd.predict(12)\n",
    "rwd.predict(12, None, (80,95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "rwd = RandomWalkWithDrift()\n",
    "test_class(rwd, x=ap, h=12, level=[90, 80])\n",
    "rwd = rwd.fit(ap)\n",
    "fcst_rwd = rwd.predict(12)\n",
    "test_close(fcst_rwd['mean'][:2], np.array([434.2378, 436.4755]), eps=1e-4)\n",
    "np.testing.assert_almost_equal(\n",
    "    rwd.predict_in_sample()['fitted'][:3], \n",
    "    np.array([np.nan, 118 - 3.7622378, 132 - 11.7622378]),\n",
    "    decimal=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "rwd = RandomWalkWithDrift()\n",
    "fcst_rwd = rwd.forecast(ap,12,None,None,(80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_rwd['lo-80'],\n",
    "    np.array([390.9799, 375.0862, 363.2664, 353.5325, 345.1178, 337.6304, 330.8384, 324.5916, 318.7857, 313.3453, 308.2136, 303.3469]),\n",
    "    decimal=1\n",
    ")\n",
    "_plot_insample_pi(fcst_rwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(RandomWalkWithDrift()),\n",
    "    'RWD'\n",
    ")\n",
    "test_eq(\n",
    "    repr(RandomWalkWithDrift(alias='RWD_custom')),\n",
    "    'RWD_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomWalkWithDrift's usage example\n",
    "\n",
    "from statsforecast.models import RandomWalkWithDrift\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = RandomWalkWithDrift()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeasonalNaive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeasonalNaive(_TS):\n",
    "    \n",
    "    def __init__(self, season_length: int, alias: str = 'SeasonalNaive'):\n",
    "        self.season_length = season_length\n",
    "        self.alias = alias\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the SeasonalNaive model.\n",
    "\n",
    "        Fit an SeasonalNaive to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: SeasonalNaive fitted model.\n",
    "        \"\"\"        \n",
    "        mod = _seasonal_naive(\n",
    "            y=y, \n",
    "            season_length=self.season_length, \n",
    "            h=self.season_length, \n",
    "            fitted=True,\n",
    "        )\n",
    "        mod = dict(mod) \n",
    "        residuals = y - mod['fitted']\n",
    "        mod['sigma'] = _calculate_sigma(residuals, \n",
    "                                        len(y) - self.season_length)\n",
    "        self.model_ = mod\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,  \n",
    "            X: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None, \n",
    "        ):\n",
    "        \"\"\"Predict with fitted Naive.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val_seas(season_vals=self.model_['mean'], \n",
    "                                season_length=self.season_length, h=h)\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is not None: \n",
    "            k = np.floor((h - 1) / self.season_length)\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(k + 1)\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        \n",
    "        return res\n",
    "        \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        \"\"\"Access fitted SeasonalNaive insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"        \n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    " \n",
    "    \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient SeasonalNaive predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _seasonal_naive(\n",
    "            y=y, h=h, fitted=fitted or (level is not None), \n",
    "            season_length=self.season_length\n",
    "        )\n",
    "        res = {'mean': out['mean']}\n",
    "        \n",
    "        if fitted:\n",
    "            res['fitted'] = out['fitted']\n",
    "        \n",
    "        if level is not None: \n",
    "            k = np.floor((h - 1) / self.season_length)\n",
    "            residuals = y - out['fitted']\n",
    "            sigma = _calculate_sigma(residuals, len(y) - self.season_length)\n",
    "            sigmah = sigma * np.sqrt(k + 1)\n",
    "            pred_int = _calculate_intervals(out, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "            \n",
    "        return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - forecast\n",
    "seas_naive = SeasonalNaive(season_length=12)\n",
    "seas_naive.forecast(ap, 12)\n",
    "seas_naive.forecast(ap, 12, None, None, (80,95), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - fit and predict \n",
    "seas_naive = SeasonalNaive(season_length=12)\n",
    "seas_naive.fit(ap)\n",
    "seas_naive.predict(12)\n",
    "seas_naive.predict(12, None, (80,95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "seas_naive = SeasonalNaive(season_length=12)\n",
    "test_class(seas_naive, x=ap, h=12, level=[90, 80])\n",
    "seas_naive = seas_naive.fit(ap)\n",
    "fcst_seas_naive = seas_naive.predict(12)\n",
    "test_eq(seas_naive.predict_in_sample()['fitted'][-3:], np.array([461 - 54., 390 - 28., 432 - 27.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "seas_naive = SeasonalNaive(season_length=12)\n",
    "fcst_seas_naive = seas_naive.forecast(ap, 12, None, None, (80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_seas_naive['lo-80'],\n",
    "    np.array([370.4595, 344.4595, 372.4595, 414.4595, 425.4595, 488.4595, \n",
    "              575.4595, 559.4595, 461.4595, 414.4595, 343.4595, 385.4595]),\n",
    "    decimal=4\n",
    ")\n",
    "_plot_insample_pi(fcst_seas_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SeasonalNaive(12)),\n",
    "    'SeasonalNaive'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SeasonalNaive(12, alias='SeasonalNaive_custom')),\n",
    "    'SeasonalNaive_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeasonalNaive's usage example\n",
    "\n",
    "from statsforecast.models import SeasonalNaive\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = SeasonalNaive(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WindowAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _window_average(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "        window_size: int, # window size\n",
    "    ): \n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    if y.size < window_size:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    wavg = y[-window_size:].mean()\n",
    "    mean = _repeat_val(val=wavg, h=h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class WindowAverage(_TS):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            window_size: int,\n",
    "            alias: str = 'WindowAverage'\n",
    "        ):\n",
    "        \"\"\"WindowAverage model.\n",
    "\n",
    "        Uses the average of the last $k$ observations, with $k$ the length of the window.\n",
    "        Wider windows will capture global trends, while narrow windows will reveal local trends.\n",
    "        The length of the window selected should take into account the importance of past\n",
    "        observations and how fast the series changes.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `window_size`: int, size of truncated series on which average is estimated.<br>\n",
    "        `alias`: str, Custom name of the model. Default `WindowAverage`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "        \"\"\"        \n",
    "        self.window_size = window_size\n",
    "        self.alias = alias\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the WindowAverage model.\n",
    "\n",
    "        Fit an WindowAverage to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: WindowAverage fitted model.\n",
    "        \"\"\"\n",
    "        mod = _window_average(y=y, h=1, window_size=self.window_size, fitted=False)\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self, \n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted WindowAverage.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted WindowAverage insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient WindowAverage predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _window_average(y=y, h=h, fitted=fitted, window_size=self.window_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "w_avg = WindowAverage(window_size=24)\n",
    "test_class(w_avg, x=ap, h=12, skip_insample=True)\n",
    "w_avg = w_avg.fit(ap)\n",
    "fcst_w_avg = w_avg.predict(12)\n",
    "test_close(fcst_w_avg['mean'], np.repeat(ap[-24:].mean(), 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(WindowAverage(1)),\n",
    "    'WindowAverage'\n",
    ")\n",
    "test_eq(\n",
    "    repr(WindowAverage(1, alias='WindowAverage_custom')),\n",
    "    'WindowAverage_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WindowAverage's usage example\n",
    "\n",
    "from statsforecast.models import WindowAverage\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = WindowAverage(window_size=12*4)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeasonalWindowAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _seasonal_window_average(\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        fitted: bool,\n",
    "        season_length: int,\n",
    "        window_size: int,\n",
    "    ):\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    min_samples = season_length * window_size\n",
    "    if y.size < min_samples:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    season_avgs = np.zeros(season_length, np.float32)\n",
    "    for i, value in enumerate(y[-min_samples:]):\n",
    "        season = i % season_length\n",
    "        season_avgs[season] += value / window_size\n",
    "    out = _repeat_val_seas(season_vals=season_avgs, h=h, season_length=season_length)\n",
    "    return {'mean': out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeasonalWindowAverage(_TS):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int,\n",
    "            window_size: int,\n",
    "            alias: str = 'SeasWA'\n",
    "        ):\n",
    "        \"\"\"SeasonalWindowAverage model.\n",
    "\n",
    "        An average of the last $k$ observations of the same period, with $k$ the length of the window.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `window_size`: int, size of truncated series on which average is estimated.\n",
    "        `seasonal_length`: int, number of observations per cycle.\n",
    "        `alias`: str, Custom name of the model. Default `SeasWA`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "        \"\"\"        \n",
    "        self.season_length = season_length\n",
    "        self.window_size = window_size\n",
    "        self.alias = alias\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the SeasonalWindowAverage model.\n",
    "\n",
    "        Fit an SeasonalWindowAverage to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: SeasonalWindowAverage fitted model.\n",
    "        \"\"\"        \n",
    "        mod = _seasonal_window_average(\n",
    "            y=y, \n",
    "            h=self.season_length,\n",
    "            fitted=False,\n",
    "            season_length=self.season_length, \n",
    "            window_size=self.window_size,\n",
    "        )\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted SeasonalWindowAverage.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val_seas(season_vals=self.model_['mean'], \n",
    "                                season_length=self.season_length, h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted SeasonalWindowAverage insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient SeasonalWindowAverage predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"        \n",
    "        out = _seasonal_window_average(\n",
    "            y=y, h=h, fitted=fitted, \n",
    "            season_length=self.season_length,\n",
    "            window_size=self.window_size\n",
    "        )\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "seas_w_avg = SeasonalWindowAverage(season_length=12, window_size=1)\n",
    "test_class(seas_w_avg, x=ap, h=12, skip_insample=True)\n",
    "seas_w_avg = seas_w_avg.fit(ap)\n",
    "fcst_seas_w_avg = w_avg.predict(12)\n",
    "test_eq(fcst_w_avg['mean'], fcst_seas_w_avg['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SeasonalWindowAverage(12, 1)),\n",
    "    'SeasWA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SeasonalWindowAverage(12, 1, alias='SeasWA_custom')),\n",
    "    'SeasWA_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeasonalWindowAverage's usage example\n",
    "\n",
    "from statsforecast.models import SeasonalWindowAverage\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = SeasonalWindowAverage(season_length=12, window_size=4)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 4. Sparse or Intermittent </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADIDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _adida(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ):\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    if (y == 0).all():\n",
    "        return {'mean': np.repeat(np.float32(0), h)}\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean()\n",
    "    aggregation_level = round(mean_interval)\n",
    "    lost_remainder_data = len(y) % aggregation_level\n",
    "    y_cut = y[lost_remainder_data:]\n",
    "    aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "    sums_forecast, _ = _optimized_ses_forecast(aggregation_sums)\n",
    "    forecast = sums_forecast / aggregation_level\n",
    "    mean = _repeat_val(val=forecast, h=h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ADIDA(_TS):\n",
    "\n",
    "    def __init__(self, alias: str = 'ADIDA'):\n",
    "        \"\"\"ADIDA model.\n",
    "\n",
    "        Aggregate-Dissagregate Intermittent Demand Approach: Uses temporal aggregation to reduce the \n",
    "        number of zero observations. Once the data has been agregated, it uses the optimized SES to \n",
    "        generate the forecasts at the new level. It then breaks down the forecast to the original \n",
    "        level using equal weights.\n",
    "\n",
    "        ADIDA specializes on sparse or intermittent series are series with very few non-zero observations. \n",
    "        They are notoriously hard to forecast, and so, different methods have been developed \n",
    "        especifically for them.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alias`: str, Custom name of the model. Default `ADIDA`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Nikolopoulos, K., Syntetos, A. A., Boylan, J. E., Petropoulos, F., & Assimakopoulos, V. (2011). An aggregate–disaggregate intermittent demand approach (ADIDA) to forecasting: an empirical proposition and analysis. Journal of the Operational Research Society, 62(3), 544-554.](https://researchportal.bath.ac.uk/en/publications/an-aggregate-disaggregate-intermittent-demand-approach-adida-to-f).\n",
    "        \"\"\"        \n",
    "        self.alias = alias\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the ADIDA model.\n",
    "\n",
    "        Fit an ADIDA to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: ADIDA fitted model.\n",
    "        \"\"\"        \n",
    "        mod = _adida(y=y, h=1, fitted=False)\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted ADIDA.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"        \n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted ADIDA insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient ADIDA predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _adida(y=y, h=h, fitted=fitted)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "deg_ts = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "adida = ADIDA()\n",
    "test_class(adida, x=ap, h=12, skip_insample=True)\n",
    "test_class(adida, x=deg_ts, h=12, skip_insample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(ADIDA()),\n",
    "    'ADIDA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(ADIDA(alias='ADIDA_custom')),\n",
    "    'ADIDA_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADIDA's usage example\n",
    "\n",
    "from statsforecast.models import ADIDA\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = ADIDA()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrostonClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _croston_classic(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ): \n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    yd = _demand(y)\n",
    "    yi = _intervals(y)\n",
    "    if not yd.size: #no demand\n",
    "        return {'mean': _repeat_val(val=y[-1], h=h)}\n",
    "    ydp, _ = _ses_forecast(yd, 0.1)\n",
    "    yip, _ = _ses_forecast(yi, 0.1)\n",
    "    if yip != 0.:\n",
    "        mean = ydp / yip\n",
    "    else:\n",
    "        mean = ydp\n",
    "    mean = _repeat_val(val=mean, h=h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrostonClassic(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'CrostonClassic'):\n",
    "        \"\"\"CrostonClassic model.\n",
    "\n",
    "        A method to forecast time series that exhibit intermittent demand.\n",
    "        It decomposes the original time series into a non-zero demand size $z_t$ and \n",
    "        inter-demand intervals $p_t$. Then the forecast is given by:\n",
    "        $$ \\hat{y}_t = \\\\frac{\\hat{z}_t}{\\hat{p}_t} $$ \n",
    "\n",
    "        where $\\hat{z}_t$ and $\\hat{p}_t$ are forecasted using SES. The smoothing parameter \n",
    "        of both components is set equal to 0.1\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alias`: str, Custom name of the model. Default `CrostonClassic`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.](https://link.springer.com/article/10.1057/jors.1972.50)\n",
    "        \"\"\"        \n",
    "        self.alias = alias\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the CrostonClassic model.\n",
    "\n",
    "        Fit an CrostonClassic to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: CrostonClassic fitted model.\n",
    "        \"\"\"        \n",
    "        mod = _croston_classic(y=y, h=1, fitted=False)\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted CrostonClassic.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level):\n",
    "        \"\"\"Access fitted CrostonClassic insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient CrostonClassic predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"        \n",
    "        out = _croston_classic(y=y, h=h, fitted=fitted)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "croston = CrostonClassic()\n",
    "test_class(croston, x=ap, h=12, skip_insample=True)\n",
    "test_class(croston, x=deg_ts, h=12, skip_insample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(CrostonClassic()),\n",
    "    'CrostonClassic'\n",
    ")\n",
    "test_eq(\n",
    "    repr(CrostonClassic(alias='CrostonClassic_custom')),\n",
    "    'CrostonClassic_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrostonClassic's usage example\n",
    "\n",
    "from statsforecast.models import CrostonClassic\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = CrostonClassic()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrostonOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _croston_optimized(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ): \n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    yd = _demand(y)\n",
    "    yi = _intervals(y)\n",
    "    if not yd.size:\n",
    "        return {'mean': _repeat_val(val=y[-1], h=h)}\n",
    "    ydp, _ = _optimized_ses_forecast(yd)\n",
    "    yip, _ = _optimized_ses_forecast(yi)\n",
    "    if yip != 0.:\n",
    "        mean = ydp / yip\n",
    "    else:\n",
    "        mean = ydp\n",
    "    mean = _repeat_val(val=mean, h=h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrostonOptimized(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'CrostonOptimized'):\n",
    "        \"\"\"CrostonOptimized model.\n",
    "\n",
    "        A method to forecast time series that exhibit intermittent demand.\n",
    "        It decomposes the original time series into a non-zero demand size $z_t$ and \n",
    "        inter-demand intervals $p_t$. Then the forecast is given by:\n",
    "        $$ \\hat{y}_t = \\\\frac{\\hat{z}_t}{\\hat{p}_t} $$\n",
    "\n",
    "        A variation of the classic Croston's method where the smooting paramater is optimally \n",
    "        selected from the range $[0.1,0.3]$. Both the non-zero demand $z_t$ and the inter-demand \n",
    "        intervals $p_t$ are smoothed separately, so their smoothing parameters can be different.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alias`: str, Custom name of the model. Default `CrostonOptimized`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.](https://link.springer.com/article/10.1057/jors.1972.50).\n",
    "        \"\"\"        \n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the CrostonOptimized model.\n",
    "\n",
    "        Fit an CrostonOptimized to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: CrostonOptimized fitted model.\n",
    "        \"\"\"        \n",
    "        mod = _croston_optimized(y=y, h=1, fitted=False)\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted CrostonOptimized.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted CrostonOptimized insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient CrostonOptimized predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"        \n",
    "        out = _croston_optimized(y=y, h=h, fitted=fitted)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "croston_op = CrostonOptimized()\n",
    "test_class(croston_op, x=ap, h=12, skip_insample=True)\n",
    "test_class(croston_op, x=deg_ts, h=12, skip_insample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(CrostonOptimized()),\n",
    "    'CrostonOptimized'\n",
    ")\n",
    "test_eq(\n",
    "    repr(CrostonOptimized(alias='CrostonOptimized_custom')),\n",
    "    'CrostonOptimized_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrostonOptimized's usage example\n",
    "\n",
    "from statsforecast.models import CrostonOptimized\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = CrostonOptimized()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrostonSBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _croston_sba(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool,  # fitted values\n",
    "    ):\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    mean = _croston_classic(y, h, fitted)\n",
    "    mean['mean'] *= 0.95\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrostonSBA(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'CrostonSBA'):\n",
    "        \"\"\"CrostonSBA model.\n",
    "\n",
    "        A method to forecast time series that exhibit intermittent demand.\n",
    "        It decomposes the original time series into a non-zero demand size $z_t$ and \n",
    "        inter-demand intervals $p_t$. Then the forecast is given by:\n",
    "        $$ \\hat{y}_t = \\\\frac{\\hat{z}_t}{\\hat{p}_t} $$\n",
    "\n",
    "        A variation of the classic Croston's method that uses a debiasing factor, so that the \n",
    "        forecast is given by:\n",
    "        $$ \\hat{y}_t = 0.95  \\\\frac{\\hat{z}_t}{\\hat{p}_t} $$\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alias`: str, Custom name of the model. Default `CrostonSBA`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        [Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.](https://link.springer.com/article/10.1057/jors.1972.50).\n",
    "        \"\"\"        \n",
    "        self.alias = alias\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the CrostonSBA model.\n",
    "\n",
    "        Fit an CrostonSBA to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: CrostonSBA fitted model.\n",
    "        \"\"\"\n",
    "        mod = _croston_sba(y=y, h=1, fitted=False)\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted CrostonSBA.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted CrostonSBA insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forecast(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient CrostonSBA predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"        \n",
    "        out = _croston_sba(y=y, h=h, fitted=fitted)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "croston_sba = CrostonSBA()\n",
    "test_class(croston_sba, x=ap, h=12, skip_insample=True)\n",
    "test_class(croston_sba, x=deg_ts, h=12, skip_insample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(CrostonSBA()),\n",
    "    'CrostonSBA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(CrostonSBA(alias='CrostonSBA_custom')),\n",
    "    'CrostonSBA_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrostonSBA's usage example\n",
    "\n",
    "from statsforecast.models import CrostonSBA\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = CrostonSBA()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _imapa(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ): \n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    if (y == 0).all():\n",
    "        return {'mean': np.repeat(np.float32(0), h)}\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean().item()\n",
    "    max_aggregation_level = round(mean_interval)\n",
    "    forecasts = np.empty(max_aggregation_level, np.float32)\n",
    "    for aggregation_level in range(1, max_aggregation_level + 1):\n",
    "        lost_remainder_data = len(y) % aggregation_level\n",
    "        y_cut = y[lost_remainder_data:]\n",
    "        aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "        forecast, _ = _optimized_ses_forecast(aggregation_sums)\n",
    "        forecasts[aggregation_level - 1] = (forecast / aggregation_level)\n",
    "    forecast = forecasts.mean()\n",
    "    mean = _repeat_val(val=forecast, h=h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IMAPA(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'IMAPA'):\n",
    "        \"\"\"IMAPA model.\n",
    "\n",
    "        Intermittent Multiple Aggregation Prediction Algorithm: Similar to ADIDA, but instead of\n",
    "        using a single aggregation level, it considers multiple in order to capture different\n",
    "        dynamics of the data. Uses the optimized SES to generate the forecasts at the new levels\n",
    "        and then combines them using a simple average.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alias`: str, Custom name of the model. Default `IMAPA`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        - [Syntetos, A. A., & Boylan, J. E. (2021). Intermittent demand forecasting: Context, methods and applications. John Wiley & Sons.](https://www.ifors.org/intermittent-demand-forecasting-context-methods-and-applications/).\n",
    "        \"\"\"\n",
    "        self.alias = alias\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the IMAPA model.\n",
    "\n",
    "        Fit an IMAPA to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: IMAPA fitted model.\n",
    "        \"\"\"\n",
    "        mod = _imapa(y=y, h=1, fitted=False)\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted IMAPA.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted IMAPA insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        \"\"\"Memory Efficient IMAPA predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _imapa(y=y, h=h, fitted=fitted)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "imapa = IMAPA()\n",
    "test_class(imapa, x=ap, h=12, skip_insample=True)\n",
    "test_class(imapa, x=deg_ts, h=12, skip_insample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(IMAPA()),\n",
    "    'IMAPA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(IMAPA(alias='IMAPA_custom')),\n",
    "    'IMAPA_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAPA's usage example\n",
    "\n",
    "from statsforecast.models import IMAPA\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = IMAPA()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _tsb(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: int, # fitted values\n",
    "        alpha_d: float,\n",
    "        alpha_p: float,\n",
    "    ):\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    if (y == 0).all():\n",
    "        return {'mean': np.repeat(np.float32(0), h)}\n",
    "    yd = _demand(y)\n",
    "    yp = _probability(y)\n",
    "    ypf, _ = _ses_forecast(yp, alpha_p)\n",
    "    ydf, _ = _ses_forecast(yd, alpha_d)\n",
    "    forecast = np.float32(ypf * ydf)\n",
    "    mean = _repeat_val(val=forecast, h=h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TSB(_TS):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            alpha_d: float,\n",
    "            alpha_p: float,\n",
    "            alias: str = 'TSB'\n",
    "        ):\n",
    "        \"\"\"TSB model.\n",
    "\n",
    "        Teunter-Syntetos-Babai: A modification of Croston's method that replaces the inter-demand \n",
    "        intervals with the demand probability $d_t$, which is defined as follows.\n",
    "\n",
    "        $$\n",
    "        d_t = \\\\begin{cases}\n",
    "            1  & \\\\text{if demand occurs at time t} \\\\\\ \n",
    "            0  & \\\\text{otherwise.}\n",
    "        \\\\end{cases}\n",
    "        $$\n",
    "\n",
    "        Hence, the forecast is given by \n",
    "\n",
    "        $$\\hat{y}_t= \\hat{d}_t\\hat{z_t}$$\n",
    "\n",
    "        Both $d_t$ and $z_t$ are forecasted using SES. The smooting paramaters of each may differ, \n",
    "        like in the optimized Croston's method.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `alpha_d`: float, smoothing parameter for demand<br>\n",
    "        `alpha_p`: float, smoothing parameter for probability<br>\n",
    "        `alias`: str, Custom name of the model. Default `TSB`.<br>\n",
    "\n",
    "        **References:**<br>\n",
    "        - [Teunter, R. H., Syntetos, A. A., & Babai, M. Z. (2011). Intermittent demand: Linking forecasting to inventory obsolescence. European Journal of Operational Research, 214(3), 606-615.](https://www.sciencedirect.com/science/article/abs/pii/S0377221711004437)\n",
    "        \"\"\"\n",
    "        self.alpha_d = alpha_d\n",
    "        self.alpha_p = alpha_p\n",
    "        self.alias = alias\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the TSB model.\n",
    "\n",
    "        Fit an TSB to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: TSB fitted model.\n",
    "        \"\"\"\n",
    "        mod = _tsb(\n",
    "            y=y, h=1, \n",
    "            fitted=False, \n",
    "            alpha_d=self.alpha_d, \n",
    "            alpha_p=self.alpha_p\n",
    "        )\n",
    "        self.model_ = dict(mod)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted TSB.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"        \n",
    "        mean = _repeat_val(self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        \"\"\"Access fitted TSB insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient TSB predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        out = _tsb(\n",
    "            y=y, h=h, \n",
    "            fitted=fitted, \n",
    "            alpha_d=self.alpha_d, \n",
    "            alpha_p=self.alpha_p\n",
    "        )\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "tsb = TSB(alpha_d=0.9, alpha_p=0.1)\n",
    "test_class(tsb, x=ap, h=12, skip_insample=True)\n",
    "test_class(tsb, x=deg_ts, h=12, skip_insample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(TSB(0.9, 0.1)),\n",
    "    'TSB'\n",
    ")\n",
    "test_eq(\n",
    "    repr(TSB(0.9, 0.1, alias='TSB_custom')),\n",
    "    'TSB_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSB's usage example\n",
    "\n",
    "from statsforecast.models import TSB\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = TSB(alpha_d=0.5, alpha_p=0.5)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 5. Multiple Seasonalities </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _predict_mstl_seas(mstl_ob, h, season_length):\n",
    "    seasoncolumns = mstl_ob.filter(regex='seasonal*').columns\n",
    "    nseasons = len(seasoncolumns)\n",
    "    seascomp = np.full((h, nseasons), np.nan)\n",
    "    seasonal_periods = [season_length] if isinstance(season_length, int) else season_length\n",
    "    for i in range(nseasons):\n",
    "        mp = seasonal_periods[i]\n",
    "        colname = seasoncolumns[i]\n",
    "        seascomp[:, i] = np.tile(mstl_ob[colname].values[-mp:], trunc(1 + (h-1)/mp))[:h]\n",
    "    lastseas = seascomp.sum(axis=1)\n",
    "    return lastseas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSTL(_TS):\n",
    "    \"\"\"MSTL model.\n",
    "    \n",
    "    The MSTL (Multiple Seasonal-Trend decomposition using LOESS) decomposes the time series\n",
    "    in multiple seasonalities using LOESS. Then forecasts the trend using \n",
    "    a custom non-seaonal model and each seasonality using a SeasonalNaive model.\n",
    "    \n",
    "    **Parameters:**<br>\n",
    "    `season_length`: Union[int, List[int], number of observations per unit of time. For multiple seasonalities use a list.<br>\n",
    "    `trend_forecaster`: StatsForecast model used to forecast the trend component.<br>\n",
    "    `alias`: str, Custom name of the model. Default `MSTL`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Bandara, Kasun & Hyndman, Rob & Bergmeir, Christoph. (2021). \"MSTL: A Seasonal-Trend Decomposition Algorithm for Time Series with Multiple Seasonal Patterns\".](https://arxiv.org/abs/2107.13462).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: Union[int, List[int]],\n",
    "        trend_forecaster = AutoETS(model='ZZN'),\n",
    "        alias: str = 'MSTL'\n",
    "    ):\n",
    "        \n",
    "        # check ETS model doesnt have seasonality\n",
    "        if repr(trend_forecaster) == 'AutoETS':\n",
    "            if trend_forecaster.model[2] != 'N':\n",
    "                raise Exception(\n",
    "                    'Trend forecaster should not adjust '\n",
    "                    'seasonal models.'\n",
    "                )\n",
    "        # check if trend forecaster has season_length=1\n",
    "        if hasattr(trend_forecaster, 'season_length'):\n",
    "            if trend_forecaster.season_length != 1:\n",
    "                raise Exception(\n",
    "                    'Trend forecaster should not adjust '\n",
    "                    'seasonal models. Please pass `season_length=1` '\n",
    "                    'to your trend forecaster'\n",
    "                )\n",
    "        self.season_length = season_length\n",
    "        self.trend_forecaster = trend_forecaster\n",
    "        self.alias = alias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            y: np.ndarray,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "        ):\n",
    "        \"\"\"Fit the MSTL model.\n",
    "\n",
    "        Fit MSTL to a time series (numpy array) `y`.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (t, ), clean time series.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional exogenous (default=None).<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `self`: MSTL fitted model.\n",
    "        \"\"\"\n",
    "        self.model_ = mstl(\n",
    "            x=y, \n",
    "            period=self.season_length\n",
    "        )\n",
    "        x_sa = self.model_[['trend', 'remainder']].sum(axis=1).values\n",
    "        self.trend_forecaster = self.trend_forecaster.fit(y=x_sa, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "            self,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            level: Optional[Tuple[int]] = None,\n",
    "        ):\n",
    "        \"\"\"Predict with fitted MSTL.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        kwargs: Dict[str, Any] = {'h': h, 'X': X}\n",
    "        if 'level' in signature(self.trend_forecaster.predict).parameters:\n",
    "            kwargs['level'] = level\n",
    "        res = self.trend_forecaster.predict(**kwargs)\n",
    "        seas = _predict_mstl_seas(self.model_, h=h, season_length=self.season_length)\n",
    "        res = {key: val + seas for key, val in res.items()}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        \"\"\"Access fitted MSTL insample predictions.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        kwargs = {}\n",
    "        if 'level' in signature(self.trend_forecaster.predict_in_sample).parameters:\n",
    "            kwargs['level'] = level\n",
    "        \n",
    "        res = self.trend_forecaster.predict_in_sample(**kwargs)\n",
    "        seas = self.model_.filter(regex='seasonal*').sum(axis=1).values\n",
    "        res = {key: val + seas for key, val in res.items()}\n",
    "        return res\n",
    "        \n",
    "    def forecast(\n",
    "            self, \n",
    "            y: np.ndarray,\n",
    "            h: int,\n",
    "            X: Optional[np.ndarray] = None,\n",
    "            X_future: Optional[np.ndarray] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "            fitted: bool = False,\n",
    "        ):\n",
    "        \"\"\"Memory Efficient MSTL predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        **Parameters:**<br>\n",
    "        `y`: numpy array of shape (n,), clean time series.<br>\n",
    "        `h`: int, forecast horizon.<br>\n",
    "        `X`: array-like of shape (t, n_x) optional insample exogenous (default=None).<br>\n",
    "        `X_future`: array-like of shape (h, n_x) optional exogenous (default=None).<br>\n",
    "        `level`: float list 0-100, confidence levels for prediction intervals.<br>\n",
    "        `fitted`: bool, wether or not returns insample predictions.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `forecasts`: dictionary, with entries 'mean' for point predictions and\n",
    "            'level_*' for probabilistic predictions.<br>\n",
    "        \"\"\"\n",
    "        model_ = mstl(\n",
    "            x=y, \n",
    "            period=self.season_length\n",
    "        )\n",
    "        x_sa = model_[['trend', 'remainder']].sum(axis=1).values\n",
    "        kwargs = {\n",
    "            'y': x_sa,\n",
    "            'h': h,\n",
    "            'X': X,\n",
    "            'X_future': X_future,\n",
    "            'fitted': fitted\n",
    "        }\n",
    "        if 'level' in signature(self.trend_forecaster.forecast).parameters:\n",
    "            kwargs['level'] = level\n",
    "        res = self.trend_forecaster.forecast(**kwargs)\n",
    "        #reseasonalize results\n",
    "        seas_h = _predict_mstl_seas(model_, h=h, season_length=self.season_length)\n",
    "        seas_insample = model_.filter(regex='seasonal*').sum(axis=1).values\n",
    "        res = {\n",
    "            key: val + (seas_insample if 'fitted' in key else seas_h) \\\n",
    "            for key, val in res.items()\n",
    "        }\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "trend_forecasters = [\n",
    "    AutoARIMA(), \n",
    "    AutoCES(), \n",
    "    AutoETS(model='ZZN'),\n",
    "    Naive(),\n",
    "    CrostonClassic()\n",
    "]\n",
    "skip_insamples = [False, True, False, False, True]\n",
    "for trend_forecaster, skip_insample in zip(trend_forecasters, skip_insamples):\n",
    "    mstl_model = MSTL(season_length=[12, 14], trend_forecaster=trend_forecaster)\n",
    "    test_class(mstl_model, x=ap, h=12, \n",
    "               skip_insample=skip_insample,\n",
    "               level=[80, 90] if not skip_insample else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#fail with seasonal trend forecasters\n",
    "test_fail(\n",
    "    MSTL,\n",
    "    contains='should not adjust seasonal',\n",
    "    args=([3, 12], AutoETS(model='ZZZ'))\n",
    ")\n",
    "test_fail(\n",
    "    MSTL,\n",
    "    contains='should not adjust seasonal',\n",
    "    args=([3, 12], AutoARIMA(season_length=12))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(MSTL(season_length=7)),\n",
    "    'MSTL'\n",
    ")\n",
    "test_eq(\n",
    "    repr(MSTL(season_length=7, alias='MSTL_custom')),\n",
    "    'MSTL_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSTL's usage example\n",
    "\n",
    "from statsforecast.models import MSTL\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "mstl_model = MSTL(season_length=[3, 12], trend_forecaster=AutoARIMA())\n",
    "mstl_model = mstl_model.fit(y=ap)\n",
    "y_hat_dict = mstl_model.predict(h=4, level=[80])\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 6. Theta Family </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Theta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Theta(AutoTheta): \n",
    "    \"\"\" Standard Theta Method. \n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `decomposition_type`: str, Sesonal decomposition type, 'multiplicative' (default) or 'additive'.<br>\n",
    "    `alias`: str, Custom name of the model. Default `Theta`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting](https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int = 1, \n",
    "            decomposition_type: str = 'multiplicative',\n",
    "            alias: str = 'Theta'\n",
    "        ): \n",
    "        super().__init__(season_length=season_length, \n",
    "                         model='STM', \n",
    "                         decomposition_type=decomposition_type, alias=alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "stm = Theta(season_length=12)\n",
    "fcast_stm = stm.forecast(ap,12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='STM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_stm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "stm = Theta(season_length=12)\n",
    "stm.fit(ap)\n",
    "fcast_stm = stm.predict(12)\n",
    "forward_stm = stm.forward(y=ap, h=12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='STM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "theta.fit(ap)\n",
    "forward_autotheta = theta.forward(y=ap, h=12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_stm,\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    forward_stm,\n",
    "    forward_autotheta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(Theta()),\n",
    "    'Theta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(Theta(alias='Theta_custom')),\n",
    "    'Theta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.forecast, name='Theta.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.fit, name='Theta.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.predict, name='Theta.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.predict_in_sample, name='Theta.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.forward, name='Theta.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta's usage example\n",
    "\n",
    "#from statsforecast.models import Holt\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = Theta(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Theta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class OptimizedTheta(AutoTheta): \n",
    "    \"\"\" Optimized Theta Method. \n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `decomposition_type`: str, Sesonal decomposition type, 'multiplicative' (default) or 'additive'.<br>\n",
    "    `alias`: str, Custom name of the model. Default `OptimizedTheta`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting](https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int = 1, \n",
    "            decomposition_type: str = 'multiplicative',\n",
    "            alias: str = 'OptimizedTheta'\n",
    "        ): \n",
    "        super().__init__(season_length=season_length, \n",
    "                         model='OTM', \n",
    "                         decomposition_type=decomposition_type, alias=alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "otm = OptimizedTheta(season_length=12)\n",
    "fcast_otm = otm.forecast(ap,12)\n",
    "otm.fit(ap)\n",
    "forward_otm = otm.forward(y=ap, h=12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='OTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "theta.fit(ap)\n",
    "forward_autotheta = theta.forward(y=ap, h=12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_otm\n",
    ")\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    forward_autotheta, \n",
    "    forward_otm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "otm = OptimizedTheta(season_length=12)\n",
    "otm.fit(ap)\n",
    "fcast_otm = otm.predict(12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='OTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_otm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(OptimizedTheta()),\n",
    "    'OptimizedTheta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(OptimizedTheta(alias='OptimizedTheta_custom')),\n",
    "    'OptimizedTheta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.forecast, name='OptimizedTheta.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.fit, name='OptimizedTheta.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.predict, name='OptimizedTheta.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.predict_in_sample, name='OptimizedTheta.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.forward, name='OptimizedTheta.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OptimzedThetA's usage example\n",
    "\n",
    "#from statsforecast.models import Holt\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = OptimizedTheta(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Standard Theta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DynamicTheta(AutoTheta): \n",
    "    \"\"\" Dynamic Standard Theta Method. \n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `decomposition_type`: str, Sesonal decomposition type, 'multiplicative' (default) or 'additive'.<br>\n",
    "    `alias`: str, Custom name of the model. Default `DynamicTheta`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting]( https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int = 1, \n",
    "            decomposition_type: str = 'multiplicative',\n",
    "            alias: str = 'DynamicTheta'\n",
    "        ): \n",
    "        super().__init__(season_length=season_length, \n",
    "                         model='DSTM', \n",
    "                         decomposition_type=decomposition_type, alias=alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "dstm = DynamicTheta(season_length=12)\n",
    "fcast_dstm = dstm.forecast(ap,12)\n",
    "dstm.fit(ap)\n",
    "forward_dstm = dstm.forward(y=ap, h=12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='DSTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "theta.fit(ap)\n",
    "forward_autotheta = theta.forward(y=ap, h=12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_dstm\n",
    ")\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    forward_autotheta, \n",
    "    forward_dstm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "dstm = DynamicTheta(season_length=12)\n",
    "dstm.fit(ap)\n",
    "fcast_dstm = dstm.predict(12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='DSTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_dstm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(DynamicTheta()),\n",
    "    'DynamicTheta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(DynamicTheta(alias='DynamicTheta_custom')),\n",
    "    'DynamicTheta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.forecast, name='DynamicTheta.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.fit, name='DynamicTheta.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.predict, name='DynamicTheta.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.predict_in_sample, name='DynamicTheta.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.forward, name='DynamicTheta.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DynStandardThetaMethod's usage example\n",
    "\n",
    "#from statsforecast.models import Holt\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = DynamicTheta(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Optimized Theta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DynamicOptimizedTheta(AutoTheta): \n",
    "    \"\"\" Dynamic Optimized Theta Method. \n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `season_length`: int, number of observations per unit of time. Ex: 24 Hourly data.<br>\n",
    "    `decomposition_type`: str, Sesonal decomposition type, 'multiplicative' (default) or 'additive'.<br>\n",
    "    `alias`: str, Custom name of the model. Default `DynamicOptimizedTheta`.<br>\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting]( https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int = 1, \n",
    "            decomposition_type: str = 'multiplicative',\n",
    "            alias: str = 'DynamicOptimizedTheta'\n",
    "        ): \n",
    "        super().__init__(season_length=season_length, \n",
    "                         model='DOTM', \n",
    "                         decomposition_type=decomposition_type, alias=alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "dotm = DynamicOptimizedTheta(season_length=12)\n",
    "fcast_dotm = dotm.forecast(ap,12)\n",
    "dotm.fit(ap)\n",
    "forward_dotm = dotm.forward(y=ap, h=12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='DOTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "theta.fit(ap)\n",
    "forward_autotheta = theta.forward(y=ap, h=12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_dotm\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    forward_autotheta, \n",
    "    forward_dotm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "dotm = DynamicOptimizedTheta(season_length=12)\n",
    "dotm.fit(ap)\n",
    "fcast_dotm = dotm.predict(12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='DOTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_dotm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(DynamicOptimizedTheta()),\n",
    "    'DynamicOptimizedTheta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(DynamicOptimizedTheta(alias='DynamicOptimizedTheta_custom')),\n",
    "    'DynamicOptimizedTheta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.forecast, name='DynamicOptimizedTheta.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.fit, name='DynamicOptimizedTheta.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.predict, name='DynamicOptimizedTheta.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.predict_in_sample, name='DynamicOptimizedTheta.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.forward, name='DynamicOptimizedTheta.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OptimzedThetaMethod's usage example\n",
    "\n",
    "#from statsforecast.models import Holt\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "\n",
    "model = DynamicOptimizedTheta(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> References </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **General**\n",
    "-  [Hyndman, R.J., & Athanasopoulos, G. (2021). \"Forecasting: principles and practice, 3rd edition\". OTexts: Melbourne, Australia. OTexts.com/fpp3  Accessed on July 2022](https://otexts.com/fpp3/).\n",
    "\n",
    "- [Shmueli, G., & Lichtendahl Jr, K. C. (2016). \"Practical time series forecasting with R: A hands-on guide\". Axelrod Schnall Publishers](https://www.forecastingbook.com/).\n",
    "\n",
    "#### **Automatic Forecasting**\n",
    "- [Rob J. Hyndman, Yeasmin Khandakar (2008). \"Automatic Time Series Forecasting: The forecast package for R\"](https://www.jstatsoft.org/article/view/v027i03).\n",
    "\n",
    "#### **Exponential Smoothing**\n",
    "- [Charles. C. Holt (1957). \"Forecasting seasonals and trends by exponentially weighted moving averages\", ONR Research Memorandum, Carnegie Institute of Technology 52](https://www.sciencedirect.com/science/article/abs/pii/S0169207003001134).\n",
    "\n",
    "- [Peter R. Winters (1960). \"Forecasting sales by exponentially weighted moving averages\". Management Science](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.3.324).\n",
    "\n",
    "- [Hyndman, Rob, et al (2008). \"Forecasting with exponential smoothing: the state space approach\"](https://robjhyndman.com/expsmooth/).\n",
    "\n",
    "- [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Methods with trend\"](https://otexts.com/fpp3/holt.html).\n",
    "\n",
    "- [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Methods with seasonality\"](https://otexts.com/fpp3/holt-winters.html).\n",
    "\n",
    "#### **Simple Methods**\n",
    "- [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "\n",
    "#### **Sparse Intermittent**\n",
    "- [Croston, J. D. (1972). \"Forecasting and stock control for intermittent demands\". Journal of the Operational Research Society, 23(3), 289-303](https://link.springer.com/article/10.1057/jors.1972.50).\n",
    "\n",
    "- [Nikolopoulos, K., Syntetos, A. A., Boylan, J. E., Petropoulos, F., & Assimakopoulos, V. (2011). \"An aggregate–disaggregate intermittent demand approach (ADIDA) to forecasting: an empirical proposition and analysis\". Journal of the Operational Research Society, 62(3), 544-554](https://researchportal.bath.ac.uk/en/publications/an-aggregate-disaggregate-intermittent-demand-approach-adida-to-f).\n",
    "\n",
    "- [Syntetos, A. A., & Boylan, J. E. (2005). \"The accuracy of intermittent demand estimates\". International Journal of forecasting, 21(2), 303-314](https://www.academia.edu/1527250/The_accuracy_of_intermittent_demand_estimates).\n",
    "\n",
    "- [Syntetos, A. A., & Boylan, J. E. (2021). \"Intermittent demand forecasting: Context, methods and applications\". John Wiley & Sons](https://www.ifors.org/intermittent-demand-forecasting-context-methods-and-applications/).\n",
    "\n",
    "- [Teunter, R. H., Syntetos, A. A., & Babai, M. Z. (2011). \"Intermittent demand: Linking forecasting to inventory obsolescence\". European Journal of Operational Research, 214(3), 606-615](https://www.sciencedirect.com/science/article/abs/pii/S0377221711004437).\n",
    "\n",
    "#### **Multiple Seasonalities**\n",
    "\n",
    "- [Bandara, Kasun & Hyndman, Rob & Bergmeir, Christoph. (2021). \"MSTL: A Seasonal-Trend Decomposition Algorithm for Time Series with Multiple Seasonal Patterns\".](https://arxiv.org/abs/2107.13462)\n",
    "\n",
    "#### **Theta Family**\n",
    "\n",
    "- [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting]( https://www.sciencedirect.com/science/article/pii/S0169207016300243).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
